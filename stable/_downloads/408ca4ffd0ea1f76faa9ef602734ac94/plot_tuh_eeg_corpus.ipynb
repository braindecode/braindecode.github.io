{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Process a big data EEG resource (TUH EEG Corpus)\n\nIn this example, we showcase usage of the Temple University Hospital EEG Corpus\n(https://isip.piconepress.com/projects/nedc/html/tuh_eeg/)\nincluding simple preprocessing steps as well as cutting of compute windows.\n   :depth: 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Lukas Gemein <l.gemein@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport tempfile\n\nimport matplotlib.pyplot as plt\nimport mne\nimport numpy as np\nfrom numpy import multiply\n\nfrom braindecode.datasets import TUH\nfrom braindecode.preprocessing import (\n    Preprocessor,\n    create_fixed_length_windows,\n    preprocess,\n)\n\nmne.set_log_level(\"ERROR\")  # avoid messages every time a window is extracted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the dataset using TUHMock\n\nSince the data is not available at the time of the creation of this example,\nwe are required to mock some of the dataset functionality. Therefore, if you\nwant to try this code with the actual data, please disconsider this section.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.datasets.tuh import _TUHMock as TUH  # noqa F811"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly, we start by creating a TUH mock dataset using braindecode's _TUHMock class.\nThe complete code can be found at :func:`braindecode.datasets.TUH`, but we will give\na small description of how it works.\nThis class is able to read the recordings from TUH_PATH and generate a description\nby parsing information from file paths, such as patient id and recording data.\nTHis description can later be accessed by the object's .description method.\nAfter that, the files are sorted chronologically by year, month, day,\npatient id, recording session and segment, and then use the description corresponding\nto the specified by recording ids.\nFInally, additional information regarding age and gender of the subjects are parsed\ndirectly to the description.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "TUH_PATH = \"please insert actual path to data here\"\n# specify the number of jobs for loading and windowing\nN_JOBS = 2\ntuh = TUH(\n    path=TUH_PATH,\n    recording_ids=None,\n    target_name=None,\n    preload=False,\n    add_physician_reports=False,\n    rename_channels=True,\n    set_montage=True,\n    n_jobs=1 if TUH.__name__ == \"_TUHMock\" else N_JOBS,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize our data's statistics using the class' \"description\" method\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plt_histogram(df_of_ages_genders, alpha=0.5, fs=24, ylim=1.5, show_title=True):\n    # Dafarame containing info about gender and age of subjects\n    df = df_of_ages_genders\n    male_df = df[df[\"gender\"] == \"M\"]\n    female_df = df[df[\"gender\"] == \"F\"]\n\n    plt.figure(figsize=(15, 18))\n    if show_title:\n        plt.suptitle(\"Age information\", y=0.95, fontsize=fs + 5)\n\n    # First plot: Male individuals\n    plt.subplot(121)\n    plt.hist(\n        male_df[\"age\"],\n        bins=np.linspace(0, 100, 101),\n        alpha=alpha,\n        color=\"green\",\n        orientation=\"horizontal\",\n    )\n    plt.axhline(\n        np.mean(male_df[\"age\"]),\n        color=\"black\",\n        label=f\"mean age {np.mean(male_df['age']):.1f} (\u00b1{np.std(male_df['age']):.1f})\",\n    )\n    plt.barh(\n        np.mean(male_df[\"age\"]),\n        height=2 * np.std(male_df[\"age\"]),\n        width=ylim,\n        color=\"black\",\n        alpha=0.25,\n    )\n\n    # Legend\n    plt.xlim(0, ylim)\n    plt.legend(fontsize=fs, loc=\"upper left\")\n    plt.title(\n        f\"male ({100 * len(male_df) / len(df):.1f}%)\",\n        fontsize=fs,\n        loc=\"left\",\n        y=1,\n        x=0.05,\n    )\n    plt.yticks(color=\"w\")\n    plt.gca().invert_xaxis()\n    plt.yticks(np.linspace(0, 100, 11), fontsize=fs - 5)\n    plt.tick_params(labelsize=fs - 5)\n\n    # First plot: Female individuals\n    plt.subplot(122)\n    plt.hist(\n        female_df[\"age\"],\n        bins=np.linspace(0, 100, 101),\n        alpha=alpha,\n        color=\"orange\",\n        orientation=\"horizontal\",\n    )\n    plt.axhline(\n        np.mean(female_df[\"age\"]),\n        color=\"black\",\n        linestyle=\"--\",\n        label=f\"mean age {np.mean(female_df['age']):.1f} (\"\n        f\"\u00b1{np.std(female_df['age']):.1f})\",\n    )\n    plt.barh(\n        np.mean(female_df[\"age\"]),\n        height=2 * np.std(female_df[\"age\"]),\n        width=ylim,\n        color=\"black\",\n        alpha=0.25,\n    )\n\n    # Label\n    plt.legend(fontsize=fs, loc=\"upper right\")\n    plt.xlim(0, ylim)\n    plt.title(\n        f\"female ({100 * len(female_df) / len(df):.1f}%)\",\n        fontsize=fs,\n        loc=\"right\",\n        y=1,\n        x=0.95,\n    )\n    plt.ylim(0, 100)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    plt.ylabel(\"age [years]\", fontsize=fs)\n    plt.xlabel(\"count\", fontsize=fs, x=1, labelpad=20)\n    plt.yticks(np.linspace(0, 100, 11), fontsize=fs - 5)\n    plt.tick_params(labelsize=fs - 5)\n\n    plt.show()\n\n\ndf = tuh.description\nplt_histogram(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing\n\n### Selecting recordings\n\nFirst, we will do some selection of available recordings based on the duration.\nWe will select those recordings that have at least five minutes duration.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def select_by_duration(ds, tmin=0, tmax=None):\n    if tmax is None:\n        tmax = np.inf\n    # determine length of the recordings and select based on tmin and tmax\n    split_ids = []\n    for d_i, d in enumerate(ds.datasets):\n        duration = d.raw.n_times / d.raw.info[\"sfreq\"]\n        # select the ones in the required duration range\n        if tmin <= duration <= tmax:\n            split_ids.append(d_i)\n    splits = ds.split(split_ids)\n    split = splits[\"0\"]\n    return split\n\n\ntmin = 5 * 60\ntmax = None\ntuh = select_by_duration(tuh, tmin, tmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will discard all recordings that have an incomplete channel\nconfiguration on the channels that we are interested.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "short_ch_names = sorted(\n    [\n        \"A1\",\n        \"A2\",\n        \"Fp1\",\n        \"Fp2\",\n        \"F3\",\n        \"F4\",\n        \"C3\",\n        \"C4\",\n        \"P3\",\n        \"P4\",\n        \"O1\",\n        \"O2\",\n        \"F7\",\n        \"F8\",\n        \"T3\",\n        \"T4\",\n        \"T5\",\n        \"T6\",\n        \"Fz\",\n        \"Cz\",\n        \"Pz\",\n    ]\n)\n\n\ndef select_by_channels(ds, ch_names):\n    # these are the channels we are looking for\n    seta = set(ch_names)\n    split_ids = []\n    for i, d in enumerate(ds.datasets):\n        # these are the channels of the recoding\n        setb = set(d.raw.ch_names)\n        # if recording contains all channels we are looking for, include it\n        if seta.issubset(setb):\n            split_ids.append(i)\n    return ds.split(split_ids)[\"0\"]\n\n\ntuh = select_by_channels(tuh, short_ch_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combining preprocessing steps\n\nNext, we use braindecode's preprocess to combine and execute several preprocessing\nsteps that are executed through 'mne':\n\n- Crop the recordings to a region of interest\n- Re-reference all recordings to 'ar' (requires load)\n- Pick channels of interest\n- Scale signals to micro volts (requires load)\n- Clip outlier values to +/- 800 micro volts (requires load)\n- Resample recordings to a common frequency (requires load)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n    # crop recordings to tmin \u2013 tmax. can be incomplete if recording\n    # has lower duration than tmax\n    # by default mne fails if tmax is bigger than duration\n    tmax = min((raw.n_times - 1) / raw.info[\"sfreq\"], tmax)\n    raw.crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n\n\ntmin = 1 * 60\ntmax = 6 * 60\nsfreq = 100\nfactor = 1e6\n\npreprocessors = [\n    Preprocessor(\n        custom_crop, tmin=tmin, tmax=tmax, include_tmax=False, apply_on_array=False\n    ),\n    Preprocessor(\"set_eeg_reference\", ref_channels=\"average\", ch_type=\"eeg\"),\n    Preprocessor(\"pick_channels\", ch_names=short_ch_names, ordered=True),\n    Preprocessor(\n        lambda data: multiply(data, factor), apply_on_array=True\n    ),  # Convert from V to uV\n    Preprocessor(lambda x: np.clip(x, a_min=-800, a_max=800), apply_on_array=True),\n    Preprocessor(\"resample\", sfreq=sfreq),\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we can apply the defined preprocessors on the selected recordings in parallel.\nWe additionally use the serialization functionality of\n:func:`braindecode.preprocessing.preprocess` to limit memory usage during\npreprocessing, as each file must be loaded into memory for some of the\npreprocessing steps to work.\nThis also makes it possible to use the lazy\nloading capabilities of :class:`braindecode.datasets.BaseConcatDataset`, as\nthe preprocessed data is automatically reloaded with ``preload=False``.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Here we use ``n_jobs=2`` as the machines the documentation is build on\n   only have two cores. This number should be modified based on the machine\n   that is available for preprocessing.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "OUT_PATH = tempfile.mkdtemp()  # please insert actual output directory here\ntuh_preproc = preprocess(\n    concat_ds=tuh, preprocessors=preprocessors, n_jobs=N_JOBS, save_dir=OUT_PATH\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cut Compute Windows\nWe can finally generate compute windows. The resulting dataset is now ready\nto be used for model training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "window_size_samples = 1000\nwindow_stride_samples = 1000\n# Generate compute windows here and store them to disk\ntuh_windows = create_fixed_length_windows(\n    tuh_preproc,\n    window_size_samples=window_size_samples,\n    window_stride_samples=window_stride_samples,\n    drop_last_window=False,\n    n_jobs=N_JOBS,\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}