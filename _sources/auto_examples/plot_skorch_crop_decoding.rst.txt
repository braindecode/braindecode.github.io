.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_skorch_crop_decoding.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_examples_plot_skorch_crop_decoding.py:


Skorch Crop Decoding
=========================

Example using Skorch for crop decoding on a simpler dataset.




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Using default location ~/mne_data for EEGBCI...
    Downloading http://www.physionet.org/physiobank/database/eegmmidb/S022/S022R05.edf (2.5 MB)

    Using default location ~/mne_data for EEGBCI...
    Downloading http://www.physionet.org/physiobank/database/eegmmidb/S022/S022R06.edf (2.5 MB)

    Using default location ~/mne_data for EEGBCI...
    Downloading http://www.physionet.org/physiobank/database/eegmmidb/S022/S022R09.edf (2.5 MB)

    Using default location ~/mne_data for EEGBCI...
    Downloading http://www.physionet.org/physiobank/database/eegmmidb/S022/S022R10.edf (2.5 MB)

    Using default location ~/mne_data for EEGBCI...
    Downloading http://www.physionet.org/physiobank/database/eegmmidb/S022/S022R13.edf (2.5 MB)

    Using default location ~/mne_data for EEGBCI...
    Downloading http://www.physionet.org/physiobank/database/eegmmidb/S022/S022R14.edf (2.5 MB)

    Used Annotations descriptions: ['T0', 'T1', 'T2']
    90 matching events found
    No baseline correction applied
    Not setting metadata
    Loading data for 90 events and 497 original time points ...
    0 bad epochs dropped
      epoch    train_loss    train_trial_accuracy    valid_loss    valid_trial_accuracy     dur
    -------  ------------  ----------------------  ------------  ----------------------  ------
          1        [36m1.3460[0m                  [32m0.8250[0m        [35m0.7710[0m                  [31m0.6333[0m  0.7916
          2        [36m0.6674[0m                  [32m0.9000[0m        [35m0.6395[0m                  0.6333  0.6393
          3        [36m0.3789[0m                  [32m0.9250[0m        [35m0.5846[0m                  [31m0.7000[0m  0.6649
          4        [36m0.3279[0m                  [32m0.9500[0m        [35m0.5263[0m                  [31m0.7667[0m  0.6310

    array([[8, 0],
           [0, 5],
           [8, 0],
           [6, 2],
           [8, 1],
           [8, 3],
           [3, 8],
           [0, 8],
           [8, 5],
           [7, 0],
           [0, 8],
           [4, 0],
           [8, 0],
           [8, 0],
           [0, 8],
           [0, 8],
           [1, 7],
           [0, 6],
           [8, 0],
           [2, 8]])





|


.. code-block:: default


    # Authors: Lukas Gemein
    #          Robin Tibor Schirrmeister
    #          Alexandre Gramfort
    #          Maciej Sliwowski
    #
    # License: BSD-3

    import mne
    import numpy as np
    import torch
    from mne.io import concatenate_raws
    from torch import optim

    from braindecode.classifier import EEGClassifier
    from braindecode.datasets.croppedxy import CroppedXyDataset
    from braindecode.datautil.splitters import TrainTestSplit
    from braindecode.losses import CroppedNLLLoss
    from braindecode.models import ShallowFBCSPNet
    from braindecode.models.util import to_dense_prediction_model
    from braindecode.scoring import CroppedTrialEpochScoring
    from braindecode.util import set_random_seeds

    subject_id = (
        22  # carefully cherry-picked to give nice results on such limited data :)
    )
    event_codes = [
        5,
        6,
        9,
        10,
        13,
        14,
    ]  # codes for executed and imagined hands/feet

    # This will download the files if you don't have them yet,
    # and then return the paths to the files.
    physionet_paths = mne.datasets.eegbci.load_data(
        subject_id, event_codes, update_path=False
    )

    # Load each of the files
    raws = [
        mne.io.read_raw_edf(
            path, preload=True, stim_channel="auto", verbose="WARNING"
        )
        for path in physionet_paths
    ]

    # Concatenate them
    raw = concatenate_raws(raws)
    del raws

    # Find the events in this dataset
    events, _ = mne.events_from_annotations(raw)

    # Use only EEG channels
    picks = mne.pick_types(raw.info, meg=False, eeg=True, exclude="bads")

    # Extract trials, only using EEG channels
    epochs = mne.Epochs(
        raw,
        events,
        event_id=dict(hands_or_left=2, feet_or_right=3),
        tmin=1,
        tmax=4.1,
        proj=False,
        picks=picks,
        baseline=None,
        preload=True,
    )

    X = (epochs.get_data() * 1e6).astype(np.float32)
    y = (epochs.events[:, 2] - 2).astype(np.int64)  # 2,3 -> 0,1
    del epochs

    # Set if you want to use GPU
    # You can also use torch.cuda.is_available() to determine if cuda is available on your machine.
    cuda = False
    set_random_seeds(seed=20170629, cuda=cuda)
    n_classes = 2
    in_chans = X.shape[1]



    set_random_seeds(20200114, cuda=False)

    # final_conv_length = auto ensures we only get a single output in the time dimension
    model = ShallowFBCSPNet(
        in_chans=in_chans,
        n_classes=n_classes,
        input_time_length=X.shape[2],
        final_conv_length="auto",
    )
    to_dense_prediction_model(model)
    if cuda:
        model.cuda()

    input_time_length = X.shape[2]

    # Perform forward pass to determine how many outputs per input
    with torch.no_grad():
        dummy_input = torch.tensor(X[:1, :, :input_time_length, None], device="cpu")
        n_preds_per_input = model(dummy_input).shape[2]


    train_set = CroppedXyDataset(X[:70], y[:70],
                           input_time_length=input_time_length,
                           n_preds_per_input=n_preds_per_input)
    test_set = CroppedXyDataset(X[70:], y=y[70:],
                          input_time_length=input_time_length,
                          n_preds_per_input=n_preds_per_input)

    cropped_cb_train = CroppedTrialEpochScoring(
        "accuracy",
        on_train=True,
        name="train_trial_accuracy",
        lower_is_better=False,
    )

    cropped_cb_valid = CroppedTrialEpochScoring(
        "accuracy",
        on_train=False,
        name="valid_trial_accuracy",
        lower_is_better=False,
    )

    clf = EEGClassifier(
        model,
        criterion=CroppedNLLLoss,
        optimizer=optim.AdamW,
        train_split=TrainTestSplit(
            train_size=40,
            input_time_length=input_time_length,
            n_preds_per_input=n_preds_per_input,),
        optimizer__lr=0.0625 * 0.01,
        optimizer__weight_decay=0,
        batch_size=64,
        callbacks=[
            ("train_trial_accuracy", cropped_cb_train),
            ("valid_trial_accuracy", cropped_cb_valid),
        ],
    )

    clf.fit(train_set, y=None, epochs=4)
    clf.predict(test_set)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  5.641 seconds)

**Estimated memory usage:**  826 MB


.. _sphx_glr_download_auto_examples_plot_skorch_crop_decoding.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_skorch_crop_decoding.py <plot_skorch_crop_decoding.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_skorch_crop_decoding.ipynb <plot_skorch_crop_decoding.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
