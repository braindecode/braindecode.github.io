.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_skorch_crop_decoding.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_examples_plot_skorch_crop_decoding.py:


Skorch Crop Decoding
=========================

Example using Skorch for crop decoding on a simpler dataset.




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Using default location ~/mne_data for EEGBCI...
    Using default location ~/mne_data for EEGBCI...
    Using default location ~/mne_data for EEGBCI...
    Using default location ~/mne_data for EEGBCI...
    Using default location ~/mne_data for EEGBCI...
    Using default location ~/mne_data for EEGBCI...
    Used Annotations descriptions: ['T0', 'T1', 'T2']
    90 matching events found
    No baseline correction applied
    Not setting metadata
    Loading data for 90 events and 497 original time points ...
    0 bad epochs dropped
      epoch    train_accuracy    train_loss    valid_accuracy    valid_loss     dur
    -------  ----------------  ------------  ----------------  ------------  ------
          1            [36m0.6333[0m        [32m1.3460[0m            [35m0.6333[0m        [31m0.7710[0m  0.7327
          2            [36m0.7000[0m        [32m0.5877[0m            [35m0.7000[0m        [31m0.5442[0m  0.6729
          3            [36m0.7333[0m        [32m0.5167[0m            [35m0.7333[0m        [31m0.5152[0m  0.6463
          4            [36m0.7667[0m        [32m0.3726[0m            [35m0.7667[0m        0.5246  0.6969

    array([[8, 0],
           [1, 5],
           [8, 5],
           [8, 1],
           [0, 8],
           [8, 3],
           [3, 8],
           [0, 8],
           [8, 4],
           [8, 0],
           [0, 8],
           [4, 0],
           [8, 0],
           [8, 3],
           [0, 8],
           [0, 8],
           [1, 7],
           [0, 6],
           [8, 0],
           [2, 8]])





|


.. code-block:: default


    # Authors: Lukas Gemein
    #          Robin Tibor Schirrmeister
    #          Alexandre Gramfort
    #          Maciej Sliwowski
    #
    # License: BSD-3

    import mne
    import numpy as np
    from mne.io import concatenate_raws
    from torch import optim

    from braindecode.classifier import EEGClassifier
    from braindecode.datasets.croppedxy import CroppedXyDataset
    from braindecode.datautil.splitters import TrainTestSplit
    from braindecode.losses import CroppedNLLLoss
    from braindecode.models import ShallowFBCSPNet
    from braindecode.models.util import to_dense_prediction_model, get_output_shape
    from braindecode.scoring import CroppedTrialEpochScoring
    from braindecode.util import set_random_seeds

    subject_id = (
        22  # carefully cherry-picked to give nice results on such limited data :)
    )
    event_codes = [
        5,
        6,
        9,
        10,
        13,
        14,
    ]  # codes for executed and imagined hands/feet

    # This will download the files if you don't have them yet,
    # and then return the paths to the files.
    physionet_paths = mne.datasets.eegbci.load_data(
        subject_id, event_codes, update_path=False
    )

    # Load each of the files
    raws = [
        mne.io.read_raw_edf(
            path, preload=True, stim_channel="auto", verbose="WARNING"
        )
        for path in physionet_paths
    ]

    # Concatenate them
    raw = concatenate_raws(raws)
    del raws

    # Find the events in this dataset
    events, _ = mne.events_from_annotations(raw)

    # Use only EEG channels
    picks = mne.pick_types(raw.info, meg=False, eeg=True, exclude="bads")

    # Extract trials, only using EEG channels
    epochs = mne.Epochs(
        raw,
        events,
        event_id=dict(hands_or_left=2, feet_or_right=3),
        tmin=1,
        tmax=4.1,
        proj=False,
        picks=picks,
        baseline=None,
        preload=True,
    )

    X = (epochs.get_data() * 1e6).astype(np.float32)
    y = (epochs.events[:, 2] - 2).astype(np.int64)  # 2,3 -> 0,1
    del epochs

    # Set if you want to use GPU
    # You can also use torch.cuda.is_available() to determine if cuda is available on your machine.
    cuda = False
    set_random_seeds(seed=20170629, cuda=cuda)
    n_classes = 2
    in_chans = X.shape[1]


    set_random_seeds(20200114, cuda=False)

    # final_conv_length = auto ensures we only get a single output in the time dimension
    model = ShallowFBCSPNet(
        in_chans=in_chans,
        n_classes=n_classes,
        input_time_length=X.shape[2],
        final_conv_length="auto",
    )
    to_dense_prediction_model(model)
    if cuda:
        model.cuda()

    input_time_length = X.shape[2]

    # Perform forward pass to determine how many outputs per input
    n_preds_per_input = get_output_shape(model, in_chans, input_time_length)[2]


    train_set = CroppedXyDataset(X[:70], y[:70],
                                 input_time_length=input_time_length,
                                 n_preds_per_input=n_preds_per_input)
    test_set = CroppedXyDataset(X[70:], y=y[70:],
                                input_time_length=input_time_length,
                                n_preds_per_input=n_preds_per_input)

    clf = EEGClassifier(
        model,
        cropped=True,
        criterion=CroppedNLLLoss,
        optimizer=optim.AdamW,
        train_split=TrainTestSplit(
            train_size=40,
            input_time_length=input_time_length,
            n_preds_per_input=n_preds_per_input,),
        optimizer__lr=0.0625 * 0.01,
        optimizer__weight_decay=0,
        batch_size=64,
        callbacks=['accuracy'],
    )

    clf.fit(train_set, y=None, epochs=4)
    clf.predict(test_set)


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  3.568 seconds)

**Estimated memory usage:**  892 MB


.. _sphx_glr_download_auto_examples_plot_skorch_crop_decoding.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_skorch_crop_decoding.py <plot_skorch_crop_decoding.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_skorch_crop_decoding.ipynb <plot_skorch_crop_decoding.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
