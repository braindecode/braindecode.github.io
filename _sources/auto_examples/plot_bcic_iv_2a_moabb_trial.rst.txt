.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_bcic_iv_2a_moabb_trial.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_examples_plot_bcic_iv_2a_moabb_trial.py:


Trialwise Decoding on BCIC IV 2a Dataset
========================================

This tutorial shows you how to train and test deep learning models with Braindecode.
Whole procedure is performed on
`MOABB BCI IV <http://moabb.neurotechx.com/docs/generated/moabb.datasets.BNCI2014001.html>`_
dataset. Braindeocde supplies infrastructure for loading, transforming and splitting all
MOABB datasets which is also briefly presented here. You can find more on this topic in
another tutorial.

This script presents a standard processing workflow using trialwise braindecode models.
It is also compatible with `PyTorch <https://pytorch.org/>`_ deep learning models created
by user. There are no additional constraints on model's implementations except being
valid PyTorch (it does not have to inherit from any additional class or implement any
additional method).

Trialwise decoding is one out of two ways of EEG signal processing implemented in
Braindecode. Main points of trialwise decoding:

1. A complete trial is pushed through the network.
2. The network produces a prediction.
3. The prediction is compared to the target (label) for that trial to compute the loss.

We supply some default parameters that we have found to work well for
motor decoding, however we strongly encourage you to perform your own hyperparameter
optimization using cross validation on your training data.


.. code-block:: default


    # Authors: Maciej Sliwowski <maciek.sliwowski@gmail.com>
    #          Robin Tibor Schirrmeister <robintibor@gmail.com>
    #          Lukas Gemein <l.gemein@gmail.com>
    #          Hubert Banville <hubert.jbanville@gmail.com>
    #
    # License: BSD-3
    from functools import partial

    import matplotlib.pyplot as plt
    import mne
    import numpy as np
    import pandas as pd
    import torch
    from matplotlib.lines import Line2D
    from skorch.callbacks import LRScheduler
    from skorch.helper import predefined_split

    from braindecode import EEGClassifier
    from braindecode.datasets import MOABBDataset
    from braindecode.datautil import create_windows_from_events
    from braindecode.datautil.preprocess import exponential_moving_standardize
    from braindecode.datautil.preprocess import preprocess, MNEPreproc, \
        NumpyPreproc
    from braindecode.models import ShallowFBCSPNet
    from braindecode.util import set_random_seeds

    mne.set_log_level('ERROR')








Script parameters definition
----------------------------


.. code-block:: default

    seed = 20200220  # random seed to make results reproducible

    # Parameters describing the dataset and transformations
    subject_id = 3  # 1-9
    low_cut_hz = 4.  # low cut frequency for filtering
    high_cut_hz = 38.  # high cut frequency for filtering
    n_classes = 4  # number of classes to predict
    n_chans = 22  # number of channels in the dataset
    trial_start_offset_seconds = -0.5  # offset between trail start in the raw data and dataset
    input_window_samples = 1125  # length of trial in samples
    # Parameters for exponential running standarization
    factor_new = 1e-3
    init_block_size = 1000

    # Define parameters describing training
    n_epochs = 5  # number of epochs of training
    batch_size = 64
    cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it
    device = 'cuda' if cuda else 'cpu'
    if cuda:
        torch.backends.cudnn.benchmark = True

    # Set random seed to be able to reproduce results
    set_random_seeds(seed=seed, cuda=cuda)








Create model
------------
Braindecode comes with some predefined convolutional neural network architectures for
raw time-domain EEG. Here, we use the shallow ConvNet model from
`Deep learning with convolutional neural networks for EEG decoding and visualization <https://arxiv.org/abs/1703.05051>`_.


.. code-block:: default


    model = ShallowFBCSPNet(
        n_chans,
        n_classes,
        input_window_samples=input_window_samples,
        final_conv_length='auto',
    )

    lr = 0.0625 * 0.01
    weight_decay = 0

    # Send model to GPU
    if cuda:
        model.cuda()








Load the dataset
--------------------------
Load `MOABB <https://github.com/NeuroTechX/moabb>`_ dataset using Braindecode datasets
functionalities.


.. code-block:: default

    dataset = MOABBDataset(dataset_name="BNCI2014001", subject_ids=[subject_id])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)
    /home/circleci/.local/lib/python3.7/site-packages/moabb/datasets/bnci.py:535: DeprecationWarning: Passing montage to create_info is deprecated and will be removed in 0.21, use raw.set_montage (or epochs.set_montage, etc.) instead
      ch_names=ch_names, ch_types=ch_types, sfreq=sfreq, montage=montage)




Define data preprocessing and preprocess the data
-------------------------------------------------
Transform steps are defined as 2 elements tuples of `(str | callable, dict)`
If the first element is string it has to be a name of
`mne.Raw <https://mne.tools/stable/generated/mne.io.Raw.html>`_/`mne.Epochs <https://mne.tools/0.11/generated/mne.Epochs.html#mne.Epochs>`_
method. The second element of a tuple defines method parameters.


.. code-block:: default


    preprocessors = [
        MNEPreproc(fn='pick_types', eeg=True, meg=False, stim=False), # keep only EEG sensors
        NumpyPreproc(fn=lambda x: x * 1e6), # convert from volt to microvolt, directly modifying the numpy array
        MNEPreproc(fn='filter', l_freq=low_cut_hz, h_freq=high_cut_hz), # bandpass filter
        NumpyPreproc(fn=exponential_moving_standardize, factor_new=factor_new,
                     init_block_size=init_block_size)
    ]

    # Transform the data
    preprocess(dataset, preprocessors)








Create windows from MOABB dataset
---------------------------------


.. code-block:: default


    # Extract sampling frequency from all datasets (in general they may be different for each
    # dataset).
    sfreqs = [ds.raw.info['sfreq'] for ds in dataset.datasets]
    assert len(np.unique(sfreqs)) == 1
    # Calculate the trial start offset in samples.
    trial_start_offset_samples = int(trial_start_offset_seconds * sfreqs[0])

    # Create windows using braindecode function for this. It needs parameters to define how
    # trials should be used.
    windows_dataset = create_windows_from_events(
        dataset,
        trial_start_offset_samples=trial_start_offset_samples,
        trial_stop_offset_samples=0,
        window_size_samples=input_window_samples,
        window_stride_samples=input_window_samples,
        drop_last_window=False,
        preload=True,
    )







Split dataset into train and valid
----------------------------------
We can easily split the dataset using additional info stored in the description
attribute, in this case `session` column. We select `session_T` for training and
`session_E` for validation.


.. code-block:: default

    splitted = windows_dataset.split('session')
    train_set = splitted['session_T']
    valid_set = splitted['session_E']








EEGClassifier definition and training
-------------------------------------
EEGClassifier is a Braindecode object responsible for managing the training of neural
networks. It inherits from `skorch.NeuralNetClassifier`, so the training logic is the
same as in `skorch <https://skorch.readthedocs.io/en/stable/index.html>`_.
EEGClassifier object takes all training hyperparameters, creates all callbacks and
performs training. Model supplied to this class has to be a PyTorch model.


.. code-block:: default

    clf = EEGClassifier(
        model,
        criterion=torch.nn.NLLLoss,
        optimizer=torch.optim.AdamW,
        train_split=predefined_split(valid_set),  # using valid_set for validation
        optimizer__lr=lr,
        optimizer__weight_decay=weight_decay,
        batch_size=batch_size,
        callbacks=[
            "accuracy", ("lr_scheduler", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),
        ],
        device=device,
    )
    # Model training for a specified number of epochs. `y` is None as it is already supplied
    # in the dataset.
    clf.fit(windows_dataset, y=None, epochs=n_epochs)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/circleci/.local/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
      warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
      epoch    train_accuracy    train_loss    valid_accuracy    valid_loss     dur
    -------  ----------------  ------------  ----------------  ------------  ------
          1            [36m0.2569[0m        [32m1.5211[0m            [35m0.2535[0m        [31m6.5564[0m  7.2684
          2            [36m0.3715[0m        [32m1.1702[0m            [35m0.3715[0m        [31m3.8837[0m  6.4208
          3            0.3351        [32m0.9766[0m            0.3299        [31m2.5528[0m  6.3135
          4            [36m0.4149[0m        [32m0.8462[0m            [35m0.4271[0m        [31m1.5158[0m  6.1161
          5            [36m0.6024[0m        [32m0.8309[0m            [35m0.6007[0m        [31m0.9143[0m  6.0590

    <class 'braindecode.classifier.EEGClassifier'>[initialized](
      module_=ShallowFBCSPNet(
        (ensuredims): Ensure4d()
        (dimshuffle): Expression(expression=transpose_time_to_spat) 
        (conv_time): Conv2d(1, 40, kernel_size=(25, 1), stride=(1, 1))
        (conv_spat): Conv2d(40, 40, kernel_size=(1, 22), stride=(1, 1), bias=False)
        (bnorm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_nonlin_exp): Expression(expression=square) 
        (pool): AvgPool2d(kernel_size=(75, 1), stride=(15, 1), padding=0)
        (pool_nonlin_exp): Expression(expression=safe_log) 
        (drop): Dropout(p=0.5, inplace=False)
        (conv_classifier): Conv2d(40, 4, kernel_size=(69, 1), stride=(1, 1))
        (softmax): LogSoftmax()
        (squeeze): Expression(expression=squeeze_final_output) 
      ),
    )



Plot Results
-------------


.. code-block:: default


    # Extract loss and accuracy values for plotting from history object
    results_columns = ['train_loss', 'valid_loss', 'train_accuracy', 'valid_accuracy']
    df = pd.DataFrame(clf.history[:, results_columns], columns=results_columns,
                      index=clf.history[:, 'epoch'])

    # get percent of misclass for better visual comparison to loss
    df = df.assign(train_misclass=100 - 100 * df.train_accuracy,
                   valid_misclass=100 - 100 * df.valid_accuracy)

    plt.style.use('seaborn')
    fig, ax1 = plt.subplots(figsize=(8, 3))
    df.loc[:, ['train_loss', 'valid_loss']].plot(
        ax=ax1, style=['-', ':'], marker='o', color='tab:blue', legend=False, fontsize=14)

    ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)
    ax1.set_ylabel("Loss", color='tab:blue', fontsize=14)

    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis

    df.loc[:, ['train_misclass', 'valid_misclass']].plot(
        ax=ax2, style=['-', ':'], marker='o', color='tab:red', legend=False)
    ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)
    ax2.set_ylabel("Misclassification Rate [%]", color='tab:red', fontsize=14)
    ax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend
    ax1.set_xlabel("Epoch", fontsize=14)

    # where some data has already been plotted to ax
    handles = []
    handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))
    handles.append(Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))
    plt.legend(handles, [h.get_label() for h in handles], fontsize=14)
    plt.tight_layout()



.. image:: /auto_examples/images/sphx_glr_plot_bcic_iv_2a_moabb_trial_001.png
    :alt: plot bcic iv 2a moabb trial
    :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  6.750 seconds)

**Estimated memory usage:**  1585 MB


.. _sphx_glr_download_auto_examples_plot_bcic_iv_2a_moabb_trial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_bcic_iv_2a_moabb_trial.py <plot_bcic_iv_2a_moabb_trial.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_bcic_iv_2a_moabb_trial.ipynb <plot_bcic_iv_2a_moabb_trial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
