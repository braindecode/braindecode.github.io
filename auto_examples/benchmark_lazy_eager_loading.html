

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Benchmarking eager and lazy loading &mdash; Braindecode 0.5 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-rendered-html.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Self-supervised learning on EEG with relative positioning" href="plot_relative_positioning.html" />
    <link rel="prev" title="Process a big data EEG resource (TUH EEG Corpus)" href="tuh_eeg_corpus.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Braindecode
          

          
          </a>

          
            
            
              <div class="version">
                0.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="plot_bcic_iv_2a_moabb_trial.html"> Basic trialwise decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_bcic_iv_2a_moabb_cropped.html"> More data-efficient &quot;cropped decoding&quot;</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_mne_dataset_example.html"> Your own datasets through MNE</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_custom_dataset_example.html"> Your own datasets through Numpy</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Braindecode examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="plot_split_dataset.html">Split Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_custom_dataset_example.html">Custom Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_load_save_datasets.html">Load and save dataset example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_mne_dataset_example.html">MNE Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_dataset_example.html">MOABB Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_regression.html">Regression example on fake data</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sleep_staging.html">Sleep staging on the Sleep Physionet dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_bcic_iv_2a_moabb_trial.html">Trialwise Decoding on BCIC IV 2a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_bcic_iv_2a_moabb_cropped.html">Cropped Decoding on BCIC IV 2a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="tuh_eeg_corpus.html">Process a big data EEG resource (TUH EEG Corpus)</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Benchmarking eager and lazy loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_relative_positioning.html">Self-supervised learning on EEG with relative positioning</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Reference</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../whats_new.html">What’s new</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Braindecode</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Braindecode examples</a> &raquo;</li>
        
      <li>Benchmarking eager and lazy loading</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/auto_examples/benchmark_lazy_eager_loading.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-benchmark-lazy-eager-loading-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="benchmarking-eager-and-lazy-loading">
<span id="sphx-glr-auto-examples-benchmark-lazy-eager-loading-py"></span><h1>Benchmarking eager and lazy loading<a class="headerlink" href="#benchmarking-eager-and-lazy-loading" title="Permalink to this headline">¶</a></h1>
<p>In this example, we compare the execution time and memory requirements of 1)
eager loading, i.e., preloading the entire data into memory and 2) lazy loading,
i.e., only loading examples from disk when they are required. We also include
some other experiment parameters in the comparison for the sake of completeness
(e.g., <cite>num_workers</cite>, <cite>cuda</cite>, <cite>batch_size</cite>, etc.).</p>
<p>While eager loading might be required for some preprocessing steps that require
continuous data (e.g., temporal filtering, resampling), it also allows
fast access to the data during training. However, this might come at the expense
of large memory usage, and can ultimately become impossible if the dataset does
not fit into memory (e.g., the TUH EEG dataset’s &gt;1,5 TB of recordings will
not fit in the memory of most machines).</p>
<p>Lazy loading avoids this potential memory issue by loading examples from disk
when they are required. This means large datasets can be used for training,
however this introduces some file-reading overhead every time an example must
be extracted. Some preprocessing steps that require continuous data also have to
be implemented differently to accomodate the nature of windowed data. Overall
though, we can reduce the impact of lazy loading by using the <cite>num_workers</cite>
parameter of pytorch’s <cite>Dataloader</cite> class, which dispatches the data loading to
multiple processes.</p>
<p>To enable lazy loading in braindecode, data files must be saved in an
MNE-compatible format (e.g., ‘fif’, ‘edf’, etc.), and the <cite>Dataset</cite> object must
have been instantiated with parameter <cite>preload=False</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Hubert Banville &lt;hubert.jbanville@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD (3-clause)</span>

<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/itertools.html#itertools.product" title="itertools.product" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">product</span></a>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">braindecode.datasets</span> <span class="kn">import</span> <a href="../generated/braindecode.datasets.TUHAbnormal.html#braindecode.datasets.TUHAbnormal" title="braindecode.datasets.TUHAbnormal" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TUHAbnormal</span></a>
<span class="kn">from</span> <span class="nn">braindecode.datautil.windowers</span> <span class="kn">import</span> <a href="../generated/braindecode.datautil.create_fixed_length_windows.html#braindecode.datautil.create_fixed_length_windows" title="braindecode.datautil.create_fixed_length_windows" class="sphx-glr-backref-module-braindecode-datautil sphx-glr-backref-type-py-function"><span class="n">create_fixed_length_windows</span></a>
<span class="kn">from</span> <span class="nn">braindecode.models</span> <span class="kn">import</span> <a href="../generated/braindecode.models.ShallowFBCSPNet.html#braindecode.models.ShallowFBCSPNet" title="braindecode.models.ShallowFBCSPNet" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ShallowFBCSPNet</span></a><span class="p">,</span> <a href="../generated/braindecode.models.Deep4Net.html#braindecode.models.Deep4Net" title="braindecode.models.Deep4Net" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Deep4Net</span></a>


<a href="https://mne.tools/stable/generated/mne.set_log_level.html#mne.set_log_level" title="mne.set_log_level" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">set_log_level</span></a><span class="p">(</span><span class="s1">&#39;WARNING&#39;</span><span class="p">)</span>  <span class="c1"># avoid messages everytime a window is extracted</span>
</pre></div>
</div>
<p>We start by setting two pytorch internal parameters that can affect the
comparison:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">..</span> <span class="n">GENERATED</span> <span class="n">FROM</span> <span class="n">PYTHON</span> <span class="n">SOURCE</span> <span class="n">LINES</span> <span class="mi">57</span><span class="o">-</span><span class="mi">61</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_JOBS</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Enables automatic algorithm optimizations</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">(</span><span class="n">N_JOBS</span><span class="p">)</span>  <span class="c1"># Sets the available number of threads</span>
</pre></div>
</div>
<p>Next, we define a few functions to automate the benchmarking.
For the purpose of this example, we load some recordings from the TUH Abnormal
corpus, extract sliding windows, and bundle them in a braindecode Dataset.
We then train a neural network for a few epochs.</p>
<p>Each one of these steps will be timed, so we can report the total time taken
to prepare the data and train the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_example_data</span><span class="p">(</span><span class="n">preload</span><span class="p">,</span> <span class="n">window_len_s</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create windowed dataset from subjects of the TUH Abnormal dataset.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    preload: bool</span>
<span class="sd">        If True, use eager loading, otherwise use lazy loading.</span>
<span class="sd">    n_subjects: int</span>
<span class="sd">        Number of subjects to load.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    windows_ds: BaseConcatDataset</span>
<span class="sd">        Windowed data.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        The recordings from the TUH Abnormal corpus do not all share the same</span>
<span class="sd">        sampling rate. The following assumes that the files have already been</span>
<span class="sd">        resampled to a common sampling rate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">subject_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_subjects</span><span class="p">))</span>
    <span class="n">ds</span> <span class="o">=</span> <a href="../generated/braindecode.datasets.TUHAbnormal.html#braindecode.datasets.TUHAbnormal" title="braindecode.datasets.TUHAbnormal" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TUHAbnormal</span></a><span class="p">(</span>
        <span class="n">TUH_PATH</span><span class="p">,</span> <span class="n">subject_ids</span><span class="o">=</span><span class="n">subject_ids</span><span class="p">,</span> <span class="n">target_name</span><span class="o">=</span><span class="s1">&#39;pathological&#39;</span><span class="p">,</span>
        <span class="n">preload</span><span class="o">=</span><span class="n">preload</span><span class="p">)</span>

    <span class="n">fs</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;sfreq&#39;</span><span class="p">]</span>
    <span class="n">window_len_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fs</span> <span class="o">*</span> <span class="n">window_len_s</span><span class="p">)</span>
    <span class="n">window_stride_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fs</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
    <span class="c1"># window_stride_samples = int(fs * window_len_s)</span>
    <span class="n">windows_ds</span> <span class="o">=</span> <a href="../generated/braindecode.datautil.create_fixed_length_windows.html#braindecode.datautil.create_fixed_length_windows" title="braindecode.datautil.create_fixed_length_windows" class="sphx-glr-backref-module-braindecode-datautil sphx-glr-backref-type-py-function"><span class="n">create_fixed_length_windows</span></a><span class="p">(</span>
        <span class="n">ds</span><span class="p">,</span> <span class="n">start_offset_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stop_offset_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">window_size_samples</span><span class="o">=</span><span class="n">window_len_samples</span><span class="p">,</span>
        <span class="n">window_stride_samples</span><span class="o">=</span><span class="n">window_stride_samples</span><span class="p">,</span> <span class="n">drop_last_window</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">preload</span><span class="o">=</span><span class="n">preload</span><span class="p">,</span> <span class="n">drop_bad_windows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Drop bad epochs</span>
    <span class="c1"># XXX: This could be parallelized.</span>
    <span class="c1"># XXX: Also, this could be implemented in the Dataset object itself.</span>
    <span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">windows_ds</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">drop_bad</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">ds</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">preload</span> <span class="o">==</span> <span class="n">preload</span>

    <span class="k">return</span> <span class="n">windows_ds</span>


<span class="k">def</span> <span class="nf">create_example_model</span><span class="p">(</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">window_len_samples</span><span class="p">,</span>
                         <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;shallow&#39;</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Create model, loss and optimizer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_channels : int</span>
<span class="sd">        Number of channels in the input</span>
<span class="sd">    n_times : int</span>
<span class="sd">        Window length in the input</span>
<span class="sd">    n_classes : int</span>
<span class="sd">        Number of classes in the output</span>
<span class="sd">    kind : str</span>
<span class="sd">        &#39;shallow&#39; or &#39;deep&#39;</span>
<span class="sd">    cuda : bool</span>
<span class="sd">        If True, move the model to a CUDA device.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    model : torch.nn.Module</span>
<span class="sd">        Model to train.</span>
<span class="sd">    loss :</span>
<span class="sd">        Loss function</span>
<span class="sd">    optimizer :</span>
<span class="sd">        Optimizer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;shallow&#39;</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <a href="../generated/braindecode.models.ShallowFBCSPNet.html#braindecode.models.ShallowFBCSPNet" title="braindecode.models.ShallowFBCSPNet" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ShallowFBCSPNet</span></a><span class="p">(</span>
            <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">input_window_samples</span><span class="o">=</span><span class="n">window_len_samples</span><span class="p">,</span>
            <span class="n">n_filters_time</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">filter_time_length</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">n_filters_spat</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
            <span class="n">pool_time_length</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">pool_time_stride</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">final_conv_length</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
            <span class="n">split_first_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_norm_alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;deep&#39;</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <a href="../generated/braindecode.models.Deep4Net.html#braindecode.models.Deep4Net" title="braindecode.models.Deep4Net" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Deep4Net</span></a><span class="p">(</span>
            <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">input_window_samples</span><span class="o">=</span><span class="n">window_len_samples</span><span class="p">,</span>
            <span class="n">final_conv_length</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">n_filters_time</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">n_filters_spat</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
            <span class="n">filter_time_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pool_time_length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pool_time_stride</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">n_filters_2</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">filter_length_2</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_filters_3</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">filter_length_3</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_filters_4</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">filter_length_4</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">first_pool_mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">later_pool_mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">double_time_convs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">split_first_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_norm_alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">stride_before_pool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span>


<span class="k">def</span> <span class="nf">run_training</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Run training loop.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : torch.nn.Module</span>
<span class="sd">        Model to train.</span>
<span class="sd">    dataloader : torch.utils.data.Dataloader</span>
<span class="sd">        Data loader which will serve examples to the model during training.</span>
<span class="sd">    loss :</span>
<span class="sd">        Loss function.</span>
<span class="sd">    optimizer :</span>
<span class="sd">        Optimizer.</span>
<span class="sd">    n_epochs : int</span>
<span class="sd">        Number of epochs to train the model for.</span>
<span class="sd">    cuda : bool</span>
<span class="sd">        If True, move X and y to CUDA device.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    model : torch.nn.Module</span>
<span class="sd">        Trained model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="n">loss_vals</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">_</span>  <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

            <span class="n">loss_val</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">loss_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_val</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="n">loss_val</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s1"> - mean training loss: </span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><span class="n">loss_vals</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>Next, we define the different hyperparameters that we want to compare:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">PRELOAD</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>  <span class="c1"># True -&gt; eager loading; False -&gt; lazy loading</span>
<span class="n">N_SUBJECTS</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">]</span>  <span class="c1"># Number of recordings to load from the TUH Abnormal corpus</span>
<span class="n">WINDOW_LEN_S</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>  <span class="c1"># Window length, in seconds</span>
<span class="n">N_EPOCHS</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># Number of epochs to train the model for</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">]</span>  <span class="c1"># Training minibatch size</span>
<span class="n">MODEL</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;shallow&#39;</span><span class="p">,</span> <span class="s1">&#39;deep&#39;</span><span class="p">]</span>

<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># number of processes used by pytorch&#39;s Dataloader</span>
<span class="n">PIN_MEMORY</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>  <span class="c1"># whether to use pinned memory</span>
<span class="n">CUDA</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>  <span class="c1"># whether to use a CUDA device</span>

<span class="n">N_REPETITIONS</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1">#3 # Number of times to repeat the experiment (to get better time estimates)</span>
</pre></div>
</div>
<p>The following path needs to be changed to your local folder containing the
TUH Abnormal corpus:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TUH_PATH</span> <span class="o">=</span> <span class="s1">&#39;/storage/store/data/tuh_eeg/www.isip.piconepress.com/projects/tuh_eeg/downloads/tuh_eeg_abnormal/v2.0.0/edf/&#39;</span>
</pre></div>
</div>
<p>We can finally cycle through all the different combinations of the parameters
we set above to evaluate their execution time:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">all_results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">preload</span><span class="p">,</span> <span class="n">n_subjects</span><span class="p">,</span> <span class="n">win_len_s</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">model_kind</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/itertools.html#itertools.product" title="itertools.product" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">product</span></a><span class="p">(</span>
            <span class="nb">range</span><span class="p">(</span><span class="n">N_REPETITIONS</span><span class="p">),</span> <span class="n">PRELOAD</span><span class="p">,</span> <span class="n">N_SUBJECTS</span><span class="p">,</span> <span class="n">WINDOW_LEN_S</span><span class="p">,</span> <span class="n">N_EPOCHS</span><span class="p">,</span>
            <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">MODEL</span><span class="p">,</span> <span class="n">NUM_WORKERS</span><span class="p">,</span> <span class="n">PIN_MEMORY</span><span class="p">,</span> <span class="n">CUDA</span><span class="p">):</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;repetition&#39;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
        <span class="s1">&#39;preload&#39;</span><span class="p">:</span> <span class="n">preload</span><span class="p">,</span>
        <span class="s1">&#39;n_subjects&#39;</span><span class="p">:</span> <span class="n">n_subjects</span><span class="p">,</span>
        <span class="s1">&#39;win_len_s&#39;</span><span class="p">:</span> <span class="n">win_len_s</span><span class="p">,</span>
        <span class="s1">&#39;n_epochs&#39;</span><span class="p">:</span> <span class="n">n_epochs</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
        <span class="s1">&#39;model_kind&#39;</span><span class="p">:</span> <span class="n">model_kind</span><span class="p">,</span>
        <span class="s1">&#39;num_workers&#39;</span><span class="p">:</span> <span class="n">num_workers</span><span class="p">,</span>
        <span class="s1">&#39;pin_memory&#39;</span><span class="p">:</span> <span class="n">pin_memory</span><span class="p">,</span>
        <span class="s1">&#39;cuda&#39;</span><span class="p">:</span> <span class="n">cuda</span>
    <span class="p">}</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Repetition </span><span class="si">{</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">N_REPETITIONS</span><span class="si">}</span><span class="s1">:</span><span class="se">\n</span><span class="si">{</span><span class="n">results</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># Load the dataset</span>
    <span class="n">data_loading_start</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_example_data</span><span class="p">(</span><span class="n">preload</span><span class="p">,</span> <span class="n">win_len_s</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="n">n_subjects</span><span class="p">)</span>
    <span class="n">data_loading_end</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>

    <span class="c1"># Create the data loader</span>
    <span class="n">training_setup_start</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">worker_init_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Instantiate model and optimizer</span>
    <span class="n">n_channels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">ch_names</span><span class="p">)</span>
    <span class="n">n_times</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">times</span><span class="p">)</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">create_example_model</span><span class="p">(</span>
        <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">n_times</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="n">model_kind</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="n">cuda</span><span class="p">)</span>
    <span class="n">training_setup_end</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>

    <span class="c1"># Start training loop</span>
    <span class="n">model_training_start</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="n">trained_model</span> <span class="o">=</span> <span class="n">run_training</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="n">cuda</span><span class="p">)</span>
    <span class="n">model_training_end</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>

    <span class="k">del</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">trained_model</span>

    <span class="c1"># Record timing results</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;data_preparation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_loading_end</span> <span class="o">-</span> <span class="n">data_loading_start</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;training_setup&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_setup_end</span> <span class="o">-</span> <span class="n">training_setup_start</span>
    <span class="n">results</span> <span class="p">[</span><span class="s1">&#39;model_training&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_training_end</span> <span class="o">-</span> <span class="n">model_training_start</span>
    <span class="n">all_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
<p>The results are formatted into a pandas DataFrame and saved locally as a CSV
file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_results</span><span class="p">)</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s1">&#39;lazy_vs_eager_loading_results.csv&#39;</span>
<span class="n">results_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Results saved under </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>We can finally summarize this information into the following plot:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">catplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">results_df</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;model_kind&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;model_training&#39;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;num_workers&#39;</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s1">&#39;preload&#39;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;strip&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The results of this comparison will change depending on the hyperparameters
that were set above, and on the actual hardware that is being used.</p>
</div>
<p>Generally speaking, we expect lazy loading to be slower than eager loading
during model training, but to potentially be pretty competitive if multiple
workers were enabled (i.e.., <cite>num_workers &gt; 0</cite>). Training on a CUDA device
should also yield substantial speedups.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.000 seconds)</p>
<p><strong>Estimated memory usage:</strong>  0 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-benchmark-lazy-eager-loading-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/2a53ed6bee60a29af3f760043d35ed09/benchmark_lazy_eager_loading.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">benchmark_lazy_eager_loading.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/25408d8d92a873e370d4750ba414b84a/benchmark_lazy_eager_loading.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">benchmark_lazy_eager_loading.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="plot_relative_positioning.html" class="btn btn-neutral float-right" title="Self-supervised learning on EEG with relative positioning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="tuh_eeg_corpus.html" class="btn btn-neutral float-left" title="Process a big data EEG resource (TUH EEG Corpus)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2018-2021, Braindecode developers.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>