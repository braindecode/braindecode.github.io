{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Process a big data EEG resource (TUH EEG Corpus)\n\nIn this example, we showcase usage of the Temple University Hospital EEG Corpus\n(https://www.isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml#c_tueg)\nincluding simple preprocessing steps as well as cutting of compute windows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Lukas Gemein <l.gemein@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport os\nimport tempfile\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nimport mne\n\nfrom braindecode.datasets import TUH\nfrom braindecode.preprocessing import preprocess, Preprocessor, create_fixed_length_windows, scale\nfrom braindecode.datautil.serialization import load_concat_dataset\n\nmne.set_log_level('ERROR')  # avoid messages everytime a window is extracted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want to try this code with the actual data, please delete the next\nsection. We are required to mock some dataset functionality, since the data\nis not available at creation time of this example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.datasets.tuh import _TUHMock as TUH  # noqa F811"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We start by creating a TUH dataset. First, the class generates a description\nof the recordings in `TUH_PATH` (which is later accessible as\n`tuh.description`) without actually touching the files. This will parse\ninformation from file paths such as patient id, recording data, etc and should\nbe really fast. Afterwards, the files are sorted chronologically by year,\nmonth, day, patient id, recording session and segment.\nIn the following, a subset of the description corresponding to `recording_ids`\nis used.\nAfterwards, the files will be iterated a second time, slower than before.\nThe files are now actually touched. Additional information about subjects\nlike age and gender are parsed directly from the EDF file header. If existent,\nthe physician report is added to the description. Furthermore, the recordings\nare read with `mne.io.read_raw_edf` with `preload=False`. Finally, we will get\na `BaseConcatDataset` of `BaseDatasets` each holding a single\n`nme.io.Raw` which is fully compatible with other braindecode functionalities.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "TUH_PATH = 'please insert actual path to data here'\ntuh = TUH(\n    path=TUH_PATH,\n    recording_ids=None,\n    target_name=None,\n    preload=False,\n    add_physician_reports=False,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can easily create descriptive statistics using the description `DataFrame`,\nfor example an age histogram split by gender of patients.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\ngenders = tuh.description.gender.unique()\nx = [tuh.description.age[tuh.description.gender == g] for g in genders]\nax.hist(\n    x=x,\n    stacked=True,\n    bins=np.arange(100, dtype=int),\n    alpha=.5,\n)\nax.legend(genders)\nax.set_xlabel('Age [years]')\nax.set_ylabel('Count')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will perform some preprocessing steps. First, we will do some\nselection of available recordings based on the duration. We will select those\nrecordings, that have at least five minutes duration. Data is not loaded here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def select_by_duration(ds, tmin=0, tmax=None):\n    # determine length of the recordings and select based on tmin and tmax\n    duration = ds.description.n_samples / ds.description.sfreq\n    duration = duration[duration >= tmin]\n    if tmax is None:\n        tmax = np.inf\n    duration = duration[duration <= tmax]\n    split_ids = list(duration.index)\n    splits = ds.split(split_ids)\n    split = splits['0']\n    return split\n\n\ntmin = 5 * 60\ntmax = None\ntuh = select_by_duration(tuh, tmin, tmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will discard all recordings that have an incomplete channel\nconfiguration (wrt the channels that we are interested in, i.e. the 21\nchannels of the international 10-20-placement). The dataset is subdivided into\nrecordings with 'le' and 'ar' reference which we will have to consider. Data\nis not loaded here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "short_ch_names = sorted([\n    'A1', 'A2',\n    'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2',\n    'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'FZ', 'CZ', 'PZ'])\nar_ch_names = sorted([\n    'EEG A1-REF', 'EEG A2-REF',\n    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF',\n    'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF',\n    'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF',\n    'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\nle_ch_names = sorted([\n    'EEG A1-LE', 'EEG A2-LE',\n    'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE',\n    'EEG C4-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE',\n    'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE',\n    'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE'])\nassert len(short_ch_names) == len(ar_ch_names) == len(le_ch_names)\nar_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n    ar_ch_names, short_ch_names)}\nle_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n    le_ch_names, short_ch_names)}\nch_mapping = {'ar': ar_ch_mapping, 'le': le_ch_mapping}\n\n\ndef select_by_channels(ds, ch_mapping):\n    split_ids = []\n    for i, d in enumerate(ds.datasets):\n        # these are the channels we are looking for\n        seta = set(ch_mapping[d.description.reference].keys())\n        # these are the channels of the recoding\n        setb = set(d.raw.ch_names)\n        # if recording contains all channels we are looking for, include it\n        if seta.issubset(setb):\n            split_ids.append(i)\n    return ds.split(split_ids)['0']\n\n\ntuh = select_by_channels(tuh, ch_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will chain several preprocessing steps that are realized through\n`mne`. Data will be loaded by the first preprocessor that has a mention of it\nin brackets:\n\n#. crop the recordings to a region of interest\n#. re-reference all recordings to 'ar' (requires load)\n#. rename channels to short channel names\n#. pick channels of interest\n#. scale signals to microvolts (requires load)\n#. clip outlier values to +/- 800 microvolts (requires load)\n#. resample recordings to a common frequency (requires load)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def custom_rename_channels(raw, mapping):\n    # rename channels which are dependent on referencing:\n    # le: EEG 01-LE, ar: EEG 01-REF\n    # mne fails if the mapping contains channels as keys that are not present\n    # in the raw\n    reference = raw.ch_names[0].split('-')[-1].lower()\n    assert reference in ['le', 'ref'], 'unexpected referencing'\n    reference = 'le' if reference == 'le' else 'ar'\n    raw.rename_channels(mapping[reference])\n\n\ndef custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n    # crop recordings to tmin \u2013 tmax. can be incomplete if recording\n    # has lower duration than tmax\n    # by default mne fails if tmax is bigger than duration\n    tmax = min((raw.n_times - 1) / raw.info['sfreq'], tmax)\n    raw.crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n\n\ntmin = 1 * 60\ntmax = 6 * 60\nsfreq = 100\n\npreprocessors = [\n    Preprocessor(custom_crop, tmin=tmin, tmax=tmax, include_tmax=False,\n                 apply_on_array=False),\n    Preprocessor('set_eeg_reference', ref_channels='average', ch_type='eeg'),\n    Preprocessor(custom_rename_channels, mapping=ch_mapping,\n                 apply_on_array=False),\n    Preprocessor('pick_channels', ch_names=short_ch_names, ordered=True),\n    Preprocessor(scale, factor=1e6, apply_on_array=True),\n    Preprocessor(np.clip, a_min=-800, a_max=800, apply_on_array=True),\n    Preprocessor('resample', sfreq=sfreq),\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The preprocessing loop works as follows. For every recording, we apply the\npreprocessors as defined above. Then, we update the description of the rec,\nsince we have altered the duration, the reference, and the sampling\nfrequency. Afterwards, we store each recording to a unique subdirectory that\nis named corresponding to the rec id. To save memory we delete the raw\ndataset after storing. This gives us the option to try different windowing\nparameters after reloading the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "OUT_PATH = tempfile.mkdtemp()  # plaese insert actual output directory here\ntuh_splits = tuh.split([[i] for i in range(len(tuh.datasets))])\nfor rec_i, tuh_subset in tuh_splits.items():\n    preprocess(tuh_subset, preprocessors)\n\n    # update description of the recording(s)\n    tuh_subset.set_description({\n        'sfreq': len(tuh_subset.datasets) * [sfreq],\n        'reference': len(tuh_subset.datasets) * ['ar'],\n        'n_samples': [len(d) for d in tuh_subset.datasets],\n    }, overwrite=True)\n\n    # create one directory for every recording\n    rec_path = os.path.join(OUT_PATH, str(rec_i))\n    if not os.path.exists(rec_path):\n        os.makedirs(rec_path)\n    tuh_subset.save(rec_path)\n    # save memory by deleting raw recording\n    del tuh_subset.datasets[0].raw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We reload the preprocessed data again in a lazy fashion (`preload=False`).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tuh_loaded = load_concat_dataset(OUT_PATH, preload=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We generate compute windows. The resulting dataset is now ready to be used\nfor model training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "window_size_samples = 1000\nwindow_stride_samples = 1000\n# generate compute windows here and store them to disk\ntuh_windows = create_fixed_length_windows(\n    tuh_loaded,\n    start_offset_samples=0,\n    stop_offset_samples=None,\n    window_size_samples=window_size_samples,\n    window_stride_samples=window_stride_samples,\n    drop_last_window=False\n)\n# store the number of windows required for loading later on\ntuh_windows.set_description({\n    \"n_windows\": [len(d) for d in tuh_windows.datasets]})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}