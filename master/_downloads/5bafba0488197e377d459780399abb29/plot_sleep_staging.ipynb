{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sleep staging on the Sleep Physionet dataset\n\nThis tutorial shows how to train and test a sleep staging neural network with\nBraindecode. We adapt the time distributed approach of [1]_ to learn on\nsequences of EEG windows using the openly accessible Sleep Physionet dataset\n[2]_ [3]_.\n\n## References\n.. [1] Chambon, S., Galtier, M., Arnal, P., Wainrib, G. and Gramfort, A.\n      (2018)A Deep Learning Architecture for Temporal Sleep Stage\n      Classification Using Multivariate and Multimodal Time Series.\n      IEEE Trans. on Neural Systems and Rehabilitation Engineering 26:\n      (758-769)\n\n.. [2] B Kemp, AH Zwinderman, B Tuk, HAC Kamphuisen, JJL Obery\u00e9. Analysis of\n       a sleep-dependent neuronal feedback loop: the slow-wave\n       microcontinuity of the EEG. IEEE-BME 47(9):1185-1194 (2000).\n\n.. [3] Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh,\n       Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000)\n       PhysioBank, PhysioToolkit, and PhysioNet: Components of a New\n       Research Resource for Complex Physiologic Signals.\n       Circulation 101(23):e215-e220\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Hubert Banville <hubert.jbanville@gmail.com>\n#\n# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading and preprocessing the dataset\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we load the data using the\n:class:`braindecode.datasets.sleep_physionet.SleepPhysionet` class. We load\ntwo recordings from two different individuals: we will use the first one to\ntrain our network and the second one to evaluate performance (as in the `MNE`_\nsleep staging example).\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.datasets.sleep_physionet import SleepPhysionet\n\ndataset = SleepPhysionet(\n    subject_ids=[0, 1], recording_ids=[2], crop_wake_mins=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we preprocess the raw data. We convert the data to microvolts and apply\na lowpass filter. We omit the downsampling step of [1]_ as the Sleep\nPhysionet data is already sampled at a lower 100 Hz.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing.preprocess import preprocess, Preprocessor\n\nhigh_cut_hz = 30\n\npreprocessors = [\n    Preprocessor(lambda x: x * 1e6),\n    Preprocessor('filter', l_freq=None, h_freq=high_cut_hz)\n]\n\n# Transform the data\npreprocess(dataset, preprocessors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract windows\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We extract 30-s windows to be used in the classification task.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing import create_windows_from_events\n\n\nmapping = {  # We merge stages 3 and 4 following AASM standards.\n    'Sleep stage W': 0,\n    'Sleep stage 1': 1,\n    'Sleep stage 2': 2,\n    'Sleep stage 3': 3,\n    'Sleep stage 4': 3,\n    'Sleep stage R': 4\n}\n\nwindow_size_s = 30\nsfreq = 100\nwindow_size_samples = window_size_s * sfreq\n\nwindows_dataset = create_windows_from_events(\n    dataset, trial_start_offset_samples=0, trial_stop_offset_samples=0,\n    window_size_samples=window_size_samples,\n    window_stride_samples=window_size_samples, preload=True, mapping=mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Window preprocessing\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also preprocess the windows by applying channel-wise z-score normalization\nin each window.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing.preprocess import zscore\n\npreprocess(windows_dataset, [Preprocessor(zscore)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset into train and valid\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We split the dataset into training and validation set using additional info\nstored in the `description` attribute of\n:class:`braindecode.datasets.BaseDataset`, in this case using the ``subject``\ncolumn.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom braindecode.datasets import BaseConcatDataset\n\nrandom_state = 31\nsubjects = np.unique(windows_dataset.description['subject'])\nsubj_train, subj_valid = train_test_split(\n    subjects, test_size=0.5, random_state=random_state)\n\nsplit_ids = {'train': subj_train, 'valid': subj_valid}\nsplitted = dict()\nfor name, values in split_ids.items():\n    splitted[name] = BaseConcatDataset(\n        [ds for ds in windows_dataset.datasets\n         if ds.description['subject'] in values])\n\ntrain_set = splitted['train']\nvalid_set = splitted['valid']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create sequence samplers\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Following the time distributed approach of [1]_, we will need to provide our\nneural network with sequences of windows, such that the embeddings of\nmultiple consecutive windows can be concatenated and provided to a final\nclassifier. We can achieve this by defining Sampler objects that return\nsequences of window indices.\nTo simplify the example, we train the whole model end-to-end on sequences,\nrather than using the two-step approach of [1]_ (i.e. training the feature\nextractor on single windows, then freezing its weights and training the\nclassifier).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.samplers import SequenceSampler\n\nn_windows = 3  # Sequences of 3 consecutive windows\nn_windows_stride = 1  # Maximally overlapping sequences\n\ntrain_sampler = SequenceSampler(\n    train_set.get_metadata(), n_windows, n_windows_stride)\nvalid_sampler = SequenceSampler(\n    valid_set.get_metadata(), n_windows, n_windows_stride)\n\n# Print number of examples per class\nprint(len(train_sampler))\nprint(len(valid_sampler))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also implement a transform to extract the label of the center window of a\nsequence to use it as target.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use label of center window in the sequence\ndef get_center_label(x):\n    return x[np.ceil(len(x) / 2).astype(int)] if len(x) > 1 else x\n\n\ntrain_set.seq_target_transform = get_center_label\nvalid_set.seq_target_transform = get_center_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, since some sleep stages appear a lot more often than others (e.g.\nmost of the night is spent in the N2 stage), the classes are imbalanced. To\navoid overfitting on the more frequent classes, we compute weights that we\nwill provide to the loss function when training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n\ny_train = [train_set[idx][1] for idx in train_sampler]\nclass_weights = compute_class_weight(\n    'balanced', classes=np.unique(y_train), y=y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create model\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now create the deep learning model. In this tutorial, we use the sleep\nstaging architecture introduced in [1]_, which is a four-layer convolutional\nneural network.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch import nn\nfrom braindecode.util import set_random_seeds\nfrom braindecode.models import SleepStagerChambon2018\n\ncuda = torch.cuda.is_available()  # check if GPU is available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nif cuda:\n    torch.backends.cudnn.benchmark = True\n# Set random seed to be able to reproduce results\nset_random_seeds(seed=random_state, cuda=cuda)\n\nn_classes = 5\n# Extract number of channels and time steps from dataset\nn_channels, input_size_samples = train_set[0][0].shape\n\n\nclass TimeDistributedNet(nn.Module):\n    \"\"\"Extract features for multiple windows then concatenate & classify them.\n    \"\"\"\n    def __init__(self, feat_extractor, len_last_layer, n_windows, n_classes,\n                 dropout=0.25):\n        super().__init__()\n        self.feat_extractor = feat_extractor\n        self.clf = nn.Sequential(\n            nn.Dropout(dropout),\n            nn.Linear(len_last_layer * n_windows, n_classes)\n        )\n\n    def forward(self, x):\n        \"\"\"\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input sequence of windows, of shape (batch_size, seq_len,\n            n_channels, n_times).\n        \"\"\"\n        feats = [self.feat_extractor.embed(x[:, i]) for i in range(x.shape[1])]\n        feats = torch.stack(feats, dim=1).flatten(start_dim=1)\n        return self.clf(feats)\n\n\nfeat_extractor = SleepStagerChambon2018(\n    n_channels,\n    sfreq,\n    n_classes=n_classes,\n    input_size_s=input_size_samples / sfreq\n)\n\nmodel = TimeDistributedNet(\n    feat_extractor, feat_extractor.len_last_layer, n_windows, n_classes,\n    dropout=0.5)\n\n\n# Send model to GPU\nif cuda:\n    model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now train our network. :class:`braindecode.EEGClassifier` is a\nbraindecode object that is responsible for managing the training of neural\nnetworks. It inherits from :class:`skorch.NeuralNetClassifier`, so the\ntraining logic is the same as in\n`Skorch <https://skorch.readthedocs.io/en/stable/>`__.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note**: We use different hyperparameters from [1]_, as\nthese hyperparameters were optimized on a different dataset (MASS SS3) and\nwith a different number of recordings. Generally speaking, it is\nrecommended to perform hyperparameter optimization if reusing this code on\na different dataset or with more recordings.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skorch.helper import predefined_split\nfrom skorch.callbacks import EpochScoring\nfrom braindecode import EEGClassifier\n\nlr = 1e-3\nbatch_size = 32\nn_epochs = 10\n\ntrain_bal_acc = EpochScoring(\n    scoring='balanced_accuracy', on_train=True, name='train_bal_acc',\n    lower_is_better=False)\nvalid_bal_acc = EpochScoring(\n    scoring='balanced_accuracy', on_train=False, name='valid_bal_acc',\n    lower_is_better=False)\ncallbacks = [('train_bal_acc', train_bal_acc),\n             ('valid_bal_acc', valid_bal_acc)]\n\nclf = EEGClassifier(\n    model,\n    criterion=torch.nn.CrossEntropyLoss,\n    criterion__weight=torch.Tensor(class_weights).to(device),\n    optimizer=torch.optim.Adam,\n    iterator_train__shuffle=False,\n    iterator_train__sampler=train_sampler,\n    iterator_valid__sampler=valid_sampler,\n    train_split=predefined_split(valid_set),  # using valid_set for validation\n    optimizer__lr=lr,\n    batch_size=batch_size,\n    callbacks=callbacks,\n    device=device\n)\n# Model training for a specified number of epochs. `y` is None as it is already\n# supplied in the dataset.\nclf.fit(train_set, y=None, epochs=n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot results\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the history stored by Skorch during training to plot the performance of\nthe model throughout training. Specifically, we plot the loss and the balanced\nmisclassification rate (1 - balanced accuracy) for the training and validation\nsets.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nimport pandas as pd\n\n# Extract loss and balanced accuracy values for plotting from history object\ndf = pd.DataFrame(clf.history.to_list())\ndf[['train_mis_clf', 'valid_mis_clf']] = 100 - df[\n    ['train_bal_acc', 'valid_bal_acc']] * 100\n\n# get percent of misclass for better visual comparison to loss\nplt.style.use('seaborn-talk')\nfig, ax1 = plt.subplots(figsize=(8, 3))\ndf.loc[:, ['train_loss', 'valid_loss']].plot(\n    ax=ax1, style=['-', ':'], marker='o', color='tab:blue', legend=False,\n    fontsize=14)\n\nax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\nax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\ndf.loc[:, ['train_mis_clf', 'valid_mis_clf']].plot(\n    ax=ax2, style=['-', ':'], marker='o', color='tab:red', legend=False)\nax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\nax2.set_ylabel('Balanced misclassification rate [%]', color='tab:red',\n               fontsize=14)\nax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend\nax1.set_xlabel('Epoch', fontsize=14)\n\n# where some data has already been plotted to ax\nhandles = []\nhandles.append(\n    Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))\nhandles.append(\n    Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))\nplt.legend(handles, [h.get_label() for h in handles], fontsize=14)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we also display the confusion matrix and classification report:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\ny_true = [valid_set[[i]][1][0] for i in range(len(valid_sampler))]\ny_pred = clf.predict(valid_set)\n\nprint(confusion_matrix(y_true, y_pred))\nprint(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our model was able to learn despite the low amount of data that was available\n(only two recordings in this example) and reached a balanced accuracy of\nabout 36% in a 5-class classification task (chance-level = 20%) on held-out\ndata.\n\nTo further improve performance, more recordings should be included in the\ntraining set, and hyperparameters should be selected accordingly. Increasing\nthe sequence length was also shown in [1]_ to help improve performance,\nespecially when few EEG channels are available.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}