
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Multiple discrete targets with the TUH EEG Corpus &#8212; Braindecode 0.6 documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Benchmarking preprocessing with parallelization and serialization" href="plot_benchmark_preprocessing.html" />
    <link rel="prev" title="Load and save dataset example" href="plot_load_save_datasets.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="light">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">
  
  
  
  
    <img src="../_static/braindecode_small.svg" class="logo__image only-light" alt="Logo image">
    <img src="../_static/braindecode_small.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../install.html">
  Install
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../starting.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="index.html">
  Tutorial and Examples
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../help.html">
  Get help
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../whats_new.html">
  What’s new
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        0.6  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables auto_examples/plot_tuh_discrete_multitarget and {'json_url': 'https://github.com/braindecode/braindecode/raw/master/docs/_static/versions.json', 'version_match': '0.6'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "auto_examples/plot_tuh_discrete_multitarget.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://github.com/braindecode/braindecode/raw/master/docs/_static/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "auto_examples/plot_tuh_discrete_multitarget.html";
        let btn = document.getElementById("version_switcher_button");
        // Set empty strings by default so that these attributes exist and can be used in CSS selectors
        btn.dataset["activeVersionName"] = "";
        btn.dataset["activeVersion"] = "";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's 0.6 variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "0.6") {
                node.classList.add("active");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="plot_split_dataset.html">
   Split Dataset Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_load_save_datasets.html">
   Load and save dataset example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_mne_dataset_example.html">
   MNE Dataset Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_custom_dataset_example.html">
   Custom Dataset Example
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Multiple discrete targets with the TUH EEG Corpus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_benchmark_preprocessing.html">
   Benchmarking preprocessing with parallelization and serialization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_dataset_example.html">
   MOABB Dataset Example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_regression.html">
   Regression example on fake data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_hyperparameter_tuning_with_scikit-learn.html">
   Hyperparameter tuning with scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_tuh_eeg_corpus.html">
   Process a big data EEG resource (TUH EEG Corpus)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_sleep_staging_usleep.html">
   Sleep staging on the Sleep Physionet dataset using U-Sleep network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_data_augmentation.html">
   Data Augmentation on BCIC IV 2a Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_sleep_staging_eldele2021.html">
   Sleep staging on the Sleep Physionet dataset using Eldele2021
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_sleep_staging_chambon2018.html">
   Sleep staging on the Sleep Physionet dataset using Chambon2018 network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_bcic_iv_2a_moabb_trial.html">
   Trialwise Decoding on BCIC IV 2a Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_data_augmentation_search.html">
   Searching the best data augmentation on BCIC IV 2a Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_bcic_iv_4_ecog_trial.html">
   Fingers flexion decoding on BCIC IV 4 ECoG Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="benchmark_lazy_eager_loading.html">
   Benchmarking eager and lazy loading
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_bcic_iv_4_ecog_cropped.html">
   Fingers flexion cropped decoding on BCIC IV 4 ECoG Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_bcic_iv_2a_moabb_cropped.html">
   Cropped Decoding on BCIC IV 2a Dataset
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_relative_positioning.html">
   Self-supervised learning on EEG with relative positioning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="plot_how_train_test_and_tune.html">
   How to train, test and tune your model
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      

<nav id="bd-toc-nav">
    
</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-plot-tuh-discrete-multitarget-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="multiple-discrete-targets-with-the-tuh-eeg-corpus">
<span id="sphx-glr-auto-examples-plot-tuh-discrete-multitarget-py"></span><h1>Multiple discrete targets with the TUH EEG Corpus<a class="headerlink" href="#multiple-discrete-targets-with-the-tuh-eeg-corpus" title="Permalink to this heading">#</a></h1>
<p>In this example, we showcase usage of multiple discrete targets per recording
with the TUH EEG Corpus.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Author: Lukas Gemein &lt;l.gemein@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD (3-clause)</span>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/typing.html#typing.Generic" title="typing.Generic" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a>

<span class="kn">from</span> <span class="nn">braindecode.datasets</span> <span class="kn">import</span> <a href="../generated/braindecode.datasets.TUH.html#braindecode.datasets.TUH" title="braindecode.datasets.TUH" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class"><span class="n">TUH</span></a>
<span class="kn">from</span> <span class="nn">braindecode.preprocessing</span> <span class="kn">import</span> <a href="../generated/braindecode.preprocessing.create_fixed_length_windows.html#braindecode.preprocessing.create_fixed_length_windows" title="braindecode.preprocessing.create_fixed_length_windows" class="sphx-glr-backref-module-braindecode-preprocessing sphx-glr-backref-type-py-function"><span class="n">create_fixed_length_windows</span></a>

<a href="https://mne.tools/stable/generated/mne.set_log_level.html#mne.set_log_level" title="mne.set_log_level" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">set_log_level</span></a><span class="p">(</span><span class="s1">&#39;ERROR&#39;</span><span class="p">)</span>  <span class="c1"># avoid messages everytime a window is extracted</span>
</pre></div>
</div>
<p>If you want to try this code with the actual data, please delete the next
section. We are required to mock some dataset functionality, since the data
is not available at creation time of this example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">braindecode.datasets.tuh</span> <span class="kn">import</span> <span class="n">_TUHMock</span> <span class="k">as</span> <a href="../generated/braindecode.datasets.TUH.html#braindecode.datasets.TUH" title="braindecode.datasets.TUH" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class"><span class="n">TUH</span></a>  <span class="c1"># noqa F811</span>
</pre></div>
</div>
<p>We start by creating a TUH dataset. Instead of just a str, we give it
multiple strings as target names. Each of the strings has to exist as a
column in the description DataFrame.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TUH_PATH</span></a> <span class="o">=</span> <span class="s1">&#39;please insert actual path to data here&#39;</span>
<span class="n">tuh</span> <span class="o">=</span> <a href="../generated/braindecode.datasets.TUH.html#braindecode.datasets.TUH" title="braindecode.datasets.TUH" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class"><span class="n">TUH</span></a><span class="p">(</span>
    <span class="n">path</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TUH_PATH</span></a><span class="p">,</span>
    <span class="n">recording_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">target_name</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;gender&#39;</span><span class="p">),</span>  <span class="c1"># use both age and gender as decoding target</span>
    <span class="n">preload</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">add_physician_reports</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">tuh</span><span class="o">.</span><span class="n">description</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>path</th>
      <th>version</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>subject</th>
      <th>session</th>
      <th>segment</th>
      <th>age</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>tuh_eeg/v1.1.0/edf/02_tcp_le/000/00000058/s001...</td>
      <td>v1.1.0</td>
      <td>2003</td>
      <td>2</td>
      <td>5</td>
      <td>58</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>M</td>
    </tr>
    <tr>
      <th>1</th>
      <td>tuh_eeg/v1.1.0/edf/01_tcp_ar/099/00009932/s004...</td>
      <td>v1.1.0</td>
      <td>2014</td>
      <td>9</td>
      <td>30</td>
      <td>9932</td>
      <td>4</td>
      <td>13</td>
      <td>53</td>
      <td>F</td>
    </tr>
    <tr>
      <th>2</th>
      <td>tuh_eeg/v1.1.0/edf/03_tcp_ar_a/123/00012331/s0...</td>
      <td>v1.1.0</td>
      <td>2014</td>
      <td>12</td>
      <td>14</td>
      <td>12331</td>
      <td>3</td>
      <td>2</td>
      <td>39</td>
      <td>M</td>
    </tr>
    <tr>
      <th>3</th>
      <td>tuh_eeg/v1.1.0/edf/01_tcp_ar/000/00000000/s001...</td>
      <td>v1.1.0</td>
      <td>2015</td>
      <td>12</td>
      <td>30</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>37</td>
      <td>M</td>
    </tr>
    <tr>
      <th>4</th>
      <td>tuh_eeg/v1.2.0/edf/03_tcp_ar_a/149/00014928/s0...</td>
      <td>v1.2.0</td>
      <td>2016</td>
      <td>1</td>
      <td>15</td>
      <td>14928</td>
      <td>4</td>
      <td>7</td>
      <td>83</td>
      <td>F</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<br />
<br /><p>Iterating through the dataset gives x as ndarray(n_channels x 1) as well as
the target as [age of the subject, gender of the subject]. Let’s look at the last example
as it has more interesting age/gender labels (compare to the last row of the dataframe above).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a> <span class="o">=</span> <span class="n">tuh</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x:&#39;</span><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y:&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>x: [[-0.3309847 ]
 [ 0.31454256]
 [-0.25391167]
 [ 1.74381308]
 [-0.38714669]
 [-0.81943392]
 [ 0.69326629]
 [-0.95765616]
 [ 0.9505214 ]
 [-0.26483718]
 [-0.01890043]
 [ 0.91162042]
 [-1.82734156]
 [ 0.06716017]
 [-2.07314366]
 [ 1.48535991]
 [-0.91052954]
 [ 0.54965713]
 [ 0.00696964]
 [-0.45277894]
 [ 0.02068495]]
y: [83, &#39;F&#39;]
</pre></div>
</div>
<p>We will skip preprocessing steps for now, since it is not the aim of this
example. Instead, we will directly create compute windows. We specify a
mapping from genders ‘M’ and ‘F’ to integers, since this is required for
decoding.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../generated/braindecode.datasets.BaseConcatDataset.html#braindecode.datasets.BaseConcatDataset" title="braindecode.datasets.BaseConcatDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuh_windows</span></a> <span class="o">=</span> <a href="../generated/braindecode.preprocessing.create_fixed_length_windows.html#braindecode.preprocessing.create_fixed_length_windows" title="braindecode.preprocessing.create_fixed_length_windows" class="sphx-glr-backref-module-braindecode-preprocessing sphx-glr-backref-type-py-function"><span class="n">create_fixed_length_windows</span></a><span class="p">(</span>
    <span class="n">tuh</span><span class="p">,</span>
    <span class="n">start_offset_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">stop_offset_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">window_size_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">window_stride_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">drop_last_window</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">mapping</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;M&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>  <span class="c1"># map non-digit targets</span>
<span class="p">)</span>
<span class="c1"># store the number of windows required for loading later on</span>
<a href="../generated/braindecode.datasets.BaseConcatDataset.html#braindecode.datasets.BaseConcatDataset.set_description" title="braindecode.datasets.BaseConcatDataset.set_description" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-method"><span class="n">tuh_windows</span><span class="o">.</span><span class="n">set_description</span></a><span class="p">({</span>
    <span class="s2">&quot;n_windows&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuh_windows</span><span class="o">.</span><span class="n">datasets</span></a><span class="p">]})</span>
</pre></div>
</div>
<p>Iterating through the dataset gives x as ndarray(n_channels x 1000), y as
[age, gender], and ind. Let’s look at the last example again.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind</span></a> <span class="o">=</span> <a href="../generated/braindecode.datasets.BaseConcatDataset.html#braindecode.datasets.BaseConcatDataset" title="braindecode.datasets.BaseConcatDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuh_windows</span></a><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x:&#39;</span><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y:&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">y</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;ind:&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ind</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>x: [[-5.3881967e-01 -1.8004712e-01 -1.8795420e+00 ...  1.4073344e+00
   1.8621799e-01 -3.3098471e-01]
 [ 6.8841916e-01 -3.0692112e-01 -8.9780849e-01 ...  8.5852671e-01
   1.2517056e+00  3.1454256e-01]
 [-6.1085808e-01 -9.6638370e-01 -1.1550786e+00 ... -3.2890487e-01
  -7.0871806e-01 -2.5391167e-01]
 ...
 [ 4.8362121e-01  7.1875399e-01 -9.0939540e-01 ... -6.0460168e-01
  -2.7863982e-01  6.9696428e-03]
 [ 3.9614607e-02  4.9760902e-01  1.3550788e-03 ... -1.6085935e-01
  -1.2800215e+00 -4.5277894e-01]
 [-1.1841028e+00 -9.0715504e-01  1.4384709e-01 ... -1.4586875e+00
  -9.0018541e-02  2.0684952e-02]]
y: [83, 1]
ind: [3, 2600, 3600]
</pre></div>
</div>
<p>We give the dataset to a pytorch DataLoader, such that it can be used for
model training.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dl</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/typing.html#typing.Generic" title="typing.Generic" class="sphx-glr-backref-module-typing sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><a href="../generated/braindecode.datasets.BaseConcatDataset.html#braindecode.datasets.BaseConcatDataset" title="braindecode.datasets.BaseConcatDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tuh_windows</span></a><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Iterating through the DataLoader gives batch_X as tensor(4 x n_channels x
1000), batch_y as [tensor([4 x age of subject]), tensor([4 x gender of
subject])], and batch_ind. We will iterate to the end to look at the last example
again.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">batch_X</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_y</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_ind</span></a> <span class="ow">in</span> <span class="n">dl</span><span class="p">:</span>
    <span class="k">pass</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;batch_X:&#39;</span><span class="p">,</span> <span class="n">batch_X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;batch_y:&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_y</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;batch_ind:&#39;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch_ind</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>batch_X: tensor([[[ 6.3543e-02, -6.8188e-01,  7.1434e-01,  ..., -9.8862e-01,
           1.3296e+00,  2.8611e+00],
         [ 9.2642e-02,  6.8608e-01,  2.1258e-02,  ...,  1.1436e+00,
          -1.8833e-01,  4.4926e-01],
         [ 1.3024e+00, -2.8921e-01, -2.4220e-01,  ..., -1.5582e+00,
          -4.0417e-01,  1.5919e+00],
         ...,
         [-1.0120e+00, -1.0765e-01, -9.5121e-02,  ...,  9.9068e-01,
          -2.6470e-01, -8.0721e-01],
         [-5.3941e-01, -2.0668e-01,  1.4472e-01,  ...,  3.1556e-01,
           1.0213e+00,  3.1261e-01],
         [-3.4337e-03,  6.2847e-01, -9.0757e-01,  ..., -1.3766e+00,
           1.2679e+00, -6.7418e-01]],

        [[ 1.3641e+00, -4.9490e-01,  1.1942e-01,  ..., -1.4594e+00,
           5.7122e-01,  2.8198e-01],
         [-1.8806e-01, -1.2025e-01,  4.2540e-01,  ...,  1.1715e-01,
          -5.4054e-03, -5.3316e-01],
         [ 7.0202e-01,  1.9239e-01, -2.0321e+00,  ..., -1.3725e-01,
           9.4804e-01, -8.5314e-02],
         ...,
         [-1.7920e+00,  3.8064e-01,  8.5381e-01,  ..., -2.2568e+00,
           6.5106e-01,  9.5637e-01],
         [ 3.0670e-01,  3.0648e-02,  5.1902e-02,  ...,  2.7558e-01,
           1.6341e+00,  7.5302e-01],
         [ 5.3796e-02, -3.3934e+00,  7.3413e-01,  ..., -9.9288e-01,
          -6.1035e-01, -3.6927e-02]],

        [[ 1.6349e-01, -4.3783e-01,  2.8227e-02,  ..., -1.8198e-01,
          -1.5766e-01,  4.3227e-01],
         [-6.9744e-01, -6.2296e-01,  8.7539e-01,  ..., -5.8612e-01,
          -1.0544e+00,  7.6738e-02],
         [ 1.7749e+00,  1.0608e+00,  3.3004e-01,  ...,  3.7382e-01,
          -1.2496e+00,  3.5056e-01],
         ...,
         [ 4.4047e-01,  1.6751e+00,  1.4820e+00,  ..., -6.0621e-01,
           9.1299e-01,  8.4293e-01],
         [ 4.7019e-01,  9.1814e-01, -8.5158e-01,  ..., -1.3416e+00,
          -8.7062e-02,  3.3073e-01],
         [-1.9489e-01,  1.0481e+00, -5.7111e-01,  ..., -2.5356e+00,
          -3.0953e-01,  9.4884e-02]],

        [[-5.3882e-01, -1.8005e-01, -1.8795e+00,  ...,  1.4073e+00,
           1.8622e-01, -3.3098e-01],
         [ 6.8842e-01, -3.0692e-01, -8.9781e-01,  ...,  8.5853e-01,
           1.2517e+00,  3.1454e-01],
         [-6.1086e-01, -9.6638e-01, -1.1551e+00,  ..., -3.2890e-01,
          -7.0872e-01, -2.5391e-01],
         ...,
         [ 4.8362e-01,  7.1875e-01, -9.0940e-01,  ..., -6.0460e-01,
          -2.7864e-01,  6.9696e-03],
         [ 3.9615e-02,  4.9761e-01,  1.3551e-03,  ..., -1.6086e-01,
          -1.2800e+00, -4.5278e-01],
         [-1.1841e+00, -9.0716e-01,  1.4385e-01,  ..., -1.4587e+00,
          -9.0019e-02,  2.0685e-02]]])
batch_y: [tensor([83, 83, 83, 83]), tensor([1, 1, 1, 1])]
batch_ind: [tensor([0, 1, 2, 3]), tensor([   0, 1000, 2000, 2600]), tensor([1000, 2000, 3000, 3600])]
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  1.893 seconds)</p>
<p><strong>Estimated memory usage:</strong>  18 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-tuh-discrete-multitarget-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/7072ea9a517ea63ad1a0cf3ca2153f10/plot_tuh_discrete_multitarget.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_tuh_discrete_multitarget.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/698f5f9879e8de86ce2b89d52213c004/plot_tuh_discrete_multitarget.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_tuh_discrete_multitarget.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="plot_load_save_datasets.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Load and save dataset example</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="plot_benchmark_preprocessing.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Benchmarking preprocessing with parallelization and serialization</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2018–2022, Braindecode Developers..<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>