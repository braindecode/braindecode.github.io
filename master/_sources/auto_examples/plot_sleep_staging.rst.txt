
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_sleep_staging.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_sleep_staging.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_sleep_staging.py:


Sleep staging on the Sleep Physionet dataset
============================================

This tutorial shows how to train and test a sleep staging neural network with
Braindecode. We adapt the time distributed approach of [1]_ to learn on
sequences of EEG windows using the openly accessible Sleep Physionet dataset
[2]_ [3]_.

References
----------
.. [1] Chambon, S., Galtier, M., Arnal, P., Wainrib, G. and Gramfort, A.
      (2018)A Deep Learning Architecture for Temporal Sleep Stage
      Classification Using Multivariate and Multimodal Time Series.
      IEEE Trans. on Neural Systems and Rehabilitation Engineering 26:
      (758-769)

.. [2] B Kemp, AH Zwinderman, B Tuk, HAC Kamphuisen, JJL Obery√©. Analysis of
       a sleep-dependent neuronal feedback loop: the slow-wave
       microcontinuity of the EEG. IEEE-BME 47(9):1185-1194 (2000).

.. [3] Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh,
       Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000)
       PhysioBank, PhysioToolkit, and PhysioNet: Components of a New
       Research Resource for Complex Physiologic Signals.
       Circulation 101(23):e215-e220

.. GENERATED FROM PYTHON SOURCE LINES 28-33

.. code-block:: default

    # Authors: Hubert Banville <hubert.jbanville@gmail.com>
    #
    # License: BSD (3-clause)









.. GENERATED FROM PYTHON SOURCE LINES 34-37

Loading and preprocessing the dataset
-------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 40-43

Loading
~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 46-54

First, we load the data using the
:class:`braindecode.datasets.sleep_physionet.SleepPhysionet` class. We load
two recordings from two different individuals: we will use the first one to
train our network and the second one to evaluate performance (as in the `MNE`_
sleep staging example).

.. _MNE: https://mne.tools/stable/auto_tutorials/sample-datasets/plot_sleep.html


.. GENERATED FROM PYTHON SOURCE LINES 54-62

.. code-block:: default


    from numbers import Integral
    from braindecode.datasets.sleep_physionet import SleepPhysionet

    dataset = SleepPhysionet(
        subject_ids=[0, 1], recording_ids=[2], crop_wake_mins=30)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading https://physionet.org/physiobank/database/sleep-edfx/sleep-cassette//SC4002E0-PSG.edf (49.2 MB)
      0%|          | Downloading : 0.00/49.2M [00:00<?,        ?B/s]      0%|          | Downloading : 56.0k/49.2M [00:00<00:58,     875kB/s]      0%|          | Downloading : 88.0k/49.2M [00:00<01:19,     649kB/s]      0%|          | Downloading : 120k/49.2M [00:00<01:28,     581kB/s]       1%|          | Downloading : 344k/49.2M [00:00<00:39,    1.29MB/s]      1%|          | Downloading : 472k/49.2M [00:00<00:36,    1.42MB/s]      3%|2         | Downloading : 1.34M/49.2M [00:00<00:14,    3.50MB/s]      4%|3         | Downloading : 1.84M/49.2M [00:00<00:11,    4.22MB/s]      7%|6         | Downloading : 3.34M/49.2M [00:00<00:06,    7.71MB/s]      9%|8         | Downloading : 4.34M/49.2M [00:00<00:05,    8.96MB/s]     15%|#4        | Downloading : 7.34M/49.2M [00:00<00:03,    13.7MB/s]     19%|#8        | Downloading : 9.34M/49.2M [00:00<00:02,    16.2MB/s]     23%|##3       | Downloading : 11.3M/49.2M [00:00<00:02,    19.1MB/s]     27%|##7       | Downloading : 13.3M/49.2M [00:00<00:01,    20.4MB/s]     31%|###1      | Downloading : 15.3M/49.2M [00:00<00:01,    21.7MB/s]     35%|###5      | Downloading : 17.3M/49.2M [00:00<00:01,    23.7MB/s]     39%|###9      | Downloading : 19.3M/49.2M [00:00<00:01,    24.6MB/s]     43%|####3     | Downloading : 21.3M/49.2M [00:01<00:01,    26.0MB/s]     47%|####7     | Downloading : 23.3M/49.2M [00:01<00:00,    27.2MB/s]     51%|#####1    | Downloading : 25.3M/49.2M [00:01<00:00,    27.5MB/s]     56%|#####5    | Downloading : 27.3M/49.2M [00:01<00:00,    29.0MB/s]     60%|#####9    | Downloading : 29.3M/49.2M [00:01<00:00,    29.6MB/s]     64%|######3   | Downloading : 31.3M/49.2M [00:01<00:00,    30.3MB/s]     68%|######7   | Downloading : 33.3M/49.2M [00:01<00:00,    31.3MB/s]     72%|#######1  | Downloading : 35.3M/49.2M [00:01<00:00,    31.8MB/s]     76%|#######5  | Downloading : 37.3M/49.2M [00:01<00:00,    32.3MB/s]     80%|#######9  | Downloading : 39.3M/49.2M [00:01<00:00,    32.6MB/s]     84%|########3 | Downloading : 41.3M/49.2M [00:01<00:00,    33.1MB/s]     88%|########8 | Downloading : 43.3M/49.2M [00:01<00:00,    33.8MB/s]     92%|#########2| Downloading : 45.3M/49.2M [00:01<00:00,    34.2MB/s]     96%|#########6| Downloading : 47.3M/49.2M [00:01<00:00,    34.3MB/s]    100%|##########| Downloading : 49.2M/49.2M [00:01<00:00,    35.2MB/s]    100%|##########| Downloading : 49.2M/49.2M [00:01<00:00,    29.7MB/s]
    Verifying hash c6b6d7a8605cc7e7602b6028ee77f6fbf5f7581d.
    Downloading https://physionet.org/physiobank/database/sleep-edfx/sleep-cassette//SC4002EC-Hypnogram.edf (4 kB)
      0%|          | Downloading : 0.00/4.47k [00:00<?,        ?B/s]    100%|##########| Downloading : 4.47k/4.47k [00:00<00:00,    2.44MB/s]
    Verifying hash 386230188a3552b1fc90bba0fb7476ceaca174b6.
    Downloading https://physionet.org/physiobank/database/sleep-edfx/sleep-cassette//SC4012E0-PSG.edf (49.6 MB)
      0%|          | Downloading : 0.00/49.6M [00:00<?,        ?B/s]      0%|          | Downloading : 56.0k/49.6M [00:00<01:03,     816kB/s]      0%|          | Downloading : 88.0k/49.6M [00:00<01:22,     631kB/s]      0%|          | Downloading : 184k/49.6M [00:00<00:58,     891kB/s]       1%|          | Downloading : 376k/49.6M [00:00<00:37,    1.39MB/s]      1%|1         | Downloading : 760k/49.6M [00:00<00:22,    2.28MB/s]      3%|3         | Downloading : 1.49M/49.6M [00:00<00:12,    3.90MB/s]      6%|6         | Downloading : 2.99M/49.6M [00:00<00:07,    6.64MB/s]      8%|8         | Downloading : 3.99M/49.6M [00:00<00:05,    8.76MB/s]     10%|#         | Downloading : 4.99M/49.6M [00:00<00:04,    10.1MB/s]     12%|#2        | Downloading : 5.99M/49.6M [00:00<00:03,    12.1MB/s]     16%|#6        | Downloading : 7.99M/49.6M [00:00<00:02,    14.6MB/s]     18%|#8        | Downloading : 8.99M/49.6M [00:00<00:02,    15.9MB/s]     20%|##        | Downloading : 9.99M/49.6M [00:00<00:02,    17.5MB/s]     22%|##2       | Downloading : 11.0M/49.6M [00:00<00:02,    17.8MB/s]     26%|##6       | Downloading : 13.0M/49.6M [00:00<00:01,    21.1MB/s]     30%|###       | Downloading : 15.0M/49.6M [00:00<00:01,    22.1MB/s]     34%|###4      | Downloading : 17.0M/49.6M [00:00<00:01,    23.3MB/s]     38%|###8      | Downloading : 19.0M/49.6M [00:00<00:01,    25.8MB/s]     42%|####2     | Downloading : 21.0M/49.6M [00:01<00:01,    26.5MB/s]     46%|####6     | Downloading : 23.0M/49.6M [00:01<00:01,    27.2MB/s]     50%|#####     | Downloading : 25.0M/49.6M [00:01<00:00,    28.2MB/s]     54%|#####4    | Downloading : 27.0M/49.6M [00:01<00:00,    29.7MB/s]     58%|#####8    | Downloading : 29.0M/49.6M [00:01<00:00,    30.1MB/s]     63%|######2   | Downloading : 31.0M/49.6M [00:01<00:00,    30.0MB/s]     67%|######6   | Downloading : 33.0M/49.6M [00:01<00:00,    31.9MB/s]     71%|#######   | Downloading : 35.0M/49.6M [00:01<00:00,    32.0MB/s]     75%|#######4  | Downloading : 37.0M/49.6M [00:01<00:00,    32.1MB/s]     79%|#######8  | Downloading : 39.0M/49.6M [00:01<00:00,    33.1MB/s]     83%|########2 | Downloading : 41.0M/49.6M [00:01<00:00,    33.3MB/s]     87%|########6 | Downloading : 43.0M/49.6M [00:01<00:00,    33.8MB/s]     91%|######### | Downloading : 45.0M/49.6M [00:01<00:00,    34.7MB/s]     95%|#########4| Downloading : 47.0M/49.6M [00:01<00:00,    34.7MB/s]     99%|#########8| Downloading : 49.0M/49.6M [00:01<00:00,    35.1MB/s]    100%|##########| Downloading : 49.6M/49.6M [00:01<00:00,    34.9MB/s]    100%|##########| Downloading : 49.6M/49.6M [00:01<00:00,    29.5MB/s]
    Verifying hash a47d525f5147904b6890231e2ad338359c7ab94c.
    Downloading https://physionet.org/physiobank/database/sleep-edfx/sleep-cassette//SC4012EC-Hypnogram.edf (5 kB)
      0%|          | Downloading : 0.00/4.96k [00:00<?,        ?B/s]    100%|##########| Downloading : 4.96k/4.96k [00:00<00:00,    2.70MB/s]
    Verifying hash fa99f60d7f54617cdd1128aff4f21c4daed763c7.
    Extracting EDF parameters from /home/runner/mne_data/physionet-sleep-data/SC4002E0-PSG.edf...
    EDF file detected
    Setting channel info structure...
    Creating raw.info structure...
    Extracting EDF parameters from /home/runner/mne_data/physionet-sleep-data/SC4012E0-PSG.edf...
    EDF file detected
    Setting channel info structure...
    Creating raw.info structure...




.. GENERATED FROM PYTHON SOURCE LINES 63-66

Preprocessing
~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 69-73

Next, we preprocess the raw data. We convert the data to microvolts and apply
a lowpass filter. We omit the downsampling step of [1]_ as the Sleep
Physionet data is already sampled at a lower 100 Hz.


.. GENERATED FROM PYTHON SOURCE LINES 73-87

.. code-block:: default


    from braindecode.preprocessing.preprocess import preprocess, Preprocessor

    high_cut_hz = 30

    preprocessors = [
        Preprocessor(lambda x: x * 1e6),
        Preprocessor('filter', l_freq=None, h_freq=high_cut_hz)
    ]

    # Transform the data
    preprocess(dataset, preprocessors)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Reading 0 ... 3348000  =      0.000 ... 33480.000 secs...
    Filtering raw data in 1 contiguous segment
    Setting up low-pass filter at 30 Hz

    FIR filter parameters
    ---------------------
    Designing a one-pass, zero-phase, non-causal lowpass filter:
    - Windowed time-domain design (firwin) method
    - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
    - Upper passband edge: 30.00 Hz
    - Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)
    - Filter length: 45 samples (0.450 sec)

    Reading 0 ... 3447000  =      0.000 ... 34470.000 secs...
    Filtering raw data in 1 contiguous segment
    Setting up low-pass filter at 30 Hz

    FIR filter parameters
    ---------------------
    Designing a one-pass, zero-phase, non-causal lowpass filter:
    - Windowed time-domain design (firwin) method
    - Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation
    - Upper passband edge: 30.00 Hz
    - Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)
    - Filter length: 45 samples (0.450 sec)





.. GENERATED FROM PYTHON SOURCE LINES 88-91

Extract windows
~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 94-95

We extract 30-s windows to be used in the classification task.

.. GENERATED FROM PYTHON SOURCE LINES 95-118

.. code-block:: default


    from braindecode.preprocessing import create_windows_from_events


    mapping = {  # We merge stages 3 and 4 following AASM standards.
        'Sleep stage W': 0,
        'Sleep stage 1': 1,
        'Sleep stage 2': 2,
        'Sleep stage 3': 3,
        'Sleep stage 4': 3,
        'Sleep stage R': 4
    }

    window_size_s = 30
    sfreq = 100
    window_size_samples = window_size_s * sfreq

    windows_dataset = create_windows_from_events(
        dataset, trial_start_offset_samples=0, trial_stop_offset_samples=0,
        window_size_samples=window_size_samples,
        window_stride_samples=window_size_samples, preload=True, mapping=mapping)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']
    Adding metadata with 4 columns
    Replacing existing metadata with 4 columns
    1116 matching events found
    No baseline correction applied
    0 projection items activated
    Loading data for 1116 events and 3000 original time points ...
    0 bad epochs dropped
    Used Annotations descriptions: ['Sleep stage 1', 'Sleep stage 2', 'Sleep stage 3', 'Sleep stage 4', 'Sleep stage R', 'Sleep stage W']
    Adding metadata with 4 columns
    Replacing existing metadata with 4 columns
    1150 matching events found
    No baseline correction applied
    0 projection items activated
    Loading data for 1150 events and 3000 original time points ...
    0 bad epochs dropped




.. GENERATED FROM PYTHON SOURCE LINES 119-122

Window preprocessing
~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 125-128

We also preprocess the windows by applying channel-wise z-score normalization
in each window.


.. GENERATED FROM PYTHON SOURCE LINES 128-134

.. code-block:: default


    from braindecode.preprocessing.preprocess import zscore

    preprocess(windows_dataset, [Preprocessor(zscore)])









.. GENERATED FROM PYTHON SOURCE LINES 135-138

Split dataset into train and valid
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 141-146

We split the dataset into training and validation set using additional info
stored in the `description` attribute of
:class:`braindecode.datasets.BaseDataset`, in this case using the ``subject``
column.


.. GENERATED FROM PYTHON SOURCE LINES 146-166

.. code-block:: default


    import numpy as np
    from sklearn.model_selection import train_test_split
    from braindecode.datasets import BaseConcatDataset

    random_state = 31
    subjects = np.unique(windows_dataset.description['subject'])
    subj_train, subj_valid = train_test_split(
        subjects, test_size=0.5, random_state=random_state)

    split_ids = {'train': subj_train, 'valid': subj_valid}
    splitted = dict()
    for name, values in split_ids.items():
        splitted[name] = BaseConcatDataset(
            [ds for ds in windows_dataset.datasets
             if ds.description['subject'] in values])

    train_set = splitted['train']
    valid_set = splitted['valid']








.. GENERATED FROM PYTHON SOURCE LINES 167-170

Create sequence samplers
------------------------


.. GENERATED FROM PYTHON SOURCE LINES 173-183

Following the time distributed approach of [1]_, we will need to provide our
neural network with sequences of windows, such that the embeddings of
multiple consecutive windows can be concatenated and provided to a final
classifier. We can achieve this by defining Sampler objects that return
sequences of window indices.
To simplify the example, we train the whole model end-to-end on sequences,
rather than using the two-step approach of [1]_ (i.e. training the feature
extractor on single windows, then freezing its weights and training the
classifier).


.. GENERATED FROM PYTHON SOURCE LINES 183-198

.. code-block:: default


    from braindecode.samplers import SequenceSampler

    n_windows = 3  # Sequences of 3 consecutive windows
    n_windows_stride = 1  # Maximally overlapping sequences

    train_sampler = SequenceSampler(
        train_set.get_metadata(), n_windows, n_windows_stride)
    valid_sampler = SequenceSampler(
        valid_set.get_metadata(), n_windows, n_windows_stride)

    # Print number of examples per class
    print(len(train_sampler))
    print(len(valid_sampler))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    1114
    1148




.. GENERATED FROM PYTHON SOURCE LINES 199-202

We also implement a transform to extract the label of the center window of a
sequence to use it as target.


.. GENERATED FROM PYTHON SOURCE LINES 202-214

.. code-block:: default



    # Use label of center window in the sequence
    def get_center_label(x):
        if isinstance(x, Integral):
            return x
        return x[np.ceil(len(x) / 2).astype(int)] if len(x) > 1 else x


    train_set.target_transform = get_center_label
    valid_set.target_transform = get_center_label








.. GENERATED FROM PYTHON SOURCE LINES 215-219

Finally, since some sleep stages appear a lot more often than others (e.g.
most of the night is spent in the N2 stage), the classes are imbalanced. To
avoid overfitting on the more frequent classes, we compute weights that we
will provide to the loss function when training.

.. GENERATED FROM PYTHON SOURCE LINES 219-227

.. code-block:: default


    from sklearn.utils.class_weight import compute_class_weight

    y_train = [train_set[idx][1] for idx in train_sampler]
    class_weights = compute_class_weight(
        'balanced', classes=np.unique(y_train), y=y_train)









.. GENERATED FROM PYTHON SOURCE LINES 228-231

Create model
------------


.. GENERATED FROM PYTHON SOURCE LINES 234-238

We can now create the deep learning model. In this tutorial, we use the sleep
staging architecture introduced in [1]_, which is a four-layer convolutional
neural network.


.. GENERATED FROM PYTHON SOURCE LINES 238-298

.. code-block:: default


    import torch
    from torch import nn
    from braindecode.util import set_random_seeds
    from braindecode.models import SleepStagerChambon2018

    cuda = torch.cuda.is_available()  # check if GPU is available
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    if cuda:
        torch.backends.cudnn.benchmark = True
    # Set random seed to be able to reproduce results
    set_random_seeds(seed=random_state, cuda=cuda)

    n_classes = 5
    # Extract number of channels and time steps from dataset
    n_channels, input_size_samples = train_set[0][0].shape


    class TimeDistributedNet(nn.Module):
        """Extract features for multiple windows then concatenate & classify them.
        """
        def __init__(self, feat_extractor, len_last_layer, n_windows, n_classes,
                     dropout=0.25):
            super().__init__()
            self.feat_extractor = feat_extractor
            self.clf = nn.Sequential(
                nn.Dropout(dropout),
                nn.Linear(len_last_layer * n_windows, n_classes)
            )

        def forward(self, x):
            """
            Parameters
            ----------
            x : torch.Tensor
                Input sequence of windows, of shape (batch_size, seq_len,
                n_channels, n_times).
            """
            feats = [self.feat_extractor.embed(x[:, i]) for i in range(x.shape[1])]
            feats = torch.stack(feats, dim=1).flatten(start_dim=1)
            return self.clf(feats)


    feat_extractor = SleepStagerChambon2018(
        n_channels,
        sfreq,
        n_classes=n_classes,
        input_size_s=input_size_samples / sfreq
    )

    model = TimeDistributedNet(
        feat_extractor, feat_extractor.len_last_layer, n_windows, n_classes,
        dropout=0.5)


    # Send model to GPU
    if cuda:
        model.cuda()









.. GENERATED FROM PYTHON SOURCE LINES 299-302

Training
--------


.. GENERATED FROM PYTHON SOURCE LINES 305-311

We can now train our network. :class:`braindecode.EEGClassifier` is a
braindecode object that is responsible for managing the training of neural
networks. It inherits from :class:`skorch.NeuralNetClassifier`, so the
training logic is the same as in
`Skorch <https://skorch.readthedocs.io/en/stable/>`__.


.. GENERATED FROM PYTHON SOURCE LINES 314-320

**Note**: We use different hyperparameters from [1]_, as
these hyperparameters were optimized on a different dataset (MASS SS3) and
with a different number of recordings. Generally speaking, it is
recommended to perform hyperparameter optimization if reusing this code on
a different dataset or with more recordings.


.. GENERATED FROM PYTHON SOURCE LINES 320-357

.. code-block:: default


    from skorch.helper import predefined_split
    from skorch.callbacks import EpochScoring
    from braindecode import EEGClassifier

    lr = 1e-3
    batch_size = 32
    n_epochs = 10

    train_bal_acc = EpochScoring(
        scoring='balanced_accuracy', on_train=True, name='train_bal_acc',
        lower_is_better=False)
    valid_bal_acc = EpochScoring(
        scoring='balanced_accuracy', on_train=False, name='valid_bal_acc',
        lower_is_better=False)
    callbacks = [('train_bal_acc', train_bal_acc),
                 ('valid_bal_acc', valid_bal_acc)]

    clf = EEGClassifier(
        model,
        criterion=torch.nn.CrossEntropyLoss,
        criterion__weight=torch.Tensor(class_weights).to(device),
        optimizer=torch.optim.Adam,
        iterator_train__shuffle=False,
        iterator_train__sampler=train_sampler,
        iterator_valid__sampler=valid_sampler,
        train_split=predefined_split(valid_set),  # using valid_set for validation
        optimizer__lr=lr,
        batch_size=batch_size,
        callbacks=callbacks,
        device=device
    )
    # Model training for a specified number of epochs. `y` is None as it is already
    # supplied in the dataset.
    clf.fit(train_set, y=None, epochs=n_epochs)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      epoch    train_bal_acc    train_loss    valid_bal_acc    valid_loss      dur
    -------  ---------------  ------------  ---------------  ------------  -------
          1           [36m0.1486[0m        [32m1.6382[0m           [35m0.2058[0m        [31m1.6052[0m  13.1763
          2           [36m0.2013[0m        [32m1.5876[0m           0.2006        1.6072  10.9301
          3           [36m0.2021[0m        [32m1.4889[0m           0.2000        1.6193  11.4984
          4           [36m0.2086[0m        [32m1.3696[0m           0.2000        1.6657  11.2787
          5           [36m0.2155[0m        [32m1.2967[0m           [35m0.2115[0m        1.6254  11.9709
          6           [36m0.2440[0m        [32m1.2506[0m           [35m0.2245[0m        1.6241  11.6604
          7           [36m0.2515[0m        [32m1.2225[0m           [35m0.2412[0m        1.6577  10.8143
          8           [36m0.2739[0m        [32m1.1871[0m           [35m0.3088[0m        1.6937  12.3751
          9           [36m0.3003[0m        [32m1.1693[0m           [35m0.3328[0m        [31m1.5350[0m  10.9912
         10           [36m0.3586[0m        [32m1.1449[0m           [35m0.3469[0m        1.6483  11.2068

    <class 'braindecode.classifier.EEGClassifier'>[initialized](
      module_=TimeDistributedNet(
        (feat_extractor): SleepStagerChambon2018(
          (spatial_conv): Conv2d(1, 2, kernel_size=(2, 1), stride=(1, 1))
          (feature_extractor): Sequential(
            (0): Conv2d(1, 8, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))
            (1): Identity()
            (2): ReLU()
            (3): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)
            (4): Conv2d(8, 8, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))
            (5): Identity()
            (6): ReLU()
            (7): MaxPool2d(kernel_size=(1, 13), stride=(1, 13), padding=0, dilation=1, ceil_mode=False)
          )
          (fc): Sequential(
            (0): Dropout(p=0.25, inplace=False)
            (1): Linear(in_features=272, out_features=5, bias=True)
          )
        )
        (clf): Sequential(
          (0): Dropout(p=0.5, inplace=False)
          (1): Linear(in_features=816, out_features=5, bias=True)
        )
      ),
    )



.. GENERATED FROM PYTHON SOURCE LINES 358-361

Plot results
------------


.. GENERATED FROM PYTHON SOURCE LINES 364-369

We use the history stored by Skorch during training to plot the performance of
the model throughout training. Specifically, we plot the loss and the balanced
misclassification rate (1 - balanced accuracy) for the training and validation
sets.


.. GENERATED FROM PYTHON SOURCE LINES 369-409

.. code-block:: default


    import matplotlib.pyplot as plt
    from matplotlib.lines import Line2D
    import pandas as pd

    # Extract loss and balanced accuracy values for plotting from history object
    df = pd.DataFrame(clf.history.to_list())
    df[['train_mis_clf', 'valid_mis_clf']] = 100 - df[
        ['train_bal_acc', 'valid_bal_acc']] * 100

    # get percent of misclass for better visual comparison to loss
    plt.style.use('seaborn-talk')
    fig, ax1 = plt.subplots(figsize=(8, 3))
    df.loc[:, ['train_loss', 'valid_loss']].plot(
        ax=ax1, style=['-', ':'], marker='o', color='tab:blue', legend=False,
        fontsize=14)

    ax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)
    ax1.set_ylabel("Loss", color='tab:blue', fontsize=14)

    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis

    df.loc[:, ['train_mis_clf', 'valid_mis_clf']].plot(
        ax=ax2, style=['-', ':'], marker='o', color='tab:red', legend=False)
    ax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)
    ax2.set_ylabel('Balanced misclassification rate [%]', color='tab:red',
                   fontsize=14)
    ax2.set_ylim(ax2.get_ylim()[0], 85)  # make some room for legend
    ax1.set_xlabel('Epoch', fontsize=14)

    # where some data has already been plotted to ax
    handles = []
    handles.append(
        Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))
    handles.append(
        Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))
    plt.legend(handles, [h.get_label() for h in handles], fontsize=14)
    plt.tight_layout()





.. image:: /auto_examples/images/sphx_glr_plot_sleep_staging_001.png
    :alt: plot sleep staging
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 410-412

Finally, we also display the confusion matrix and classification report:


.. GENERATED FROM PYTHON SOURCE LINES 412-423

.. code-block:: default


    from sklearn.metrics import confusion_matrix
    from sklearn.metrics import classification_report

    y_true = [valid_set[[i]][1][0] for i in range(len(valid_sampler))]
    y_pred = clf.predict(valid_set)

    print(confusion_matrix(y_true, y_pred))
    print(classification_report(y_true, y_pred))






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [[  0   6  40  77   1]
     [  0   3  73  16   0]
     [  0   2 454 204   0]
     [  0   0   1  95   0]
     [  0   0 136  40   0]]
    /usr/share/miniconda/envs/braindecode/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
      _warn_prf(average, modifier, msg_start, len(result))
    /usr/share/miniconda/envs/braindecode/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
      _warn_prf(average, modifier, msg_start, len(result))
    /usr/share/miniconda/envs/braindecode/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
      _warn_prf(average, modifier, msg_start, len(result))
                  precision    recall  f1-score   support

               0       0.00      0.00      0.00       124
               1       0.27      0.03      0.06        92
               2       0.64      0.69      0.67       660
               3       0.22      0.99      0.36        96
               4       0.00      0.00      0.00       176

        accuracy                           0.48      1148
       macro avg       0.23      0.34      0.22      1148
    weighted avg       0.41      0.48      0.42      1148





.. GENERATED FROM PYTHON SOURCE LINES 424-434

Our model was able to learn despite the low amount of data that was available
(only two recordings in this example) and reached a balanced accuracy of
about 36% in a 5-class classification task (chance-level = 20%) on held-out
data.

To further improve performance, more recordings should be included in the
training set, and hyperparameters should be selected accordingly. Increasing
the sequence length was also shown in [1]_ to help improve performance,
especially when few EEG channels are available.



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  14.281 seconds)

**Estimated memory usage:**  2822 MB


.. _sphx_glr_download_auto_examples_plot_sleep_staging.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_sleep_staging.py <plot_sleep_staging.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_sleep_staging.ipynb <plot_sleep_staging.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
