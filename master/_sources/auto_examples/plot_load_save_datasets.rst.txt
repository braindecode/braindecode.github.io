
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_load_save_datasets.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_load_save_datasets.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_load_save_datasets.py:


Load and save dataset example
=============================

In this example, we show how to load and save braindecode datasets.

.. GENERATED FROM PYTHON SOURCE LINES 7-18

.. code-block:: default


    # Authors: Lukas Gemein <l.gemein@gmail.com>
    #
    # License: BSD (3-clause)

    from braindecode.datasets.moabb import MOABBDataset
    from braindecode.preprocessing.preprocess import preprocess, MNEPreproc
    from braindecode.datautil.serialization import load_concat_dataset
    from braindecode.preprocessing.windowers import create_windows_from_events









.. GENERATED FROM PYTHON SOURCE LINES 19-20

First, we load some dataset using MOABB.

.. GENERATED FROM PYTHON SOURCE LINES 20-25

.. code-block:: default

    ds = MOABBDataset(
        dataset_name='BNCI2014001',
        subject_ids=[1],
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]




.. GENERATED FROM PYTHON SOURCE LINES 26-28

We can apply preprocessing steps to the dataset. It is also possible to skip
this step and not apply any preprocessing.

.. GENERATED FROM PYTHON SOURCE LINES 28-33

.. code-block:: default

    preprocess(
        concat_ds=ds,
        preprocessors=[MNEPreproc(fn='resample', sfreq=10)]
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/runner/work/braindecode/braindecode/braindecode/preprocessing/preprocess.py:86: UserWarning: MNEPreproc is deprecated. Use Preprocessor with `apply_on_array=False` instead.
      warn('MNEPreproc is deprecated. Use Preprocessor with '
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]
    48 events found
    Event IDs: [1 2 3 4]




.. GENERATED FROM PYTHON SOURCE LINES 34-40

We save the dataset to a an existing directory. It will create a '.fif' file
for every dataset in the concat dataset. Additionally it will create two
JSON files, the first holding the description of the dataset, the second
holding the name of the target. If you want to store to the same directory
several times, for example due to trying different preprocessing, you can
choose to overwrite the existing files.

.. GENERATED FROM PYTHON SOURCE LINES 40-45

.. code-block:: default

    ds.save(
        path='./',
        overwrite=False,
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Writing /home/runner/work/braindecode/braindecode/examples/0-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/0-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/1-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/1-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/2-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/2-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/3-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/3-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/4-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/4-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/5-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/5-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/6-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/6-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/7-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/7-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/8-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/8-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/9-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/9-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/10-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/10-raw.fif
    [done]
    Writing /home/runner/work/braindecode/braindecode/examples/11-raw.fif
    Closing /home/runner/work/braindecode/braindecode/examples/11-raw.fif
    [done]




.. GENERATED FROM PYTHON SOURCE LINES 46-52

We load the saved dataset from a directory. Signals can be preloaded in
compliance with mne. Optionally, only specific '.fif' files can be loaded
by specifying their ids. The target name can be changed, if the dataset
supports it (TUHAbnormal for example supports 'pathological', 'age', and
'gender'. If you stored a preprocessed version with target 'pathological'
it is possible to change the target upon loading).

.. GENERATED FROM PYTHON SOURCE LINES 52-59

.. code-block:: default

    ds_loaded = load_concat_dataset(
        path='./',
        preload=True,
        ids_to_load=[1, 3],
        target_name=None,
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Opening raw data file ./1-raw.fif...
        Range : 0 ... 3868 =      0.000 ...   386.800 secs
    Ready.
    Reading 0 ... 3868  =      0.000 ...   386.800 secs...
    Opening raw data file ./3-raw.fif...
        Range : 0 ... 3868 =      0.000 ...   386.800 secs
    Ready.
    Reading 0 ... 3868  =      0.000 ...   386.800 secs...




.. GENERATED FROM PYTHON SOURCE LINES 60-62

The serialization utility also supports WindowsDatasets, so we create
compute windows next.

.. GENERATED FROM PYTHON SOURCE LINES 62-68

.. code-block:: default

    windows_ds = create_windows_from_events(
        concat_ds=ds_loaded,
        trial_start_offset_samples=0,
        trial_stop_offset_samples=0,
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']
    Adding metadata with 4 columns
    Replacing existing metadata with 4 columns
    48 matching events found
    No baseline correction applied
    0 projection items activated
    Loading data for 48 events and 40 original time points ...
    0 bad epochs dropped
    Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']
    Adding metadata with 4 columns
    Replacing existing metadata with 4 columns
    48 matching events found
    No baseline correction applied
    0 projection items activated
    Loading data for 48 events and 40 original time points ...
    0 bad epochs dropped




.. GENERATED FROM PYTHON SOURCE LINES 69-75

Again, we save the dataset to an existing directory. It will create a
'-epo.fif' file for every dataset in the concat dataset. Additionally it
will create a JSON file holding the description of the dataset. If you
want to store to the same directory several times, for example due to
trying different windowing parameters, you can choose to overwrite the
existing files.

.. GENERATED FROM PYTHON SOURCE LINES 75-80

.. code-block:: default

    windows_ds.save(
        path='./',
        overwrite=True,
    )





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Loading data for 1 events and 40 original time points ...
    Loading data for 48 events and 40 original time points ...
    Loading data for 1 events and 40 original time points ...
    Loading data for 48 events and 40 original time points ...




.. GENERATED FROM PYTHON SOURCE LINES 81-84

Load the saved dataset from a directory. Signals can be preloaded in
compliance with mne. Optionally, only specific '-epo.fif' files can be
loaded by specifying their ids.

.. GENERATED FROM PYTHON SOURCE LINES 84-90

.. code-block:: default

    windows_ds_loaded = load_concat_dataset(
        path='./',
        preload=False,
        ids_to_load=[0],
        target_name=None,
    )




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Reading ./0-epo.fif ...
        Found the data of interest:
            t =       0.00 ...    3900.00 ms
            0 CTF compensation matrices available
    Adding metadata with 4 columns
    Replacing existing metadata with 4 columns
    48 matching events found
    No baseline correction applied
    0 projection items activated





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  4.166 seconds)

**Estimated memory usage:**  297 MB


.. _sphx_glr_download_auto_examples_plot_load_save_datasets.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_load_save_datasets.py <plot_load_save_datasets.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_load_save_datasets.ipynb <plot_load_save_datasets.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
