
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_data_augmentation.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_data_augmentation.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_data_augmentation.py:


Data Augmentation on BCIC IV 2a Dataset
=======================================

This tutorial shows how to train EEG deep models with data augmentation. It
follows the trial-wise decoding example and also illustrates the effect of a
transform on the input signals.

.. contents:: This example covers:
   :local:
   :depth: 2

.. GENERATED FROM PYTHON SOURCE LINES 14-20

.. code-block:: default


    # Authors: Simon Brandt <simonbrandt@protonmail.com>
    #          CÃ©dric Rommel <cedric.rommel@inria.fr>
    #
    # License: BSD (3-clause)








.. GENERATED FROM PYTHON SOURCE LINES 21-23

Loading and preprocessing the dataset
-------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 25-28

Loading
~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 28-37

.. code-block:: default


    from braindecode import EEGClassifier
    from skorch.helper import predefined_split
    from skorch.callbacks import LRScheduler
    from braindecode.datasets import MOABBDataset

    subject_id = 3
    dataset = MOABBDataset(dataset_name="BNCI2014001", subject_ids=[subject_id])








.. GENERATED FROM PYTHON SOURCE LINES 38-41

Preprocessing
~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 41-61

.. code-block:: default


    from braindecode.preprocessing import (
        exponential_moving_standardize, preprocess, Preprocessor, scale)

    low_cut_hz = 4.  # low cut frequency for filtering
    high_cut_hz = 38.  # high cut frequency for filtering
    # Parameters for exponential moving standardization
    factor_new = 1e-3
    init_block_size = 1000

    preprocessors = [
        Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors
        Preprocessor(scale, factor=1e6, apply_on_array=True),  # Convert from V to uV
        Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter
        Preprocessor(exponential_moving_standardize,  # Exponential moving standardization
                     factor_new=factor_new, init_block_size=init_block_size)
    ]

    preprocess(dataset, preprocessors)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /usr/share/miniconda/envs/braindecode/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function scale is deprecated; will be removed in 0.7.0. Use numpy.multiply instead.
      warnings.warn(msg, category=FutureWarning)

    <braindecode.datasets.moabb.MOABBDataset object at 0x7fcc11ecacd0>



.. GENERATED FROM PYTHON SOURCE LINES 62-65

Extracting windows
~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 65-84

.. code-block:: default


    from braindecode.preprocessing import create_windows_from_events

    trial_start_offset_seconds = -0.5
    # Extract sampling frequency, check that they are same in all datasets
    sfreq = dataset.datasets[0].raw.info['sfreq']
    assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])
    # Calculate the trial start offset in samples.
    trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)

    # Create windows using braindecode function for this. It needs parameters to
    # define how trials should be used.
    windows_dataset = create_windows_from_events(
        dataset,
        trial_start_offset_samples=trial_start_offset_samples,
        trial_stop_offset_samples=0,
        preload=True,
    )








.. GENERATED FROM PYTHON SOURCE LINES 85-88

Split dataset into train and valid
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 88-93

.. code-block:: default


    splitted = windows_dataset.split('session')
    train_set = splitted['session_T']
    valid_set = splitted['session_E']








.. GENERATED FROM PYTHON SOURCE LINES 94-97

Defining a Transform
--------------------


.. GENERATED FROM PYTHON SOURCE LINES 99-103

Data can be manipulated by transforms, which are callable objects. A
transform is usually handled by a custom data loader, but can also be called
directly on input data, as demonstrated below for illutrative purposes.


.. GENERATED FROM PYTHON SOURCE LINES 103-115

.. code-block:: default


    # First, we need to define a Transform. Here we chose the FrequencyShift, which
    # randomly translates all frequencies within a given range.

    from braindecode.augmentation import FrequencyShift

    transform = FrequencyShift(
        probability=1.,  # defines the probability of actually modifying the input
        sfreq=sfreq,
        max_delta_freq=10.  # -> fixed frequency shift for visualization
    )








.. GENERATED FROM PYTHON SOURCE LINES 116-119

Manipulating one session and visualizing the transformed data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 119-129

.. code-block:: default


    # Next, let us augment one session to show the resulting frequency shift. The
    # data of an mne Epoch is used here to make usage of mne functions.

    import torch

    epochs = train_set.datasets[0].windows  # original epochs
    X = epochs.get_data()
    X_tr = transform(X).numpy()








.. GENERATED FROM PYTHON SOURCE LINES 130-132

The psd of the transformed session has now been shifted by 10 Hz, as one can
see on the psd plot.

.. GENERATED FROM PYTHON SOURCE LINES 132-155

.. code-block:: default


    import mne
    import matplotlib.pyplot as plt
    import numpy as np


    def plot_psd(data, axis, label, color):
        psds, freqs = mne.time_frequency.psd_array_multitaper(data, sfreq=sfreq,
                                                              fmin=0.1, fmax=100)
        psds = 10. * np.log10(psds)
        psds_mean = psds.mean(0).mean(0)
        axis.plot(freqs, psds_mean, color=color, label=label)


    _, ax = plt.subplots()
    plot_psd(X, ax, 'original', 'k')
    plot_psd(X_tr, ax, 'shifted', 'r')

    ax.set(title='Multitaper PSD (gradiometers)', xlabel='Frequency (Hz)',
           ylabel='Power Spectral Density (dB)')
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/images/sphx_glr_plot_data_augmentation_001.png
   :alt: Multitaper PSD (gradiometers)
   :srcset: /auto_examples/images/sphx_glr_plot_data_augmentation_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 156-166

Training a model with data augmentation
---------------------------------------

Now that we know how to instantiate ``Transforms``, it is time to learn how
to use them to train a model and try to improve its generalization power.
Let's first create a model.

Create model
~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 168-169

The model to be trained is defined as usual.

.. GENERATED FROM PYTHON SOURCE LINES 169-195

.. code-block:: default


    from braindecode.util import set_random_seeds
    from braindecode.models import ShallowFBCSPNet

    cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it
    device = 'cuda' if cuda else 'cpu'
    if cuda:
        torch.backends.cudnn.benchmark = True

    # Set random seed to be able to reproduce results
    seed = 20200220
    set_random_seeds(seed=seed, cuda=cuda)

    n_classes = 4

    # Extract number of chans and time steps from dataset
    n_channels = train_set[0][0].shape[0]
    input_window_samples = train_set[0][0].shape[1]

    model = ShallowFBCSPNet(
        n_channels,
        n_classes,
        input_window_samples=input_window_samples,
        final_conv_length='auto',
    )








.. GENERATED FROM PYTHON SOURCE LINES 196-199

Create an EEGClassifier with the desired augmentation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 201-204

In order to train with data augmentation, a custom data loader can be
for the training. Multiple transforms can be passed to it and will be applied
sequentially to the batched data within the ``AugmentedDataLoader`` object.

.. GENERATED FROM PYTHON SOURCE LINES 204-224

.. code-block:: default


    from braindecode.augmentation import AugmentedDataLoader, SignFlip

    freq_shift = FrequencyShift(
        probability=.5,
        sfreq=sfreq,
        max_delta_freq=-2.  # the frequency shifts are sampled now between -2 and 2 Hz
    )

    sign_flip = SignFlip(probability=.1)

    transforms = [
        freq_shift,
        sign_flip
    ]

    # Send model to GPU
    if cuda:
        model.cuda()








.. GENERATED FROM PYTHON SOURCE LINES 225-228

The model is now trained as in the trial-wise example. The
``AugmentedDataLoader`` is used as the train iterator and the list of
transforms are passed as arguments.

.. GENERATED FROM PYTHON SOURCE LINES 228-255

.. code-block:: default


    lr = 0.0625 * 0.01
    weight_decay = 0

    batch_size = 64
    n_epochs = 4

    clf = EEGClassifier(
        model,
        iterator_train=AugmentedDataLoader,  # This tells EEGClassifier to use a custom DataLoader
        iterator_train__transforms=transforms,  # This sets the augmentations to use
        criterion=torch.nn.NLLLoss,
        optimizer=torch.optim.AdamW,
        train_split=predefined_split(valid_set),  # using valid_set for validation
        optimizer__lr=lr,
        optimizer__weight_decay=weight_decay,
        batch_size=batch_size,
        callbacks=[
            "accuracy",
            ("lr_scheduler", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),
        ],
        device=device,
    )
    # Model training for a specified number of epochs. `y` is None as it is already
    # supplied in the dataset.
    clf.fit(train_set, y=None, epochs=n_epochs)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

      epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur
    -------  ----------------  ------------  ----------------  ------------  ------  ------
          1            0.2708        1.6129            0.2674        5.5205  0.0006  5.1729
          2            0.2639        1.2147            0.2535        6.1279  0.0005  5.0448
          3            0.2639        1.0976            0.2535        5.0851  0.0002  5.0286
          4            0.2674        1.0492            0.2569        3.8832  0.0000  4.9926

    <class 'braindecode.classifier.EEGClassifier'>[initialized](
      module_=ShallowFBCSPNet(
        (ensuredims): Ensure4d()
        (dimshuffle): Expression(expression=transpose_time_to_spat) 
        (conv_time): Conv2d(1, 40, kernel_size=(25, 1), stride=(1, 1))
        (conv_spat): Conv2d(40, 40, kernel_size=(1, 22), stride=(1, 1), bias=False)
        (bnorm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_nonlin_exp): Expression(expression=square) 
        (pool): AvgPool2d(kernel_size=(75, 1), stride=(15, 1), padding=0)
        (pool_nonlin_exp): Expression(expression=safe_log) 
        (drop): Dropout(p=0.5, inplace=False)
        (conv_classifier): Conv2d(40, 4, kernel_size=(69, 1), stride=(1, 1))
        (softmax): LogSoftmax(dim=1)
        (squeeze): Expression(expression=squeeze_final_output) 
      ),
    )



.. GENERATED FROM PYTHON SOURCE LINES 256-261

Manually composing Transforms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

It would be equivalent (although more verbose) to pass to ``EEGClassifier`` a
composition of the same transforms:

.. GENERATED FROM PYTHON SOURCE LINES 261-266

.. code-block:: default


    from braindecode.augmentation import Compose

    composed_transforms = Compose(transforms=transforms)








.. GENERATED FROM PYTHON SOURCE LINES 267-275

Setting the data augmentation at the Dataset level
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Also note that it is also possible for most of the transforms to pass them
directly to the WindowsDataset object through the `transform` argument, as
most commonly done in other libraries. However, it is advised to use the
``AugmentedDataLoader`` as above, as it is compatible with all transforms and
can be more efficient.

.. GENERATED FROM PYTHON SOURCE LINES 275-277

.. code-block:: default


    train_set.transform = composed_transforms








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  32.759 seconds)

**Estimated memory usage:**  1571 MB


.. _sphx_glr_download_auto_examples_plot_data_augmentation.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_data_augmentation.py <plot_data_augmentation.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_data_augmentation.ipynb <plot_data_augmentation.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
