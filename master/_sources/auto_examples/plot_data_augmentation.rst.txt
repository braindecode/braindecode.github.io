
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_data_augmentation.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_data_augmentation.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_data_augmentation.py:


Data Augmentation on BCIC IV 2a Dataset
=======================================

This tutorial shows how to train EEG deep models with data augmentation. It
follows the trial-wise decoding example and also illustrates the effect of a
transform on the input signals.

.. contents:: This example covers:
   :local:
   :depth: 2

.. GENERATED FROM PYTHON SOURCE LINES 14-20

.. code-block:: default


    # Authors: Simon Brandt <simonbrandt@protonmail.com>
    #          Cédric Rommel <cedric.rommel@inria.fr>
    #
    # License: BSD (3-clause)








.. GENERATED FROM PYTHON SOURCE LINES 21-26

Loading and preprocessing the dataset
-------------------------------------

Loading
~~~~~~~

.. GENERATED FROM PYTHON SOURCE LINES 26-36

.. code-block:: default


    from skorch.helper import predefined_split
    from skorch.callbacks import LRScheduler

    from braindecode import EEGClassifier
    from braindecode.datasets import MOABBDataset

    subject_id = 3
    dataset = MOABBDataset(dataset_name="BNCI2014001", subject_ids=[subject_id])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|                                              | 0.00/44.1M [00:00<?, ?B/s]      0%|                                   | 1.02k/44.1M [00:00<1:28:55, 8.26kB/s]      0%|                                     | 17.4k/44.1M [00:00<09:09, 80.1kB/s]      0%|                                      | 33.8k/44.1M [00:00<07:07, 103kB/s]      0%|                                      | 50.2k/44.1M [00:00<06:27, 114kB/s]      0%|                                      | 82.9k/44.1M [00:00<04:24, 167kB/s]      0%|                                       | 100k/44.1M [00:00<04:40, 157kB/s]      0%|                                       | 132k/44.1M [00:00<03:53, 188kB/s]      0%|▏                                      | 165k/44.1M [00:01<03:28, 211kB/s]      0%|▏                                      | 198k/44.1M [00:01<03:13, 226kB/s]      1%|▏                                      | 230k/44.1M [00:01<03:05, 237kB/s]      1%|▏                                      | 263k/44.1M [00:01<02:59, 244kB/s]      1%|▎                                      | 312k/44.1M [00:01<02:31, 288kB/s]      1%|▎                                      | 361k/44.1M [00:01<02:16, 319kB/s]      1%|▍                                      | 427k/44.1M [00:01<01:55, 379kB/s]      1%|▍                                      | 476k/44.1M [00:01<01:54, 382kB/s]      1%|▍                                      | 542k/44.1M [00:02<01:42, 424kB/s]      1%|▌                                      | 607k/44.1M [00:02<01:36, 453kB/s]      2%|▌                                      | 673k/44.1M [00:02<01:31, 473kB/s]      2%|▋                                      | 755k/44.1M [00:02<01:22, 526kB/s]      2%|▋                                      | 820k/44.1M [00:02<01:22, 524kB/s]      2%|▊                                      | 902k/44.1M [00:02<01:16, 562kB/s]      2%|▊                                      | 984k/44.1M [00:02<01:13, 588kB/s]      2%|▉                                     | 1.10M/44.1M [00:02<01:02, 685kB/s]      3%|█                                     | 1.21M/44.1M [00:03<00:57, 751kB/s]      3%|█▏                                    | 1.31M/44.1M [00:03<00:56, 760kB/s]      3%|█▏                                    | 1.44M/44.1M [00:03<00:51, 829kB/s]      4%|█▎                                    | 1.57M/44.1M [00:03<00:47, 892kB/s]      4%|█▍                                    | 1.70M/44.1M [00:03<00:45, 933kB/s]      4%|█▌                                   | 1.85M/44.1M [00:03<00:42, 1.00MB/s]      5%|█▋                                   | 2.02M/44.1M [00:03<00:38, 1.08MB/s]      5%|█▊                                   | 2.18M/44.1M [00:03<00:36, 1.15MB/s]      5%|█▉                                   | 2.34M/44.1M [00:04<00:34, 1.19MB/s]      6%|██                                   | 2.52M/44.1M [00:04<00:33, 1.24MB/s]      6%|██▎                                  | 2.74M/44.1M [00:04<00:30, 1.38MB/s]      7%|██▍                                  | 2.92M/44.1M [00:04<00:29, 1.39MB/s]      7%|██▋                                  | 3.16M/44.1M [00:04<00:26, 1.55MB/s]      8%|██▊                                  | 3.41M/44.1M [00:04<00:24, 1.65MB/s]      8%|███                                  | 3.62M/44.1M [00:04<00:24, 1.66MB/s]      9%|███▎                                 | 3.90M/44.1M [00:04<00:22, 1.82MB/s]     10%|███▌                                 | 4.20M/44.1M [00:05<00:20, 1.97MB/s]     10%|███▋                                 | 4.46M/44.1M [00:05<00:19, 2.01MB/s]     11%|████                                 | 4.77M/44.1M [00:05<00:18, 2.15MB/s]     12%|████▎                                | 5.13M/44.1M [00:05<00:16, 2.36MB/s]     12%|████▌                                | 5.49M/44.1M [00:05<00:15, 2.51MB/s]     13%|████▉                                | 5.87M/44.1M [00:05<00:14, 2.65MB/s]     14%|█████▎                               | 6.31M/44.1M [00:05<00:13, 2.90MB/s]     15%|█████▋                               | 6.77M/44.1M [00:05<00:11, 3.13MB/s]     17%|██████                               | 7.28M/44.1M [00:06<00:10, 3.35MB/s]     18%|██████▌                              | 7.83M/44.1M [00:06<00:09, 3.67MB/s]     19%|███████                              | 8.44M/44.1M [00:06<00:08, 4.00MB/s]     21%|███████▋                             | 9.13M/44.1M [00:06<00:07, 4.43MB/s]     22%|████████▎                            | 9.85M/44.1M [00:06<00:07, 4.82MB/s]     24%|████████▉                            | 10.7M/44.1M [00:06<00:06, 5.36MB/s]     26%|█████████▋                           | 11.6M/44.1M [00:06<00:05, 5.80MB/s]     28%|██████████▍                          | 12.5M/44.1M [00:06<00:05, 6.28MB/s]     31%|███████████▎                         | 13.5M/44.1M [00:07<00:04, 6.78MB/s]     33%|████████████▏                        | 14.5M/44.1M [00:07<00:04, 7.16MB/s]     36%|█████████████▏                       | 15.6M/44.1M [00:07<00:03, 7.65MB/s]     38%|██████████████▏                      | 16.8M/44.1M [00:07<00:03, 8.16MB/s]     41%|███████████████▏                     | 18.2M/44.1M [00:07<00:02, 8.83MB/s]     44%|████████████████▎                    | 19.5M/44.1M [00:07<00:02, 9.37MB/s]     48%|█████████████████▌                   | 21.0M/44.1M [00:07<00:02, 10.0MB/s]     51%|██████████████████▉                  | 22.5M/44.1M [00:07<00:02, 10.8MB/s]     55%|████████████████████▎                | 24.2M/44.1M [00:08<00:01, 11.5MB/s]     59%|█████████████████████▊               | 26.0M/44.1M [00:08<00:01, 12.3MB/s]     63%|███████████████████████▍             | 27.9M/44.1M [00:08<00:01, 13.1MB/s]     68%|█████████████████████████▏           | 30.0M/44.1M [00:08<00:01, 14.0MB/s]     73%|██████████████████████████▉          | 32.1M/44.1M [00:08<00:00, 15.0MB/s]     78%|████████████████████████████▉        | 34.4M/44.1M [00:08<00:00, 16.0MB/s]     84%|███████████████████████████████      | 36.9M/44.1M [00:08<00:00, 17.0MB/s]     90%|█████████████████████████████████▏   | 39.5M/44.1M [00:08<00:00, 18.2MB/s]     96%|███████████████████████████████████▍ | 42.2M/44.1M [00:09<00:00, 20.2MB/s]      0%|                                              | 0.00/44.1M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 44.1M/44.1M [00:00<00:00, 80.1GB/s]
      0%|                                              | 0.00/42.3M [00:00<?, ?B/s]      0%|                                   | 1.02k/42.3M [00:00<1:27:47, 8.03kB/s]      0%|                                     | 17.4k/42.3M [00:00<08:57, 78.8kB/s]      0%|                                      | 33.8k/42.3M [00:00<06:56, 101kB/s]      0%|                                      | 50.2k/42.3M [00:00<06:17, 112kB/s]      0%|                                      | 82.9k/42.3M [00:00<04:17, 164kB/s]      0%|                                       | 100k/42.3M [00:00<04:32, 155kB/s]      0%|                                       | 132k/42.3M [00:00<03:47, 186kB/s]      0%|▏                                      | 165k/42.3M [00:01<03:22, 208kB/s]      0%|▏                                      | 186k/42.3M [00:01<03:35, 196kB/s]      1%|▏                                      | 214k/42.3M [00:01<03:28, 202kB/s]      1%|▏                                      | 263k/42.3M [00:01<02:42, 258kB/s]      1%|▎                                      | 296k/42.3M [00:01<02:42, 258kB/s]      1%|▎                                      | 329k/42.3M [00:01<02:42, 258kB/s]      1%|▎                                      | 361k/42.3M [00:01<02:42, 258kB/s]      1%|▍                                      | 411k/42.3M [00:01<02:21, 296kB/s]      1%|▍                                      | 443k/42.3M [00:02<02:27, 285kB/s]      1%|▍                                      | 493k/42.3M [00:02<02:12, 315kB/s]      1%|▌                                      | 558k/42.3M [00:02<01:51, 375kB/s]      2%|▌                                      | 640k/42.3M [00:02<01:31, 455kB/s]      2%|▋                                      | 722k/42.3M [00:02<01:21, 511kB/s]      2%|▋                                      | 787k/42.3M [00:02<01:21, 513kB/s]      2%|▊                                      | 886k/42.3M [00:02<01:10, 588kB/s]      2%|▉                                      | 984k/42.3M [00:02<01:04, 641kB/s]      3%|▉                                     | 1.10M/42.3M [00:03<00:57, 719kB/s]      3%|█                                     | 1.21M/42.3M [00:03<00:53, 771kB/s]      3%|█▏                                    | 1.31M/42.3M [00:03<00:53, 771kB/s]      3%|█▎                                    | 1.43M/42.3M [00:03<00:50, 807kB/s]      4%|█▍                                    | 1.56M/42.3M [00:03<00:46, 874kB/s]      4%|█▌                                    | 1.69M/42.3M [00:03<00:44, 920kB/s]      4%|█▋                                    | 1.82M/42.3M [00:03<00:42, 952kB/s]      5%|█▋                                   | 1.98M/42.3M [00:03<00:38, 1.05MB/s]      5%|█▊                                   | 2.13M/42.3M [00:04<00:37, 1.08MB/s]      6%|██                                   | 2.33M/42.3M [00:04<00:33, 1.20MB/s]      6%|██▏                                  | 2.54M/42.3M [00:04<00:29, 1.34MB/s]      6%|██▍                                  | 2.72M/42.3M [00:04<00:29, 1.36MB/s]      7%|██▌                                  | 2.95M/42.3M [00:04<00:26, 1.49MB/s]      7%|██▊                                  | 3.16M/42.3M [00:04<00:25, 1.54MB/s]      8%|██▉                                  | 3.43M/42.3M [00:04<00:23, 1.68MB/s]      9%|███▏                                 | 3.70M/42.3M [00:04<00:21, 1.83MB/s]      9%|███▍                                 | 3.93M/42.3M [00:05<00:21, 1.82MB/s]     10%|███▋                                 | 4.24M/42.3M [00:05<00:18, 2.01MB/s]     11%|███▉                                 | 4.56M/42.3M [00:05<00:17, 2.13MB/s]     12%|████▎                                | 4.90M/42.3M [00:05<00:16, 2.30MB/s]     12%|████▌                                | 5.24M/42.3M [00:05<00:15, 2.41MB/s]     13%|████▉                                | 5.64M/42.3M [00:05<00:14, 2.58MB/s]     14%|█████▎                               | 6.03M/42.3M [00:05<00:13, 2.73MB/s]     15%|█████▋                               | 6.46M/42.3M [00:06<00:12, 2.91MB/s]     16%|██████                               | 6.88M/42.3M [00:06<00:11, 3.04MB/s]     17%|██████▍                              | 7.36M/42.3M [00:06<00:10, 3.24MB/s]     19%|██████▉                              | 7.87M/42.3M [00:06<00:10, 3.42MB/s]     20%|███████▎                             | 8.36M/42.3M [00:06<00:09, 3.55MB/s]     21%|███████▊                             | 8.93M/42.3M [00:06<00:08, 3.83MB/s]     22%|████████▎                            | 9.52M/42.3M [00:06<00:08, 4.05MB/s]     24%|████████▉                            | 10.2M/42.3M [00:06<00:07, 4.37MB/s]     26%|█████████▍                           | 10.9M/42.3M [00:07<00:06, 4.68MB/s]     27%|██████████▏                          | 11.6M/42.3M [00:07<00:06, 4.98MB/s]     29%|██████████▊                          | 12.4M/42.3M [00:07<00:05, 5.34MB/s]     31%|███████████▌                         | 13.2M/42.3M [00:07<00:05, 5.69MB/s]     33%|████████████▎                        | 14.1M/42.3M [00:07<00:04, 6.10MB/s]     36%|█████████████▏                       | 15.1M/42.3M [00:07<00:04, 6.58MB/s]     38%|██████████████▏                      | 16.2M/42.3M [00:07<00:03, 7.10MB/s]     41%|███████████████▏                     | 17.3M/42.3M [00:07<00:03, 7.67MB/s]     44%|████████████████▎                    | 18.6M/42.3M [00:08<00:02, 8.33MB/s]     47%|█████████████████▍                   | 20.0M/42.3M [00:08<00:02, 9.07MB/s]     51%|██████████████████▊                  | 21.5M/42.3M [00:08<00:02, 9.88MB/s]     55%|████████████████████▏                | 23.1M/42.3M [00:08<00:01, 10.7MB/s]     59%|█████████████████████▋               | 24.9M/42.3M [00:08<00:01, 11.6MB/s]     63%|███████████████████████▍             | 26.8M/42.3M [00:08<00:01, 12.6MB/s]     68%|█████████████████████████▏           | 28.8M/42.3M [00:08<00:00, 13.6MB/s]     73%|███████████████████████████▏         | 31.1M/42.3M [00:08<00:00, 14.8MB/s]     79%|█████████████████████████████▎       | 33.5M/42.3M [00:09<00:00, 15.9MB/s]     85%|███████████████████████████████▌     | 36.0M/42.3M [00:09<00:00, 17.2MB/s]     91%|█████████████████████████████████▊   | 38.7M/42.3M [00:09<00:00, 18.2MB/s]     98%|████████████████████████████████████▏| 41.4M/42.3M [00:09<00:00, 19.1MB/s]      0%|                                              | 0.00/42.3M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 42.3M/42.3M [00:00<00:00, 99.2GB/s]




.. GENERATED FROM PYTHON SOURCE LINES 37-40

Preprocessing
~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 40-60

.. code-block:: default


    from braindecode.preprocessing import (
        exponential_moving_standardize, preprocess, Preprocessor, scale)

    low_cut_hz = 4.  # low cut frequency for filtering
    high_cut_hz = 38.  # high cut frequency for filtering
    # Parameters for exponential moving standardization
    factor_new = 1e-3
    init_block_size = 1000

    preprocessors = [
        Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors
        Preprocessor(scale, factor=1e6, apply_on_array=True),  # Convert from V to uV
        Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter
        Preprocessor(exponential_moving_standardize,  # Exponential moving standardization
                     factor_new=factor_new, init_block_size=init_block_size)
    ]

    preprocess(dataset, preprocessors)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /usr/share/miniconda/envs/braindecode/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function scale is deprecated; will be removed in 0.7.0. Use numpy.multiply instead.
      warnings.warn(msg, category=FutureWarning)

    <braindecode.datasets.moabb.MOABBDataset object at 0x7fa9b2f8b150>



.. GENERATED FROM PYTHON SOURCE LINES 61-64

Extracting windows
~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 64-83

.. code-block:: default


    from braindecode.preprocessing import create_windows_from_events

    trial_start_offset_seconds = -0.5
    # Extract sampling frequency, check that they are same in all datasets
    sfreq = dataset.datasets[0].raw.info['sfreq']
    assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])
    # Calculate the trial start offset in samples.
    trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)

    # Create windows using braindecode function for this. It needs parameters to
    # define how trials should be used.
    windows_dataset = create_windows_from_events(
        dataset,
        trial_start_offset_samples=trial_start_offset_samples,
        trial_stop_offset_samples=0,
        preload=True,
    )








.. GENERATED FROM PYTHON SOURCE LINES 84-87

Split dataset into train and valid
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


.. GENERATED FROM PYTHON SOURCE LINES 87-92

.. code-block:: default


    splitted = windows_dataset.split('session')
    train_set = splitted['session_T']
    valid_set = splitted['session_E']








.. GENERATED FROM PYTHON SOURCE LINES 93-102

Defining a Transform
--------------------

Data can be manipulated by transforms, which are callable objects. A
transform is usually handled by a custom data loader, but can also be called
directly on input data, as demonstrated below for illutrative purposes.

First, we need to define a Transform. Here we chose the FrequencyShift, which
randomly translates all frequencies within a given range.

.. GENERATED FROM PYTHON SOURCE LINES 102-111

.. code-block:: default


    from braindecode.augmentation import FrequencyShift

    transform = FrequencyShift(
        probability=1.,  # defines the probability of actually modifying the input
        sfreq=sfreq,
        max_delta_freq=2.  # the frequency shifts are sampled now between -2 and 2 Hz
    )








.. GENERATED FROM PYTHON SOURCE LINES 112-118

Manipulating one session and visualizing the transformed data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


Next, let us augment one session to show the resulting frequency shift. The
data of an mne Epoch is used here to make usage of mne functions.

.. GENERATED FROM PYTHON SOURCE LINES 118-127

.. code-block:: default


    import torch

    epochs = train_set.datasets[0].windows  # original epochs
    X = epochs.get_data()
    # This allows to apply the transform with a fixed shift (10 Hz) for
    # visualization instead of sampling the shift randomly between -2 and 2 Hz
    X_tr, _ = transform.operation(torch.as_tensor(X).float(), None, 10., sfreq)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/braindecode/braindecode/braindecode/augmentation/functional.py:547: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1651023291532/work/aten/src/ATen/native/TensorShape.cpp:2314.)
      N_padded, n_channels, 1).T




.. GENERATED FROM PYTHON SOURCE LINES 128-130

The psd of the transformed session has now been shifted by 10 Hz, as one can
see on the psd plot.

.. GENERATED FROM PYTHON SOURCE LINES 130-153

.. code-block:: default


    import mne
    import matplotlib.pyplot as plt
    import numpy as np


    def plot_psd(data, axis, label, color):
        psds, freqs = mne.time_frequency.psd_array_multitaper(data, sfreq=sfreq,
                                                              fmin=0.1, fmax=100)
        psds = 10. * np.log10(psds)
        psds_mean = psds.mean(0).mean(0)
        axis.plot(freqs, psds_mean, color=color, label=label)


    _, ax = plt.subplots()
    plot_psd(X, ax, 'original', 'k')
    plot_psd(X_tr.numpy(), ax, 'shifted', 'r')

    ax.set(title='Multitaper PSD (gradiometers)', xlabel='Frequency (Hz)',
           ylabel='Power Spectral Density (dB)')
    ax.legend()
    plt.show()




.. image-sg:: /auto_examples/images/sphx_glr_plot_data_augmentation_001.png
   :alt: Multitaper PSD (gradiometers)
   :srcset: /auto_examples/images/sphx_glr_plot_data_augmentation_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 154-165

Training a model with data augmentation
---------------------------------------

Now that we know how to instantiate ``Transforms``, it is time to learn how
to use them to train a model and try to improve its generalization power.
Let's first create a model.

Create model
~~~~~~~~~~~~

The model to be trained is defined as usual.

.. GENERATED FROM PYTHON SOURCE LINES 165-196

.. code-block:: default


    from braindecode.util import set_random_seeds
    from braindecode.models import ShallowFBCSPNet

    cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it
    device = 'cuda' if cuda else 'cpu'
    if cuda:
        torch.backends.cudnn.benchmark = True

    # Set random seed to be able to roughly reproduce results
    # Note that with cudnn benchmark set to True, GPU indeterminism
    # may still make results substantially different between runs.
    # To obtain more consistent results at the cost of increased computation time,
    # you can set `cudnn_benchmark=False` in `set_random_seeds`
    # or remove `torch.backends.cudnn.benchmark = True`
    seed = 20200220
    set_random_seeds(seed=seed, cuda=cuda)

    n_classes = 4

    # Extract number of chans and time steps from dataset
    n_channels = train_set[0][0].shape[0]
    input_window_samples = train_set[0][0].shape[1]

    model = ShallowFBCSPNet(
        n_channels,
        n_classes,
        input_window_samples=input_window_samples,
        final_conv_length='auto',
    )








.. GENERATED FROM PYTHON SOURCE LINES 197-203

Create an EEGClassifier with the desired augmentation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In order to train with data augmentation, a custom data loader can be
for the training. Multiple transforms can be passed to it and will be applied
sequentially to the batched data within the ``AugmentedDataLoader`` object.

.. GENERATED FROM PYTHON SOURCE LINES 203-223

.. code-block:: default


    from braindecode.augmentation import AugmentedDataLoader, SignFlip

    freq_shift = FrequencyShift(
        probability=.5,
        sfreq=sfreq,
        max_delta_freq=2.  # the frequency shifts are sampled now between -2 and 2 Hz
    )

    sign_flip = SignFlip(probability=.1)

    transforms = [
        freq_shift,
        sign_flip
    ]

    # Send model to GPU
    if cuda:
        model.cuda()








.. GENERATED FROM PYTHON SOURCE LINES 224-227

The model is now trained as in the trial-wise example. The
``AugmentedDataLoader`` is used as the train iterator and the list of
transforms are passed as arguments.

.. GENERATED FROM PYTHON SOURCE LINES 227-254

.. code-block:: default


    lr = 0.0625 * 0.01
    weight_decay = 0

    batch_size = 64
    n_epochs = 4

    clf = EEGClassifier(
        model,
        iterator_train=AugmentedDataLoader,  # This tells EEGClassifier to use a custom DataLoader
        iterator_train__transforms=transforms,  # This sets the augmentations to use
        criterion=torch.nn.NLLLoss,
        optimizer=torch.optim.AdamW,
        train_split=predefined_split(valid_set),  # using valid_set for validation
        optimizer__lr=lr,
        optimizer__weight_decay=weight_decay,
        batch_size=batch_size,
        callbacks=[
            "accuracy",
            ("lr_scheduler", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),
        ],
        device=device,
    )
    # Model training for a specified number of epochs. `y` is None as it is already
    # supplied in the dataset.
    clf.fit(train_set, y=None, epochs=n_epochs)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr     dur
    -------  ----------------  ------------  ----------------  ------------  ------  ------
          1            0.2569        1.6225            0.2431        5.5638  0.0006  6.2091
          2            0.2535        1.2218            0.2535        6.3999  0.0005  6.0876
          3            0.2535        1.0973            0.2535        5.2948  0.0002  6.0664
          4            0.2639        1.0922            0.2535        4.0277  0.0000  6.0219

    <class 'braindecode.classifier.EEGClassifier'>[initialized](
      module_=ShallowFBCSPNet(
        (ensuredims): Ensure4d()
        (dimshuffle): Expression(expression=transpose_time_to_spat) 
        (conv_time): Conv2d(1, 40, kernel_size=(25, 1), stride=(1, 1))
        (conv_spat): Conv2d(40, 40, kernel_size=(1, 22), stride=(1, 1), bias=False)
        (bnorm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv_nonlin_exp): Expression(expression=square) 
        (pool): AvgPool2d(kernel_size=(75, 1), stride=(15, 1), padding=0)
        (pool_nonlin_exp): Expression(expression=safe_log) 
        (drop): Dropout(p=0.5, inplace=False)
        (conv_classifier): Conv2d(40, 4, kernel_size=(69, 1), stride=(1, 1))
        (softmax): LogSoftmax(dim=1)
        (squeeze): Expression(expression=squeeze_final_output) 
      ),
    )



.. GENERATED FROM PYTHON SOURCE LINES 255-260

Manually composing Transforms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

It would be equivalent (although more verbose) to pass to ``EEGClassifier`` a
composition of the same transforms:

.. GENERATED FROM PYTHON SOURCE LINES 260-265

.. code-block:: default


    from braindecode.augmentation import Compose

    composed_transforms = Compose(transforms=transforms)








.. GENERATED FROM PYTHON SOURCE LINES 266-274

Setting the data augmentation at the Dataset level
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Also note that it is also possible for most of the transforms to pass them
directly to the WindowsDataset object through the `transform` argument, as
most commonly done in other libraries. However, it is advised to use the
``AugmentedDataLoader`` as above, as it is compatible with all transforms and
can be more efficient.

.. GENERATED FROM PYTHON SOURCE LINES 274-276

.. code-block:: default


    train_set.transform = composed_transforms








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  58.910 seconds)

**Estimated memory usage:**  1127 MB


.. _sphx_glr_download_auto_examples_plot_data_augmentation.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_data_augmentation.py <plot_data_augmentation.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_data_augmentation.ipynb <plot_data_augmentation.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
