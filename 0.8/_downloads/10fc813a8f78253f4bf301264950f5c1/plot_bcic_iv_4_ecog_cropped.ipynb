{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fingers flexion cropped decoding on BCIC IV 4 ECoG Dataset\n\nThis tutorial shows you how to train and test deep learning models with\nBraindecode on ECoG BCI IV competition dataset 4 using cropped mode. For this\ndataset we will predict 5 regression targets corresponding to flexion of each finger.\nThe targets were recorded as a time series (each 25 Hz), so this tutorial is\nan example of time series target prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Maciej Sliwowski <maciek.sliwowski@gmail.com>\n#          Mohammed Fattouh <mo.fattouh@gmail.com>\n#\n# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading and preparing the dataset\n\n### Loading\n\nFirst, we load the data. In this tutorial, we use the functionality of braindecode\nto load [BCI IV competition dataset 4](http://www.bbci.de/competition/iv/#dataset4)_.\nThe dataset is available as a part of ECoG library:\nhttps://searchworks.stanford.edu/view/zk881ps0522\n\nThe dataset contains ECoG signal and time series of 5 targets corresponding\nto each finger flexion. This is different than standard decoding setup for EEG with\nmultiple trials and usually one target per trial. Here, fingers flexions change in time\nand are recorded with sampling frequency equals to 25 Hz.\n\nIf this dataset is used please cite [1].\n\n[1] Miller, Kai J. \"A library of human electrocorticographic data and analyses.\n\"Nature human behaviour 3, no. 11 (2019): 1225-1235. https://doi.org/10.1038/s41562-019-0678-3\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copy\n\nimport numpy as np\nimport sklearn\nfrom mne import set_log_level\n\nfrom braindecode.datasets import BCICompetitionIVDataset4\n\nsubject_id = 1\ndataset = BCICompetitionIVDataset4(subject_ids=[subject_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset into train and test\n\nWe can easily split the dataset using additional info stored in the\ndescription attribute, in this case ``session`` column. We select `train` dataset\nfor training and validation and `test` for final evaluation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = dataset.split('session')\ntrain_set = dataset['train']\ntest_set = dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing\n\nNow we apply preprocessing like bandpass filtering to our dataset. You\ncan either apply functions provided by\n[mne.Raw](https://mne.tools/stable/generated/mne.io.Raw.html)_ or\n[mne.Epochs](https://mne.tools/0.11/generated/mne.Epochs.html#mne.Epochs)_\nor apply your own functions, either to the MNE object or the underlying\nnumpy array.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Preprocessing steps are taken from a standard EEG processing pipeline.\n   The only change is the cutoff frequency of the filter. For a proper ECoG\n   decoding other preprocessing steps may be needed.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>These prepocessings are now directly applied to the loaded\n   data, and not on-the-fly applied as transformations in\n   PyTorch-libraries like\n   [torchvision](https://pytorch.org/docs/stable/torchvision/index.html)_.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing import (Preprocessor,\n                                       exponential_moving_standardize,\n                                       preprocess)\n\nlow_cut_hz = 1.  # low cut frequency for filtering\nhigh_cut_hz = 200.  # high cut frequency for filtering, for ECoG higher than for EEG\n# Parameters for exponential moving standardization\nfactor_new = 1e-3\ninit_block_size = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We select only first 30 seconds from the training dataset to limit time and memory\nto run this example. We split training dataset into train and validation (only 6 seconds).\nTo obtain full results whole datasets should be used.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "valid_set = preprocess(copy.deepcopy(train_set),\n                       [Preprocessor('crop', tmin=24, tmax=30)], n_jobs=-1)\npreprocess(train_set, [Preprocessor('crop', tmin=0, tmax=24)], n_jobs=-1)\npreprocess(test_set, [Preprocessor('crop', tmin=0, tmax=24)], n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In time series targets setup, targets variables are stored in mne.Raw object as channels\nof type `misc`. Thus those channels have to be selected for further processing. However,\nmany mne functions ignore `misc` channels and perform operations only on data channels\n(see https://mne.tools/stable/glossary.html#term-data-channels).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "preprocessors = [\n    # TODO: ensure that misc is not removed\n    Preprocessor('pick_types', ecog=True, misc=True),\n    Preprocessor(lambda x: x / 1e6, picks='ecog'),  # Convert from V to uV\n    Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n    Preprocessor(exponential_moving_standardize,  # Exponential moving standardization\n                 factor_new=factor_new, init_block_size=init_block_size, picks='ecog')\n]\n# Transform the data\npreprocess(train_set, preprocessors)\npreprocess(valid_set, preprocessors)\npreprocess(test_set, preprocessors)\n\n# Extract sampling frequency, check that they are same in all datasets\nsfreq = train_set.datasets[0].raw.info['sfreq']\nassert all([ds.raw.info['sfreq'] == sfreq for ds in train_set.datasets])\n# Extract target sampling frequency\ntarget_sfreq = train_set.datasets[0].raw.info['temp']['target_sfreq']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create model\n\nIn contrast to trialwise decoding, we first have to create the model\nbefore we can cut the dataset into windows. This is because we need to\nknow the receptive field of the network to know how large the window\nstride should be.\n\nWe first choose the compute/input window size that will be fed to the\nnetwork during training This has to be larger than the networks\nreceptive field size and can otherwise be chosen for computational\nefficiency (see explanations in the beginning of this tutorial). Here we\nchoose 1000 samples, which is 1 second for the 1000 Hz sampling rate.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_window_samples = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we create the deep learning model! Braindecode comes with some\npredefined convolutional neural network architectures for raw\ntime-domain EEG. Here, we use the shallow ConvNet model from [Deep\nlearning with convolutional neural networks for EEG decoding and\nvisualization](https://arxiv.org/abs/1703.05051)_. These models are\npure [PyTorch](https://pytorch.org)_ deep learning models, therefore\nto use your own model, it just has to be a normal PyTorch\n[nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)_.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nfrom braindecode.models import ShallowFBCSPNet\nfrom braindecode.util import set_random_seeds\n\ncuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\ndevice = 'cuda' if cuda else 'cpu'\nif cuda:\n    torch.backends.cudnn.benchmark = True\n# Set random seed to be able to roughly reproduce results\n# Note that with cudnn benchmark set to True, GPU indeterminism\n# may still make results substantially different between runs.\n# To obtain more consistent results at the cost of increased computation time,\n# you can set `cudnn_benchmark=False` in `set_random_seeds`\n# or remove `torch.backends.cudnn.benchmark = True`\nseed = 20200220\nset_random_seeds(seed=seed, cuda=cuda)\n\nn_classes = 1\n# Extract number of chans and time steps from dataset\nn_chans = train_set[0][0].shape[0] - 5\n\nmodel = ShallowFBCSPNet(\n    n_chans,\n    n_classes,\n    final_conv_length=2,\n    add_log_softmax=False,\n)\n\n# Send model to GPU\nif cuda:\n    model.cuda()\n\nfrom braindecode.models import get_output_shape, to_dense_prediction_model\n\nto_dense_prediction_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To know the models\u2019 receptive field, we calculate the shape of model\noutput for a dummy input.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_preds_per_input = get_output_shape(model, n_chans, input_window_samples)[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cut Compute Windows\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing import create_fixed_length_windows\n\n# Create windows using braindecode function for this. It needs parameters to define how\n# trials should be used.\n\ntrain_set = create_fixed_length_windows(\n    train_set,\n    start_offset_samples=0,\n    stop_offset_samples=None,\n    window_size_samples=input_window_samples,\n    window_stride_samples=n_preds_per_input,\n    drop_last_window=False,\n    targets_from='channels',\n    last_target_only=False,\n    preload=False\n)\n\nvalid_set = create_fixed_length_windows(\n    valid_set,\n    start_offset_samples=0,\n    stop_offset_samples=None,\n    window_size_samples=input_window_samples,\n    window_stride_samples=n_preds_per_input,\n    drop_last_window=False,\n    targets_from='channels',\n    last_target_only=False,\n    preload=False\n)\n\ntest_set = create_fixed_length_windows(\n    test_set,\n    start_offset_samples=0,\n    stop_offset_samples=None,\n    window_size_samples=input_window_samples,\n    window_stride_samples=n_preds_per_input,\n    drop_last_window=False,\n    targets_from='channels',\n    last_target_only=False,\n    preload=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We select only the thumb's finger flexion to create one model per finger.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Methods to predict all 5 fingers flexion with the same model may be considered as well.\n   We encourage you to find your own way to use braindecode models to predict fingers flexions.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_set.target_transform = lambda x: x[0: 1]\nvalid_set.target_transform = lambda x: x[0: 1]\ntest_set.target_transform = lambda x: x[0: 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n\nIn difference to trialwise decoding, we now should supply\n``cropped=True`` to the EEGClassifier, and ``CroppedLoss`` as the\ncriterion, as well as ``criterion__loss_function`` as the loss function\napplied to the meaned predictions.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In this tutorial, we use some default parameters that we\n   have found to work well for EEG motor decoding, however we strongly\n   encourage you to perform your own hyperparameter optimization using\n   cross validation on your training data.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skorch.callbacks import LRScheduler\nfrom skorch.helper import predefined_split\n\nfrom braindecode import EEGRegressor\nfrom braindecode.training import CroppedTimeSeriesEpochScoring, TimeSeriesLoss\n\n# These values we found good for shallow network for EEG MI decoding:\nlr = 0.0625 * 0.01\nweight_decay = 0\nbatch_size = 27  # only 27 examples in train set, otherwise set to 64\nn_epochs = 8\n\nregressor = EEGRegressor(\n    model,\n    cropped=True,\n    aggregate_predictions=False,\n    criterion=TimeSeriesLoss,\n    criterion__loss_function=torch.nn.functional.mse_loss,\n    optimizer=torch.optim.AdamW,\n    train_split=predefined_split(valid_set),\n    optimizer__lr=lr,\n    optimizer__weight_decay=weight_decay,\n    iterator_train__shuffle=True,\n    batch_size=batch_size,\n    callbacks=[\n        (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n        ('r2_train', CroppedTimeSeriesEpochScoring(sklearn.metrics.r2_score,\n                                                   lower_is_better=False,\n                                                   on_train=True,\n                                                   name='r2_train')\n         ),\n        ('r2_valid', CroppedTimeSeriesEpochScoring(sklearn.metrics.r2_score,\n                                                   lower_is_better=False,\n                                                   on_train=False,\n                                                   name='r2_valid')\n         )\n    ],\n    device=device,\n)\nset_log_level(verbose='WARNING')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model training for a specified number of epochs. ``y`` is None as it is already supplied\nin the dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regressor.fit(train_set, y=None, epochs=n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtaining predictions and targets for the test, train, and validation dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def pad_and_select_predictions(preds, y):\n    preds = np.pad(preds,\n                   ((0, 0), (0, 0), (y.shape[2] - preds.shape[2], 0)),\n                   'constant',\n                   constant_values=0)\n\n    mask = ~np.isnan(y[0, 0, :])\n    preds = np.squeeze(preds[..., mask], 0)\n    y = np.squeeze(y[..., mask], 0)\n    return y.T, preds.T\n\n\npreds_train, y_train = regressor.predict_trials(train_set, return_targets=True)\npreds_train, y_train = pad_and_select_predictions(preds_train, y_train)\n\npreds_valid, y_valid = regressor.predict_trials(valid_set, return_targets=True)\npreds_valid, y_valid = pad_and_select_predictions(preds_valid, y_valid)\n\npreds_test, y_test = regressor.predict_trials(test_set, return_targets=True)\npreds_test, y_test = pad_and_select_predictions(preds_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Results\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot target and predicted finger flexion on training, validation, and test sets.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The model is trained and validated on limited dataset (to decrease the time needed to run\n   this example) which does not contain diverse dataset in terms of fingers flexions and may\n   cause overfitting. To obtain better results use whole dataset as well as improve the decoding\n   pipeline which may be not optimal for ECoG.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport pandas as pd\nfrom matplotlib.lines import Line2D\n\nfig, axes = plt.subplots(3, 1, figsize=(8, 9))\n\naxes[0].set_title('Training dataset')\naxes[0].plot(np.arange(y_train.shape[0]) / target_sfreq, y_train[:, 0], label='Target')\naxes[0].plot(np.arange(preds_train.shape[0]) / target_sfreq, preds_train[:, 0],\n             label='Predicted')\naxes[0].set_ylabel('Finger flexion')\naxes[0].legend()\n\naxes[1].set_title('Validation dataset')\naxes[1].plot(np.arange(y_valid.shape[0]) / target_sfreq, y_valid[:, 0], label='Target')\naxes[1].plot(np.arange(preds_valid.shape[0]) / target_sfreq, preds_valid[:, 0],\n             label='Predicted')\naxes[1].set_ylabel('Finger flexion')\naxes[1].legend()\n\naxes[2].set_title('Test dataset')\naxes[2].plot(np.arange(y_test.shape[0]) / target_sfreq, y_test[:, 0], label='Target')\naxes[2].plot(np.arange(preds_test.shape[0]) / target_sfreq, preds_test[:, 0], label='Predicted')\naxes[2].set_xlabel('Time [s]')\naxes[2].set_ylabel('Finger flexion')\naxes[2].legend()\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute correlation coefficients for each finger\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "corr_coeffs = []\nfor dim in range(y_test.shape[1]):\n    corr_coeffs.append(\n        np.corrcoef(preds_test[:, dim], y_test[:, dim])[0, 1]\n    )\nprint('Correlation coefficient for each dimension: ', np.round(corr_coeffs, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we use the history stored by Skorch throughout training to plot\naccuracy and loss curves.\nExtract loss and accuracy values for plotting from history object\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results_columns = ['train_loss', 'valid_loss', 'r2_train', 'r2_valid']\ndf = pd.DataFrame(regressor.history[:, results_columns], columns=results_columns,\n                  index=regressor.history[:, 'epoch'])\n\nfig, ax1 = plt.subplots(figsize=(8, 3))\ndf.loc[:, ['train_loss', 'valid_loss']].plot(\n    ax=ax1, style=['-', ':'], marker='o', color='tab:blue', legend=False, fontsize=14)\n\nax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\nax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\ndf.loc[:, ['r2_train', 'r2_valid']].plot(\n    ax=ax2, style=['-', ':'], marker='o', color='tab:red', legend=False)\nax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\nax2.set_ylabel(\"R2 score\", color='tab:red', fontsize=14)\nax1.set_xlabel(\"Epoch\", fontsize=14)\n\n# where some data has already been plotted to ax\nhandles = []\nhandles.append(Line2D([0], [0], color='black', linewidth=1, linestyle='-',\n                      label='Train'))\nhandles.append(Line2D([0], [0], color='black', linewidth=1, linestyle=':',\n                      label='Valid'))\nplt.legend(handles, [h.get_label() for h in handles], fontsize=14, loc='center right')\nplt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}