{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Data Augmentation on BCIC IV 2a Dataset\n\nThis tutorial shows how to train EEG deep models with data augmentation. It\nfollows the trial-wise decoding example and also illustrates the effect of a\ntransform on the input signals.\n   :depth: 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Simon Brandt <simonbrandt@protonmail.com>\n#          C\u00e9dric Rommel <cedric.rommel@inria.fr>\n#\n# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading and preprocessing the dataset\n\n### Loading\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skorch.helper import predefined_split\nfrom skorch.callbacks import LRScheduler\n\nfrom braindecode import EEGClassifier\nfrom braindecode.datasets import MOABBDataset\n\nsubject_id = 3\ndataset = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids=[subject_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing import (\n    exponential_moving_standardize, preprocess, Preprocessor)\nfrom numpy import multiply\n\nlow_cut_hz = 4.  # low cut frequency for filtering\nhigh_cut_hz = 38.  # high cut frequency for filtering\n# Parameters for exponential moving standardization\nfactor_new = 1e-3\ninit_block_size = 1000\n# Factor to convert from V to uV\nfactor = 1e6\n\npreprocessors = [\n    Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n    Preprocessor(lambda data: multiply(data, factor)),  # Convert from V to uV\n    Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n    Preprocessor(exponential_moving_standardize,  # Exponential moving standardization\n                 factor_new=factor_new, init_block_size=init_block_size)\n]\n\npreprocess(dataset, preprocessors, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting windows\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing import create_windows_from_events\n\ntrial_start_offset_seconds = -0.5\n# Extract sampling frequency, check that they are same in all datasets\nsfreq = dataset.datasets[0].raw.info['sfreq']\nassert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n# Calculate the trial start offset in samples.\ntrial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n\n# Create windows using braindecode function for this. It needs parameters to\n# define how trials should be used.\nwindows_dataset = create_windows_from_events(\n    dataset,\n    trial_start_offset_samples=trial_start_offset_samples,\n    trial_stop_offset_samples=0,\n    preload=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset into train and valid\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splitted = windows_dataset.split('session')\ntrain_set = splitted['0train']  # Session train\nvalid_set = splitted['1test']  # Session evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining a Transform\n\nData can be manipulated by transforms, which are callable objects. A\ntransform is usually handled by a custom data loader, but can also be called\ndirectly on input data, as demonstrated below for illutrative purposes.\n\nFirst, we need to define a Transform. Here we chose the FrequencyShift, which\nrandomly translates all frequencies within a given range.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.augmentation import FrequencyShift\n\ntransform = FrequencyShift(\n    probability=1.,  # defines the probability of actually modifying the input\n    sfreq=sfreq,\n    max_delta_freq=2.  # the frequency shifts are sampled now between -2 and 2 Hz\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manipulating one session and visualizing the transformed data\n\n\nNext, let us augment one session to show the resulting frequency shift. The\ndata of an mne Epoch is used here to make usage of mne functions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport numpy as np\n\nX = np.stack([X for X, y, i in train_set.datasets[0]])\n# This allows to apply the transform with a fixed shift (10 Hz) for\n# visualization instead of sampling the shift randomly between -2 and 2 Hz\nX_tr, _ = transform.operation(torch.as_tensor(X).float(), None, 10., sfreq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The psd of the transformed session has now been shifted by 10 Hz, as one can\nsee on the psd plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mne\nimport matplotlib.pyplot as plt\n\n\ndef plot_psd(data, axis, label, color):\n    psds, freqs = mne.time_frequency.psd_array_multitaper(data, sfreq=sfreq,\n                                                          fmin=0.1, fmax=100)\n    psds = 10. * np.log10(psds)\n    psds_mean = psds.mean(0).mean(0)\n    axis.plot(freqs, psds_mean, color=color, label=label)\n\n\n_, ax = plt.subplots()\nplot_psd(X, ax, 'original', 'k')\nplot_psd(X_tr.numpy(), ax, 'shifted', 'r')\n\nax.set(title='Multitaper PSD (gradiometers)', xlabel='Frequency (Hz)',\n       ylabel='Power Spectral Density (dB)')\nax.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training a model with data augmentation\n\nNow that we know how to instantiate ``Transforms``, it is time to learn how\nto use them to train a model and try to improve its generalization power.\nLet's first create a model.\n\n### Create model\n\nThe model to be trained is defined as usual.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.util import set_random_seeds\nfrom braindecode.models import ShallowFBCSPNet\n\ncuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\ndevice = 'cuda' if cuda else 'cpu'\nif cuda:\n    torch.backends.cudnn.benchmark = True\n\n# Set random seed to be able to roughly reproduce results\n# Note that with cudnn benchmark set to True, GPU indeterminism\n# may still make results substantially different between runs.\n# To obtain more consistent results at the cost of increased computation time,\n# you can set `cudnn_benchmark=False` in `set_random_seeds`\n# or remove `torch.backends.cudnn.benchmark = True`\nseed = 20200220\nset_random_seeds(seed=seed, cuda=cuda)\n\nn_classes = 4\nclasses = list(range(n_classes))\n\n# Extract number of chans and time steps from dataset\nn_channels = train_set[0][0].shape[0]\ninput_window_samples = train_set[0][0].shape[1]\n\nmodel = ShallowFBCSPNet(\n    n_channels,\n    n_classes,\n    input_window_samples=input_window_samples,\n    final_conv_length='auto',\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an EEGClassifier with the desired augmentation\n\nIn order to train with data augmentation, a custom data loader can be\nfor the training. Multiple transforms can be passed to it and will be applied\nsequentially to the batched data within the ``AugmentedDataLoader`` object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.augmentation import AugmentedDataLoader, SignFlip\n\nfreq_shift = FrequencyShift(\n    probability=.5,\n    sfreq=sfreq,\n    max_delta_freq=2.  # the frequency shifts are sampled now between -2 and 2 Hz\n)\n\nsign_flip = SignFlip(probability=.1)\n\ntransforms = [\n    freq_shift,\n    sign_flip\n]\n\n# Send model to GPU\nif cuda:\n    model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model is now trained as in the trial-wise example. The\n``AugmentedDataLoader`` is used as the train iterator and the list of\ntransforms are passed as arguments.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lr = 0.0625 * 0.01\nweight_decay = 0\n\nbatch_size = 64\nn_epochs = 4\n\nclf = EEGClassifier(\n    model,\n    iterator_train=AugmentedDataLoader,  # This tells EEGClassifier to use a custom DataLoader\n    iterator_train__transforms=transforms,  # This sets the augmentations to use\n    criterion=torch.nn.NLLLoss,\n    optimizer=torch.optim.AdamW,\n    train_split=predefined_split(valid_set),  # using valid_set for validation\n    optimizer__lr=lr,\n    optimizer__weight_decay=weight_decay,\n    batch_size=batch_size,\n    callbacks=[\n        \"accuracy\",\n        (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n    ],\n    device=device,\n    classes=classes,\n)\n# Model training for a specified number of epochs. `y` is None as it is already\n# supplied in the dataset.\nclf.fit(train_set, y=None, epochs=n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manually composing Transforms\n\nIt would be equivalent (although more verbose) to pass to ``EEGClassifier`` a\ncomposition of the same transforms:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.augmentation import Compose\n\ncomposed_transforms = Compose(transforms=transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting the data augmentation at the Dataset level\n\nAlso note that it is also possible for most of the transforms to pass them\ndirectly to the WindowsDataset object through the `transform` argument, as\nmost commonly done in other libraries. However, it is advised to use the\n``AugmentedDataLoader`` as above, as it is compatible with all transforms and\ncan be more efficient.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_set.transform = composed_transforms"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}