{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Searching the best data augmentation on BCIC IV 2a Dataset\n\nThis tutorial shows how to search data augmentations using braindecode.\nIndeed, it is known that the best augmentation to use often dependent on the task\nor phenomenon studied. Here we follow the methodology proposed in [1]_ on the\nopenly available BCI IV 2a Dataset.\n\n\n.. topic:: Data Augmentation\n\n    Data augmentation could be a step in training deep learning models.\n    For decoding brain signals, recent studies have shown that artificially\n    generating samples may increase the final performance of a deep learning model [1]_.\n    Other studies have shown that data augmentation can be used to cast\n    a self-supervised paradigm, presenting a more diverse\n    view of the data, both with pretext tasks and contrastive learning [2]_.\n\n\nData augmentation and self-supervised learning approaches demand an intense comparison\nto find the best fit with the data. This view is demonstrated in [1]_ and shows the\nimportance of selecting the right transformation and strength for different type of\ntask considered. Here, we use the augmentation module present in braindecode in\nthe context of trialwise decoding with the BCI IV 2a dataset.\n   :depth: 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Bruno Aristimunha <a.bruno@ufabc.edu.br>\n#          C\u00e9dric Rommel <cedric.rommel@inria.fr>\n# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading and preprocessing the dataset\n\n### Loading\n\nFirst, we load the data. In this tutorial, we use the functionality of braindecode\nto load BCI IV competition dataset 1. The dataset is available on the BNCI website.\nThere is 9 subjects recorded with 22 electrodes while doing a motor imagery task,\nwith 144 trials per class. We will load this dataset through the MOABB library.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from skorch.callbacks import LRScheduler\n\nfrom braindecode import EEGClassifier\nfrom braindecode.datasets import MOABBDataset\n\nsubject_id = 3\ndataset = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids=[subject_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing\n\nWe apply a bandpass filter, from 4 to 38 Hz to focus motor imagery-related\nbrain activity\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing import (\n    exponential_moving_standardize, preprocess, Preprocessor)\nfrom numpy import multiply\n\nlow_cut_hz = 4.  # low cut frequency for filtering\nhigh_cut_hz = 38.  # high cut frequency for filtering\n# Parameters for exponential moving standardization\nfactor_new = 1e-3\ninit_block_size = 1000\n# Factor to convert from V to uV\nfactor = 1e6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In time series targets setup, targets variables are stored in mne.Raw object as channels\nof type `misc`. Thus those channels have to be selected for further processing. However,\nmany mne functions ignore `misc` channels and perform operations only on data channels\n(see https://mne.tools/stable/glossary.html#term-data-channels).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "preprocessors = [\n    Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n    Preprocessor(lambda data: multiply(data, factor)),  # Convert from V to uV\n    Preprocessor('filter', l_freq=low_cut_hz, h_freq=high_cut_hz),  # Bandpass filter\n    Preprocessor(exponential_moving_standardize,  # Exponential moving standardization\n                 factor_new=factor_new, init_block_size=init_block_size)\n]\n\npreprocess(dataset, preprocessors, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting windows\n\nNow we cut out compute windows, the inputs for the deep networks during\ntraining. We use the braindecode function for this, provinding parameters\nto define how trials should be used.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.preprocessing import create_windows_from_events\nfrom skorch.helper import SliceDataset\nfrom numpy import array\n\ntrial_start_offset_seconds = -0.5\n# Extract sampling frequency, check that they are same in all datasets\nsfreq = dataset.datasets[0].raw.info['sfreq']\nassert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n# Calculate the trial start offset in samples.\ntrial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n\nwindows_dataset = create_windows_from_events(\n    dataset,\n    trial_start_offset_samples=trial_start_offset_samples,\n    trial_stop_offset_samples=0,\n    preload=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset into train and valid\nFollowing the split defined in the BCI competition\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splitted = windows_dataset.split('session')\ntrain_set = splitted['0train']  # Session train\neval_set = splitted['1test']  # Session evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining a list of transforms\n\nIn this tutorial, we will use three categories of augmentations.\nThis categorization has been proposed by [1]_ to explain and aggregate\nthe several possibilities of augmentations in EEG, being them:\n\na) Frequency domain augmentations,\nb) Time domain augmentations,\nc) Spatial domain augmentations.\n\nFrom this same paper, we selected the best augmentations in each type: ``FTSurrogate``,\n``SmoothTimeMask``, ``ChannelsDropout``, respectively.\n\nFor each augmentation, we adjustable two values from a range for one parameter\ninside the transformation.\n\nIt is important to remember that you can increase the range.\nFor that, we need to define three lists of transformations and range for the parameter\n\u2206\u03c6max in FTSurrogate where \u2206\u03c6max \u2208 [0, 2\u03c0); for \u2206t in SmoothTimeMask is \u2206t \u2208 [0, 2];\nFor the method ChannelsDropout, we analyse the parameter p_drop \u2208 [0, 1].\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from numpy import linspace\nfrom braindecode.augmentation import FTSurrogate, SmoothTimeMask, ChannelsDropout\n\nseed = 20200220\n\ntransforms_freq = [FTSurrogate(probability=0.5, phase_noise_magnitude=phase_freq,\n                               random_state=seed) for phase_freq in linspace(0, 1, 2)]\n\ntransforms_time = [SmoothTimeMask(probability=0.5, mask_len_samples=int(sfreq * second),\n                                  random_state=seed) for second in linspace(0.1, 2, 2)]\n\ntransforms_spatial = [ChannelsDropout(probability=0.5, p_drop=prob,\n                                      random_state=seed) for prob in linspace(0, 1, 2)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training a model with data augmentation\n\nNow that we know how to instantiate three list of ``Transforms``, it is time to learn how\nto use them to train a model and try to search the best for the dataset.\nLet's first create a model for search a parameter.\n\n### Create model\n\nThe model to be trained is defined as usual.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n\nfrom braindecode.util import set_random_seeds\nfrom braindecode.models import ShallowFBCSPNet\n\ncuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\ndevice = 'cuda' if cuda else 'cpu'\nif cuda:\n    torch.backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set random seed to be able to roughly reproduce results\nNote that with cudnn benchmark set to True, GPU indeterminism\nmay still make results substantially different between runs.\nTo obtain more consistent results at the cost of increased computation time,\nyou can set ``cudnn_benchmark=False`` in ``set_random_seeds``\nor remove ``torch.backends.cudnn.benchmark = True``\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seed = 20200220\nset_random_seeds(seed=seed, cuda=cuda)\n\nn_classes = 4\nclasses = list(range(n_classes))\n# Extract number of chans and time steps from dataset\nn_channels = train_set[0][0].shape[0]\ninput_window_samples = train_set[0][0].shape[1]\n\nmodel = ShallowFBCSPNet(\n    n_channels,\n    n_classes,\n    input_window_samples=input_window_samples,\n    final_conv_length='auto',\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an EEGClassifier with the desired augmentation\n\nIn order to train with data augmentation, a custom data loader can be\nfor the training. Multiple transforms can be passed to it and will be applied\nsequentially to the batched data within the ``AugmentedDataLoader`` object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.augmentation import AugmentedDataLoader\n\n# Send model to GPU\nif cuda:\n    model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model is now trained as in the trial-wise example. The\n``AugmentedDataLoader`` is used as the train iterator and the list of\ntransforms are passed as arguments.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lr = 0.0625 * 0.01\nweight_decay = 0\n\nbatch_size = 64\nn_epochs = 2\n\nclf = EEGClassifier(\n    model,\n    iterator_train=AugmentedDataLoader,  # This tells EEGClassifier to use a custom DataLoader\n    iterator_train__transforms=[],  # This sets is handled by GridSearchCV\n    criterion=torch.nn.NLLLoss,\n    optimizer=torch.optim.AdamW,\n    train_split=None,  # GridSearchCV will control the split and train/validation over the dataset\n    optimizer__lr=lr,\n    optimizer__weight_decay=weight_decay,\n    batch_size=batch_size,\n    callbacks=[\n        'accuracy',\n        ('lr_scheduler', LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n    ],\n    device=device,\n    classes=classes\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To use the skorch framework, it is necessary to transform the windows\ndataset using the module SliceData. Also, it is mandatory to eval the\ngenerator of the training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_X = SliceDataset(train_set, idx=0)\ntrain_y = array(list(SliceDataset(train_set, idx=1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given the trialwise approach, here we use the KFold approach and\nGridSearchCV.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, GridSearchCV\n\ncv = KFold(n_splits=2, shuffle=True, random_state=seed)\nfit_params = {'epochs': n_epochs}\n\ntransforms = transforms_freq + transforms_time + transforms_spatial\n\nparam_grid = {\n    'iterator_train__transforms': transforms,\n}\n\nclf.verbose = 0\n\nsearch = GridSearchCV(\n    estimator=clf,\n    param_grid=param_grid,\n    cv=cv,\n    return_train_score=True,\n    scoring='accuracy',\n    refit=True,\n    verbose=1,\n    error_score='raise')\n\nsearch.fit(train_X, train_y, **fit_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysing the best fit\n\nNext, just perform an analysis of the best fit, and the parameters,\nremembering the order that was adjusted.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\n\nsearch_results = pd.DataFrame(search.cv_results_)\n\nbest_run = search_results[search_results['rank_test_score'] == 1].squeeze()\nbest_aug = best_run['params']\nvalidation_score = np.around(best_run['mean_test_score'] * 100, 2).mean()\ntraining_score = np.around(best_run['mean_train_score'] * 100, 2).mean()\n\nreport_message = 'Best augmentation is saved in best_aug which gave a mean validation accuracy' + \\\n                 'of {}% (train accuracy of {}%).'.format(validation_score, training_score)\n\nprint(report_message)\n\neval_X = SliceDataset(eval_set, idx=0)\neval_y = SliceDataset(eval_set, idx=1)\nscore = search.score(eval_X, eval_y)\nprint(f'Eval accuracy is {score * 100:.2f}%.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nsearch_results.plot.bar(\n    x=\"param_iterator_train__transforms\", y=\"mean_train_score\", yerr=\"std_train_score\",\n    rot=45, color=[\"C0\", \"C0\", \"C1\", \"C1\", \"C2\", \"C2\"], legend=None, ax=ax)\nax.set_xlabel(\"Data augmentation strategy\")\nax.set_ylim(0.2, 0.32)\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### References\n\n\n.. [1] Rommel, C., Paillard, J., Moreau, T., & Gramfort, A. (2022)\n       Data augmentation for learning predictive models on EEG:\n       a systematic comparison. https://arxiv.org/abs/2206.14483\n.. [2] Banville, H., Chehab, O., Hyv\u00e4rinen, A., Engemann, D. A., & Gramfort, A. (2021).\n       Uncovering the structure of clinical EEG signals with self-supervised learning.\n       Journal of Neural Engineering, 18(4), 046020.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}