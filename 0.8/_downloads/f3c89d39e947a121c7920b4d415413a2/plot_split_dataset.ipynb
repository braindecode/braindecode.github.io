{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Split Dataset Example\n\nIn this example, we aim to show multiple ways of how you can split your datasets for\ntraining, testing, and evaluating your models.\n   :depth: 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Lukas Gemein <l.gemein@gmail.com>\n#\n# License: BSD (3-clause)\n\nfrom braindecode.datasets import MOABBDataset\nfrom braindecode.preprocessing import create_windows_from_events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the dataset\n\nFirstly, we create a dataset using the braindecode class <MOABBDataset> to load\nit fetched from MOABB. In this example, we're using Dataset 2a from BCI\nCompetition IV.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids=[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Splitting\n\n### By description information\n\nThe class <MOABBDataset> has a pandas DataFrame containing additional\ndescription of its internal datasets, which can be used to help splitting the data\nbased on recording information, such as subject, session, and run of each trial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset.description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we're splitting the data based on different runs. The method split returns\na dictionary with string keys corresponding to unique entries in the description\nDataFrame column.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splits = dataset.split(\"run\")\nprint(splits)\nsplits[\"4\"].description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### By row index\n\nAnother way we can split the dataset is based on a list of integers corresponding to\nrows in the description. In this case, the returned dictionary will have\n'0' as the only key.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splits = dataset.split([0, 1, 5])\nprint(splits)\nsplits[\"0\"].description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, if we want multiple splits based on indices, we can also define a list\ncontaining lists of integers. In this case, the dictionary will have string keys\nrepresenting the index of the dataset split in the order of the given list of\nintegers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splits = dataset.split([[0, 1, 5], [2, 3, 4], [6, 7, 8, 9, 10, 11]])\nprint(splits)\nsplits[\"2\"].description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also name each split in the output dictionary by specifying the keys\nof each list of indexes in the input dictionary:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "splits = dataset.split(\n    {\"train\": [0, 1, 5], \"valid\": [2, 3, 4], \"test\": [6, 7, 8, 9, 10, 11]}\n)\nprint(splits)\nsplits[\"test\"].description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Observation\n\nSimilarly, we can split datasets after creating windows using the same methods.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "windows = create_windows_from_events(\n    dataset, trial_start_offset_samples=0, trial_stop_offset_samples=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Splitting by different runs\nprint(\"Using description info\")\nsplits = windows.split(\"run\")\nprint(splits)\nprint()\n\n# Splitting by row index\nprint(\"Splitting by row index\")\nsplits = windows.split([4, 8])\nprint(splits)\nprint()\n\nprint(\"Multiple row index split\")\nsplits = windows.split([[4, 8], [5, 9, 11]])\nprint(splits)\nprint()\n\n# Specifying output's keys\nprint(\"Specifying keys\")\nsplits = windows.split(dict(train=[4, 8], test=[5, 9, 11]))\nprint(splits)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}