{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multiple discrete targets with the TUH EEG Corpus\n\nWelcome to this tutorial where we demonstrate how to work with multiple discrete\n targets for each recording in the TUH EEG Corpus. We'll guide you through the\n process step by step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Lukas Gemein <l.gemein@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport mne\nfrom torch.utils.data import DataLoader\n\nfrom braindecode.datasets import TUH\nfrom braindecode.preprocessing import create_fixed_length_windows\n\n# Setting Logging Level\n# ----------------------\n#\n# We'll set the logging level to 'ERROR' to avoid excessive messages when\n# extracting windows:\n\nmne.set_log_level('ERROR')  # avoid messages every time a window is extracted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you want to try this code with the actual data, please delete the next\nsection. We are required to mock some dataset functionality, since the data\nis not available at creation time of this example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.datasets.tuh import _TUHMock as TUH  # noqa F811"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Temple University Hospital (TUH) EEG Corpus Dataset\n\nWe start by creating a TUH dataset. Instead of just a `str, we give it\nmultiple strings as target names. Each of the strings has to exist as a\ncolumn in the description DataFrame.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "TUH_PATH = 'please insert actual path to data here'\ntuh = TUH(\n    path=TUH_PATH,\n    recording_ids=None,\n    target_name=('age', 'gender'),  # use both age and gender as decoding target\n    preload=False,\n    add_physician_reports=False,\n)\nprint(tuh.description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring Data\n\nIterating through the dataset gives `x` as an ndarray with shape\n`(n_channels x 1)` and `y` as a list containing `[age of the subject, gender\nof the subject]`.\nLet's look at the last example as it has more interesting age/gender labels\n(compare to the last row of the dataframe above).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, y = tuh[-1]\n\nprint(f'{x=}\\n{y=}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Windows\n\nWe will skip preprocessing steps for now, since it is not the aim of this\nexample. Instead, we will directly create compute windows. We specify a\nmapping from genders 'M' and 'F' to integers, since this is required for\ndecoding.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tuh_windows = create_fixed_length_windows(\n    tuh,\n    start_offset_samples=0,\n    stop_offset_samples=None,\n    window_size_samples=1000,\n    window_stride_samples=1000,\n    drop_last_window=False,\n    mapping={'M': 0, 'F': 1},  # map non-digit targets\n)\n# store the number of windows required for loading later on\ntuh_windows.set_description({\n    \"n_windows\": [len(d) for d in tuh_windows.datasets]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring Windows\n\nIterating through the dataset gives `x` as an ndarray with shape\n`(n_channels x 1000)`, `y` as `[age, gender]`, and `ind`.\nLet's look at the last example again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, y, ind = tuh_windows[-1]\nprint(f'{x=}\\n{y=}\\n{ind=}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DataLoader for Model Training\n\nWe give the dataset to a pytorch DataLoader, such that it can be used for\nmodel training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dl = DataLoader(\n    dataset=tuh_windows,\n    batch_size=4,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploring DataLoader\n\nWhen iterating through the DataLoader, we get `batch_X` as a tensor with shape\n`(4 x n_channels x 1000)`, `batch_y` as `[tensor([4 x age of subject]),\ntensor([4 x gender of subject])]`, and `batch_ind`. To view the last example,\nsimply iterate through the DataLoader:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for batch_X, batch_y, batch_ind in dl:\n    pass\n\nprint(f'{batch_X=}\\n{batch_y=}\\n{batch_ind=}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}