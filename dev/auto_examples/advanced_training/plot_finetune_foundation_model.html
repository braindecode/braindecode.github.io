
<!DOCTYPE html>


<html lang="en" data-content_root="../../" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Fine-tuning a Foundation Model (Signal-JEPA) &#8212; Braindecode 1.3.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css?v=c4836816" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=96647119"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-7Q43R82K6D"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-7Q43R82K6D');
            </script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'auto_examples/advanced_training/plot_finetune_foundation_model';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://braindecode.org/stable/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.3';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="canonical" href="https://braindecode.org/auto_examples/advanced_training/plot_finetune_foundation_model.html" />
    <link rel="icon" href="../../_static/braindecode_symbol.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Cross-session motor imagery with deep learning EEGNet v4 model" href="plot_moabb_benchmark.html" />
    <link rel="prev" title="Searching the best data augmentation on BCIC IV 2a Dataset" href="plot_data_augmentation_search.html" />
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NWDKLVNR');</script>
  <!-- End Google Tag Manager -->

  <link rel="canonical" href="braindecode.org/index.html" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.3" />

  <!-- Google Analytics (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-CHY0V439ZQ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-CHY0V439ZQ');
  </script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
    
    <img src="../../_static/braindecode_long.png" class="logo__image only-light" alt="Braindecode Logo"/>
    <img src="../../_static/braindecode_long.png" class="logo__image only-dark pst-js-only" alt="Braindecode Logo"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../install/install.html">
    Install
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../models/models.html">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../cite.html">
    Cite
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Tutorial and Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../help.html">
    Get help
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../whats_new.html">
    What's new
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../install/install.html">
    Install
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../models/models.html">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../cite.html">
    Cite
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Tutorial and Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../help.html">
    Get help
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../whats_new.html">
    What's new
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../model_building/index.html">Basic model building and training</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_basic_training_epochs.html">Simple training on MNE epochs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_bcic_iv_2a_moabb_cropped.html">Cropped Decoding on BCIC IV 2a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_bcic_iv_2a_moabb_trial.html">Basic Brain Decoding on EEG Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_how_train_test_and_tune.html">How to train, test and tune your model?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_hyperparameter_tuning_with_scikit-learn.html">Hyperparameter tuning with scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_regression.html">Convolutional neural network regression model on fake data.</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_train_in_pure_pytorch_and_pytorch_lightning.html">Training a Braindecode model in PyTorch</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../datasets_io/index.html">Loading and organizing data</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../datasets_io/benchmark_lazy_eager_loading.html">Benchmarking eager and lazy loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets_io/plot_benchmark_preprocessing.html">Benchmarking preprocessing with parallelization and serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets_io/plot_bids_dataset_example.html">BIDS Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets_io/plot_custom_dataset_example.html">Custom Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets_io/plot_load_save_datasets.html">Load and save dataset example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets_io/plot_mne_dataset_example.html">MNE Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets_io/plot_moabb_dataset_example.html">MOABB Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets_io/plot_split_dataset.html">Split Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets_io/plot_tuh_discrete_multitarget.html">Multiple discrete targets with the TUH EEG Corpus</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Advanced neural network training strategies</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="bcic_iv_4_ecog_cropped.html">Fingers flexion cropped decoding on BCIC IV 4 ECoG Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_data_augmentation.html">Data Augmentation on BCIC IV 2a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_data_augmentation_search.html">Searching the best data augmentation on BCIC IV 2a Dataset</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Fine-tuning a Foundation Model (Signal-JEPA)</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_moabb_benchmark.html">Cross-session motor imagery with deep learning EEGNet v4 model</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_relative_positioning.html">Self-supervised learning on EEG with relative positioning</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../applied_examples/index.html">Applied examples on real-world datasets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/bcic_iv_4_ecog_trial.html">Fingers flexion decoding on BCIC IV 4 ECoG Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_sleep_staging_chambon2018.html">Sleep staging on the Sleep Physionet dataset using Chambon2018 network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_sleep_staging_eldele2021.html">Sleep staging on the Sleep Physionet dataset using Eldele2021</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_sleep_staging_usleep.html">Sleep staging on the Sleep Physionet dataset using U-Sleep network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_tuh_eeg_corpus.html">Process a big data EEG resource (TUH EEG Corpus)</a></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Examples</a></li>
    
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Advanced neural network training strategies</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Fine-tuning a Foundation Model (Signal-JEPA)</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NWDKLVNR"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-advanced-training-plot-finetune-foundation-model-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="fine-tuning-a-foundation-model-signal-jepa">
<span id="finetune-foundation-model"></span><span id="sphx-glr-auto-examples-advanced-training-plot-finetune-foundation-model-py"></span><h1>Fine-tuning a Foundation Model (Signal-JEPA)<a class="headerlink" href="#fine-tuning-a-foundation-model-signal-jepa" title="Link to this heading">#</a></h1>
<p>Foundation models are large-scale pre-trained models that serve as a starting point
for a wide range of downstream tasks, leveraging their generalization capabilities.
Fine-tuning these models is necessary to adapt them to specific tasks or datasets,
ensuring optimal performance in specialized applications.</p>
<p>In this tutorial, we demonstrate how to load a pre-trained foundation model
and fine-tune it for a specific task. We use the Signal-JEPA model <a class="footnote-reference brackets" href="#id4" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>
and a MOABB motor-imagery dataset for this tutorial.</p>
<nav class="contents local" id="this-example-covers">
<p class="topic-title">This example covers:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#loading-and-preparing-the-data" id="id5">Loading and preparing the data</a></p>
<ul>
<li><p><a class="reference internal" href="#loading-a-dataset" id="id6">Loading a dataset</a></p></li>
<li><p><a class="reference internal" href="#define-dataset-parameters" id="id7">Define Dataset parameters</a></p></li>
<li><p><a class="reference internal" href="#create-windows-from-events" id="id8">Create Windows from Events</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#loading-a-pre-trained-foundation-model" id="id9">Loading a pre-trained foundation model</a></p>
<ul>
<li><p><a class="reference internal" href="#download-and-load-pre-trained-weights" id="id10">Download and Load Pre-trained Weights</a></p></li>
<li><p><a class="reference internal" href="#instantiate-the-foundation-model" id="id11">Instantiate the Foundation Model</a></p></li>
<li><p><a class="reference internal" href="#load-the-pre-trained-weights-into-the-model" id="id12">Load the Pre-trained Weights into the Model</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#fine-tuning-the-model" id="id13">Fine-tuning the Model</a></p>
<ul>
<li><p><a class="reference internal" href="#freezing-pre-trained-layers" id="id14">Freezing Pre-trained Layers</a></p></li>
<li><p><a class="reference internal" href="#fine-tuning-procedure" id="id15">Fine-tuning Procedure</a></p></li>
<li><p><a class="reference internal" href="#all-in-one-implementation" id="id16">All-in-one Implementation</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#conclusion-and-next-steps" id="id17">Conclusion and Next Steps</a></p></li>
<li><p><a class="reference internal" href="#references" id="id18">References</a></p></li>
</ul>
</nav>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Pierre Guetschel &lt;pierre.guetschel@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD (3-clause)</span>
<span class="c1">#</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">mne</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">braindecode</span><span class="w"> </span><span class="kn">import</span> <a href="https://skorch.readthedocs.io/en/stable/classifier.html#skorch.classifier.NeuralNetClassifier" title="skorch.classifier.NeuralNetClassifier" class="sphx-glr-backref-module-skorch-classifier sphx-glr-backref-type-py-class"><span class="n">EEGClassifier</span></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">braindecode.datasets</span><span class="w"> </span><span class="kn">import</span> <a href="../../generated/braindecode.datasets.MOABBDataset.html#braindecode.datasets.MOABBDataset" title="braindecode.datasets.MOABBDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class"><span class="n">MOABBDataset</span></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">braindecode.models</span><span class="w"> </span><span class="kn">import</span> <a href="../../generated/braindecode.models.SignalJEPA_PreLocal.html#braindecode.models.SignalJEPA_PreLocal" title="braindecode.models.SignalJEPA_PreLocal" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class"><span class="n">SignalJEPA_PreLocal</span></a>
<span class="kn">from</span><span class="w"> </span><span class="nn">braindecode.preprocessing</span><span class="w"> </span><span class="kn">import</span> <a href="../../generated/braindecode.preprocessing.create_windows_from_events.html#braindecode.preprocessing.create_windows_from_events" title="braindecode.preprocessing.create_windows_from_events" class="sphx-glr-backref-module-braindecode-preprocessing sphx-glr-backref-type-py-function"><span class="n">create_windows_from_events</span></a>

<a href="https://docs.pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms" title="torch.use_deterministic_algorithms" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span></a><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html#numpy.random.seed" title="numpy.random.seed" class="sphx-glr-backref-module-numpy-random sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span></a><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
<section id="loading-and-preparing-the-data">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Loading and preparing the data</a><a class="headerlink" href="#loading-and-preparing-the-data" title="Link to this heading">#</a></h2>
<section id="loading-a-dataset">
<h3><a class="toc-backref" href="#id6" role="doc-backlink">Loading a dataset</a><a class="headerlink" href="#loading-a-dataset" title="Link to this heading">#</a></h3>
<p>We start by loading a MOABB dataset, a single subject only for speed.
The dataset contains motor imagery EEG recordings, which we will preprocess and use for fine-tuning.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subject_id</span></a> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Just one subject for speed</span>
<a href="../../generated/braindecode.datasets.MOABBDataset.html#braindecode.datasets.MOABBDataset" title="braindecode.datasets.MOABBDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset</span></a> <span class="o">=</span> <a href="../../generated/braindecode.datasets.MOABBDataset.html#braindecode.datasets.MOABBDataset" title="braindecode.datasets.MOABBDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class"><span class="n">MOABBDataset</span></a><span class="p">(</span><span class="n">dataset_name</span><span class="o">=</span><span class="s2">&quot;BNCI2014_001&quot;</span><span class="p">,</span> <span class="n">subject_ids</span><span class="o">=</span><span class="p">[</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">subject_id</span></a><span class="p">])</span>

<span class="c1"># Set the standard 10-20 montage for EEG channel locations</span>
<a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage</span></a> <span class="o">=</span> <a href="https://mne.tools/stable/generated/mne.channels.make_standard_montage.html#mne.channels.make_standard_montage" title="mne.channels.make_standard_montage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">channels</span><span class="o">.</span><span class="n">make_standard_montage</span></a><span class="p">(</span><span class="s2">&quot;standard_1020&quot;</span><span class="p">)</span>
<span class="k">for</span> <a href="../../generated/braindecode.datasets.BaseDataset.html#braindecode.datasets.BaseDataset" title="braindecode.datasets.BaseDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ds</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span></a><span class="p">:</span>
    <a href="https://mne.tools/stable/generated/mne.io.RawArray.html#mne.io.RawArray.set_montage" title="mne.io.RawArray.set_montage" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-method"><span class="n">ds</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">set_montage</span></a><span class="p">(</span><a href="https://mne.tools/stable/generated/mne.channels.DigMontage.html#mne.channels.DigMontage" title="mne.channels.DigMontage" class="sphx-glr-backref-module-mne-channels sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">montage</span></a><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="define-dataset-parameters">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">Define Dataset parameters</a><a class="headerlink" href="#define-dataset-parameters" title="Link to this heading">#</a></h3>
<p>We extract the sampling frequency and ensure that it is consistent across
all recordings. We also extract the window size from the annotations and
information about the EEG channels (names, positions, etc.).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extract sampling frequency</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sfreq</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;sfreq&quot;</span><span class="p">]</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><a href="https://mne.tools/stable/generated/mne.Info.html#mne.Info" title="mne._fiff.meas_info.Info" class="sphx-glr-backref-module-mne-_fiff-meas_info sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ds</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">info</span></a><span class="p">[</span><span class="s2">&quot;sfreq&quot;</span><span class="p">]</span> <span class="o">==</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sfreq</span></a> <span class="k">for</span> <a href="../../generated/braindecode.datasets.BaseDataset.html#braindecode.datasets.BaseDataset" title="braindecode.datasets.BaseDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ds</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span></a><span class="p">])</span>

<span class="c1"># Extract and validate window size from annotations</span>
<a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">window_size_seconds</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">duration</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
    <span class="n">d</span> <span class="o">==</span> <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">window_size_seconds</span></a>
    <span class="k">for</span> <a href="../../generated/braindecode.datasets.BaseDataset.html#braindecode.datasets.BaseDataset" title="braindecode.datasets.BaseDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ds</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span></a>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <a href="https://mne.tools/stable/generated/mne.io.RawArray.html#mne.io.RawArray.annotations" title="mne.io.RawArray.annotations" class="sphx-glr-backref-module-mne-io sphx-glr-backref-type-py-property"><span class="n">ds</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">duration</span></a>
<span class="p">)</span>

<span class="c1"># Extract channel information</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chs_info</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;chs&quot;</span><span class="p">]</span>  <span class="c1"># Channel information</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sfreq</span></a><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">window_size_seconds</span></a><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chs_info</span></a><span class="p">)</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>sfreq=250.0, window_size_seconds=4.0, len(chs_info)=26
</pre></div>
</div>
</section>
<section id="create-windows-from-events">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Create Windows from Events</a><a class="headerlink" href="#create-windows-from-events" title="Link to this heading">#</a></h3>
<p>We use the <cite>create_windows_from_events</cite> function from Braindecode to segment
the dataset into windows based on events.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">classes</span></a> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;feet&quot;</span><span class="p">,</span> <span class="s2">&quot;left_hand&quot;</span><span class="p">,</span> <span class="s2">&quot;right_hand&quot;</span><span class="p">]</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">classes_mapping</span></a> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">classes</span></a><span class="p">)}</span>

<a href="../../generated/braindecode.datasets.BaseConcatDataset.html#braindecode.datasets.BaseConcatDataset" title="braindecode.datasets.BaseConcatDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">windows_dataset</span></a> <span class="o">=</span> <a href="../../generated/braindecode.preprocessing.create_windows_from_events.html#braindecode.preprocessing.create_windows_from_events" title="braindecode.preprocessing.create_windows_from_events" class="sphx-glr-backref-module-braindecode-preprocessing sphx-glr-backref-type-py-function"><span class="n">create_windows_from_events</span></a><span class="p">(</span>
    <a href="../../generated/braindecode.datasets.MOABBDataset.html#braindecode.datasets.MOABBDataset" title="braindecode.datasets.MOABBDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">dataset</span></a><span class="p">,</span>
    <span class="n">preload</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># Preload the data into memory for faster processing</span>
    <span class="n">mapping</span><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">classes_mapping</span></a><span class="p">,</span>
<span class="p">)</span>
<span class="n">metadata</span> <span class="o">=</span> <a href="../../generated/braindecode.datasets.BaseConcatDataset.html#braindecode.datasets.BaseConcatDataset.get_metadata" title="braindecode.datasets.BaseConcatDataset.get_metadata" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-method"><span class="n">windows_dataset</span><span class="o">.</span><span class="n">get_metadata</span></a><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>   i_window_in_trial  i_start_in_trial  i_stop_in_trial  ...  subject  session run
0                  0               750             1750  ...        3   0train   0
1                  0              2753             3753  ...        3   0train   0
2                  0              4671             5671  ...        3   0train   0
3                  0              6623             7623  ...        3   0train   0
4                  0              8631             9631  ...        3   0train   0
5                  0             10742            11742  ...        3   0train   0
6                  0             12659            13659  ...        3   0train   0
7                  0             14709            15709  ...        3   0train   0
8                  0             16640            17640  ...        3   0train   0
9                  0             20544            21544  ...        3   0train   0

[10 rows x 7 columns]
</pre></div>
</div>
</section>
</section>
<section id="loading-a-pre-trained-foundation-model">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">Loading a pre-trained foundation model</a><a class="headerlink" href="#loading-a-pre-trained-foundation-model" title="Link to this heading">#</a></h2>
<section id="download-and-load-pre-trained-weights">
<h3><a class="toc-backref" href="#id10" role="doc-backlink">Download and Load Pre-trained Weights</a><a class="headerlink" href="#download-and-load-pre-trained-weights" title="Link to this heading">#</a></h3>
<p>We download the pre-trained weights for the SignalJEPA model from the Hugging Face Hub.
These weights will serve as the starting point for finetuning.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_state_dict</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/hub.html#torch.hub.load_state_dict_from_url" title="torch.hub.load_state_dict_from_url" class="sphx-glr-backref-module-torch-hub sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span></a><span class="p">(</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;https://huggingface.co/braindecode/SignalJEPA/resolve/main/signal-jepa_16s-60_adeuwv4s.pth&quot;</span>
<span class="p">)</span>
<span class="c1"># print(model_state_dict.keys())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://huggingface.co/braindecode/SignalJEPA/resolve/main/signal-jepa_16s-60_adeuwv4s.pth&quot; to /home/runner/.cache/torch/hub/checkpoints/signal-jepa_16s-60_adeuwv4s.pth

  0%|          | 0.00/13.2M [00:00&lt;?, ?B/s]
100%|██████████| 13.2M/13.2M [00:00&lt;00:00, 226MB/s]
</pre></div>
</div>
</section>
<section id="instantiate-the-foundation-model">
<h3><a class="toc-backref" href="#id11" role="doc-backlink">Instantiate the Foundation Model</a><a class="headerlink" href="#instantiate-the-foundation-model" title="Link to this heading">#</a></h3>
<p>We create an instance of the SignalJEPA model using the pre-local downstream
architecture. The model is initialized with the dataset’s sampling frequency,
window size, and channel information.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="../../generated/braindecode.models.SignalJEPA_PreLocal.html#braindecode.models.SignalJEPA_PreLocal" title="braindecode.models.SignalJEPA_PreLocal" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="o">=</span> <a href="../../generated/braindecode.models.SignalJEPA_PreLocal.html#braindecode.models.SignalJEPA_PreLocal" title="braindecode.models.SignalJEPA_PreLocal" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class"><span class="n">SignalJEPA_PreLocal</span></a><span class="p">(</span>
    <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sfreq</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sfreq</span></a><span class="p">,</span>
    <span class="n">input_window_seconds</span><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">window_size_seconds</span></a><span class="p">,</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chs_info</span></a><span class="o">=</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">chs_info</span></a><span class="p">,</span>
    <span class="n">n_outputs</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">classes</span></a><span class="p">),</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../generated/braindecode.models.SignalJEPA_PreLocal.html#braindecode.models.SignalJEPA_PreLocal" title="braindecode.models.SignalJEPA_PreLocal" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>======================================================================================================================================================
Layer (type (var_name):depth-idx)                  Input Shape               Output Shape              Param #                   Kernel Shape
======================================================================================================================================================
SignalJEPA_PreLocal (SignalJEPA_PreLocal)          [1, 26, 1000]             [1, 3]                    --                        --
├─Sequential (spatial_conv): 1-1                   [1, 26, 1000]             [1, 4, 1000]              --                        --
│    └─Rearrange (0): 2-1                          [1, 26, 1000]             [1, 1, 26, 1000]          --                        --
│    └─Conv2d (1): 2-2                             [1, 1, 26, 1000]          [1, 4, 1, 1000]           108                       [26, 1]
│    └─Rearrange (2): 2-3                          [1, 4, 1, 1000]           [1, 4, 1000]              --                        --
├─_ConvFeatureEncoder (feature_encoder): 1-2       [1, 4, 1000]              [1, 28, 64]               --                        --
│    └─Rearrange (0): 2-4                          [1, 4, 1000]              [4, 1, 1000]              --                        --
│    └─Sequential (1): 2-5                         [4, 1, 1000]              [4, 8, 122]               --                        --
│    │    └─Conv1d (0): 3-1                        [4, 1, 1000]              [4, 8, 122]               256                       [32]
│    │    └─Dropout (1): 3-2                       [4, 8, 122]               [4, 8, 122]               --                        --
│    │    └─GroupNorm (2): 3-3                     [4, 8, 122]               [4, 8, 122]               16                        --
│    │    └─GELU (3): 3-4                          [4, 8, 122]               [4, 8, 122]               --                        --
│    └─Sequential (2): 2-6                         [4, 8, 122]               [4, 16, 61]               --                        --
│    │    └─Conv1d (0): 3-5                        [4, 8, 122]               [4, 16, 61]               256                       [2]
│    │    └─Dropout (1): 3-6                       [4, 16, 61]               [4, 16, 61]               --                        --
│    │    └─GELU (2): 3-7                          [4, 16, 61]               [4, 16, 61]               --                        --
│    └─Sequential (3): 2-7                         [4, 16, 61]               [4, 32, 30]               --                        --
│    │    └─Conv1d (0): 3-8                        [4, 16, 61]               [4, 32, 30]               1,024                     [2]
│    │    └─Dropout (1): 3-9                       [4, 32, 30]               [4, 32, 30]               --                        --
│    │    └─GELU (2): 3-10                         [4, 32, 30]               [4, 32, 30]               --                        --
│    └─Sequential (4): 2-8                         [4, 32, 30]               [4, 64, 15]               --                        --
│    │    └─Conv1d (0): 3-11                       [4, 32, 30]               [4, 64, 15]               4,096                     [2]
│    │    └─Dropout (1): 3-12                      [4, 64, 15]               [4, 64, 15]               --                        --
│    │    └─GELU (2): 3-13                         [4, 64, 15]               [4, 64, 15]               --                        --
│    └─Sequential (5): 2-9                         [4, 64, 15]               [4, 64, 7]                --                        --
│    │    └─Conv1d (0): 3-14                       [4, 64, 15]               [4, 64, 7]                8,192                     [2]
│    │    └─Dropout (1): 3-15                      [4, 64, 7]                [4, 64, 7]                --                        --
│    │    └─GELU (2): 3-16                         [4, 64, 7]                [4, 64, 7]                --                        --
│    └─Rearrange (6): 2-10                         [4, 64, 7]                [1, 28, 64]               --                        --
├─Sequential (final_layer): 1-3                    [1, 28, 64]               [1, 3]                    --                        --
│    └─Flatten (0): 2-11                           [1, 28, 64]               [1, 1792]                 --                        --
│    └─Linear (1): 2-12                            [1, 1792]                 [1, 3]                    5,379                     --
======================================================================================================================================================
Total params: 19,327
Trainable params: 19,327
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.90
======================================================================================================================================================
Input size (MB): 0.10
Forward/backward pass size (MB): 0.20
Params size (MB): 0.08
Estimated Total Size (MB): 0.38
======================================================================================================================================================
</pre></div>
</div>
</section>
<section id="load-the-pre-trained-weights-into-the-model">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Load the Pre-trained Weights into the Model</a><a class="headerlink" href="#load-the-pre-trained-weights-into-the-model" title="Link to this heading">#</a></h3>
<p>We load the pre-trained weights into the model. The transformer layers are excluded
as this module is not used in the pre-local downstream architecture (see <a class="footnote-reference brackets" href="#id4" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define layers to exclude from the pre-trained weights</span>
<a href="https://docs.python.org/3/library/stdtypes.html#set" title="builtins.set" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">new_layers</span></a> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;spatial_conv.1.weight&quot;</span><span class="p">,</span>
    <span class="s2">&quot;spatial_conv.1.bias&quot;</span><span class="p">,</span>
    <span class="s2">&quot;final_layer.1.weight&quot;</span><span class="p">,</span>
    <span class="s2">&quot;final_layer.1.bias&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="c1"># Filter out transformer weights and load the state dictionary</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_state_dict</span></a> <span class="o">=</span> <span class="p">{</span>
    <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_state_dict</span></a><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;transformer.&quot;</span><span class="p">)</span>
<span class="p">}</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">missing_keys</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unexpected_keys</span></a> <span class="o">=</span> <a href="../../generated/braindecode.models.EEGModuleMixin.html#braindecode.models.EEGModuleMixin.load_state_dict" title="braindecode.models.EEGModuleMixin.load_state_dict" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_state_dict</span></a><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Ensure no unexpected keys and validate missing keys</span>
<span class="k">assert</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unexpected_keys</span></a> <span class="o">==</span> <span class="p">[],</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">unexpected_keys</span></a><span class="si">=}</span><span class="s2">&quot;</span>
<span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">missing_keys</span></a><span class="p">)</span> <span class="o">==</span> <a href="https://docs.python.org/3/library/stdtypes.html#set" title="builtins.set" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">new_layers</span></a><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">missing_keys</span></a><span class="si">=}</span><span class="s2">&quot;</span>
</pre></div>
</div>
</section>
</section>
<section id="fine-tuning-the-model">
<h2><a class="toc-backref" href="#id13" role="doc-backlink">Fine-tuning the Model</a><a class="headerlink" href="#fine-tuning-the-model" title="Link to this heading">#</a></h2>
<p>Signal-JEPA is a model trained in a self-supervised manner on a masked
prediction task. In this task, the model is configured in a many-to-many
fashion, which is not suited for a classification task. Therefore, we need to
adjust the model architecture for finetuning. This is what is done by the
<code class="xref py py-class docutils literal notranslate"><span class="pre">SignalJEPA_PreLocal</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">SignalJEPA_Contextual</span></code>, and
<code class="xref py py-class docutils literal notranslate"><span class="pre">SignalJEPA_PostLocal</span></code> classes. In these classes, new layers are added
specifically for classification, as described in the article <a class="footnote-reference brackets" href="#id4" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> and in the following figure:</p>
<img alt="Signal-JEPA Pre-Local Downstream Architecture" class="align-center" src="../../_images/sjepa_pre-local.jpg" />
<p>With this downstream architecture, two options are possible for fine-tuning:</p>
<ol class="arabic simple">
<li><p>Fine-tune only the newly added layers</p></li>
<li><p>Fine-tune the entire model</p></li>
</ol>
<section id="freezing-pre-trained-layers">
<h3><a class="toc-backref" href="#id14" role="doc-backlink">Freezing Pre-trained Layers</a><a class="headerlink" href="#freezing-pre-trained-layers" title="Link to this heading">#</a></h3>
<p>As the second option is rather straightforward to implement,
we will focus on the first option here.
We will freeze all layers except the newly added ones.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">name</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">param</span></a> <span class="ow">in</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_parameters" title="torch.nn.Module.named_parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span></a><span class="p">():</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">name</span></a> <span class="ow">not</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/stdtypes.html#set" title="builtins.set" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">new_layers</span></a><span class="p">:</span>
        <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span></a> <span class="o">=</span> <span class="kc">False</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Trainable parameters:&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#set" title="builtins.set" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">other_modules</span></a> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">name</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">param</span></a> <span class="ow">in</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_parameters" title="torch.nn.Module.named_parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span></a><span class="p">():</span>
    <span class="k">if</span> <a href="https://docs.python.org/3/library/functions.html#bool" title="builtins.bool" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span></a><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">name</span></a><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#set" title="builtins.set" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">other_modules</span></a><span class="o">.</span><span class="n">add</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">name</span></a><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Other modules:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#set" title="builtins.set" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">other_modules</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Trainable parameters:
spatial_conv.1.weight
spatial_conv.1.bias
final_layer.1.weight
final_layer.1.bias

Other modules:
{&#39;feature_encoder&#39;}
</pre></div>
</div>
</section>
<section id="fine-tuning-procedure">
<h3><a class="toc-backref" href="#id15" role="doc-backlink">Fine-tuning Procedure</a><a class="headerlink" href="#fine-tuning-procedure" title="Link to this heading">#</a></h3>
<p>Finally, we set up the fine-tuning procedure using Braindecode’s
<code class="xref py py-class docutils literal notranslate"><span class="pre">EEGClassifier</span></code>. We define the loss function, optimizer, and training
parameters. We then fit the model to the windows dataset.</p>
<p>We only train for a few epochs for demonstration purposes.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <a href="https://skorch.readthedocs.io/en/stable/classifier.html#skorch.classifier.NeuralNetClassifier" title="skorch.classifier.NeuralNetClassifier" class="sphx-glr-backref-module-skorch-classifier sphx-glr-backref-type-py-class"><span class="n">EEGClassifier</span></a><span class="p">(</span>
    <a href="../../generated/braindecode.models.SignalJEPA_PreLocal.html#braindecode.models.SignalJEPA_PreLocal" title="braindecode.models.SignalJEPA_PreLocal" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">,</span>
    <span class="n">criterion</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span></a><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.AdamW.html#torch.optim.AdamW" title="torch.optim.AdamW" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span></a><span class="p">,</span>
    <span class="n">optimizer__lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">classes</span></a><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <a href="https://skorch.readthedocs.io/en/stable/classifier.html#skorch.classifier.NeuralNetClassifier.fit" title="skorch.classifier.NeuralNetClassifier.fit" class="sphx-glr-backref-module-skorch-classifier sphx-glr-backref-type-py-method"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><a href="../../generated/braindecode.datasets.BaseConcatDataset.html#braindecode.datasets.BaseConcatDataset" title="braindecode.datasets.BaseConcatDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">windows_dataset</span></a><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss     dur
-------  ----------------  ------------  -----------  ----------------  ------------  ------
      1            0.3333        1.0994       0.3333            0.3333        1.0989  0.2592
      2            0.3333        1.0992       0.3333            0.3333        1.0987  0.2208
      3            0.4696        1.0985       0.3448            0.3448        1.0984  0.2205
      4            0.5217        1.0961       0.3563            0.3563        1.0979  0.2227
      5            0.5768        1.0935       0.3793            0.3793        1.0971  0.2266
      6            0.6319        1.0887       0.3448            0.3448        1.0963  0.2200
      7            0.5826        1.0827       0.3563            0.3563        1.0951  0.2198
      8            0.6348        1.0766       0.3678            0.3678        1.0939  0.2181
      9            0.6174        1.0686       0.3793            0.3793        1.0925  0.2200
     10            0.6290        1.0618       0.3793            0.3793        1.0913  0.2178
</pre></div>
</div>
</section>
<section id="all-in-one-implementation">
<h3><a class="toc-backref" href="#id16" role="doc-backlink">All-in-one Implementation</a><a class="headerlink" href="#all-in-one-implementation" title="Link to this heading">#</a></h3>
<p>In the implementation above, we manually loaded the weights and froze the layers.
This forces us to pass an initialized model to <code class="xref py py-class docutils literal notranslate"><span class="pre">EEGClassifier</span></code>, which may
create issues if we use it in a cross-validation setting.</p>
<p>Instead, we can implement the same procedure in a more compact and reproducible way,
by using skorch’s callback system.</p>
<p>Here, we import a callback to freeze layers and define a custom
callback to load the pre-trained weights at the beginning of training:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">skorch.callbacks</span><span class="w"> </span><span class="kn">import</span> <a href="https://skorch.readthedocs.io/en/stable/callbacks.html#skorch.callbacks.Callback" title="skorch.callbacks.Callback" class="sphx-glr-backref-module-skorch-callbacks sphx-glr-backref-type-py-class"><span class="n">Callback</span></a><span class="p">,</span> <a href="https://skorch.readthedocs.io/en/stable/callbacks.html#skorch.callbacks.Freezer" title="skorch.callbacks.Freezer" class="sphx-glr-backref-module-skorch-callbacks sphx-glr-backref-type-py-class"><span class="n">Freezer</span></a>


<span class="k">class</span><span class="w"> </span><span class="nc">WeightsLoader</span><span class="p">(</span><a href="https://skorch.readthedocs.io/en/stable/callbacks.html#skorch.callbacks.Callback" title="skorch.callbacks.Callback" class="sphx-glr-backref-module-skorch-callbacks sphx-glr-backref-type-py-class"><span class="n">Callback</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">url</span> <span class="o">=</span> <span class="n">url</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strict</span> <span class="o">=</span> <span class="n">strict</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">state_dict</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/hub.html#torch.hub.load_state_dict_from_url" title="torch.hub.load_state_dict_from_url" class="sphx-glr-backref-module-torch-hub sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span></a><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>
        <span class="n">net</span><span class="o">.</span><span class="n">module_</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strict</span><span class="p">)</span>
</pre></div>
</div>
<p>We can now define a classifier with those callbacks, without having
to pass an initialized model, and fit it as before:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <a href="https://skorch.readthedocs.io/en/stable/classifier.html#skorch.classifier.NeuralNetClassifier" title="skorch.classifier.NeuralNetClassifier" class="sphx-glr-backref-module-skorch-classifier sphx-glr-backref-type-py-class"><span class="n">EEGClassifier</span></a><span class="p">(</span>
    <span class="s2">&quot;SignalJEPA_PreLocal&quot;</span><span class="p">,</span>
    <span class="n">criterion</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span></a><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.AdamW.html#torch.optim.AdamW" title="torch.optim.AdamW" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span></a><span class="p">,</span>
    <span class="n">optimizer__lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
        <a href="https://skorch.readthedocs.io/en/stable/callbacks.html#skorch.callbacks.Callback" title="skorch.callbacks.Callback" class="sphx-glr-backref-module-skorch-callbacks sphx-glr-backref-type-py-class"><span class="n">WeightsLoader</span></a><span class="p">(</span>
            <span class="n">url</span><span class="o">=</span><span class="s2">&quot;https://huggingface.co/braindecode/SignalJEPA/resolve/main/signal-jepa_16s-60_adeuwv4s.pth&quot;</span>
        <span class="p">),</span>
        <a href="https://skorch.readthedocs.io/en/stable/callbacks.html#skorch.callbacks.Freezer" title="skorch.callbacks.Freezer" class="sphx-glr-backref-module-skorch-callbacks sphx-glr-backref-type-py-class"><span class="n">Freezer</span></a><span class="p">(</span><span class="n">patterns</span><span class="o">=</span><span class="s2">&quot;feature_encoder.*&quot;</span><span class="p">),</span>
    <span class="p">],</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">classes</span></a><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <a href="https://skorch.readthedocs.io/en/stable/classifier.html#skorch.classifier.NeuralNetClassifier.fit" title="skorch.classifier.NeuralNetClassifier.fit" class="sphx-glr-backref-module-skorch-classifier sphx-glr-backref-type-py-method"><span class="n">clf</span><span class="o">.</span><span class="n">fit</span></a><span class="p">(</span><a href="../../generated/braindecode.datasets.BaseConcatDataset.html#braindecode.datasets.BaseConcatDataset" title="braindecode.datasets.BaseConcatDataset" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">windows_dataset</span></a><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">metadata</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  epoch    train_accuracy    train_loss    valid_acc    valid_accuracy    valid_loss     dur
-------  ----------------  ------------  -----------  ----------------  ------------  ------
      1            0.3333        1.0997       0.3333            0.3333        1.0987  0.2337
      2            0.3362        1.0987       0.3333            0.3333        1.0985  0.2226
      3            0.3391        1.0980       0.3448            0.3448        1.0983  0.2233
      4            0.3855        1.0963       0.3448            0.3448        1.0978  0.2165
      5            0.4986        1.0936       0.4023            0.4023        1.0972  0.2142
      6            0.5739        1.0898       0.3563            0.3563        1.0965  0.2130
      7            0.5014        1.0852       0.3908            0.3908        1.0954  0.2164
      8            0.5652        1.0784       0.4138            0.4138        1.0942  0.2093
      9            0.5710        1.0717       0.4023            0.4023        1.0929  0.2089
     10            0.6174        1.0629       0.4138            0.4138        1.0914  0.2125
</pre></div>
</div>
</section>
</section>
<section id="conclusion-and-next-steps">
<h2><a class="toc-backref" href="#id17" role="doc-backlink">Conclusion and Next Steps</a><a class="headerlink" href="#conclusion-and-next-steps" title="Link to this heading">#</a></h2>
<p>In this tutorial, we demonstrated how to fine-tune a pre-trained foundation
model, Signal-JEPA, for a motor imagery classification task. We now have a basic
implementation that can automatically load pre-trained weights and freeze specific layers.</p>
<p>This setup can easily be extended to explore different fine-tuning techniques,
base foundation models, and downstream tasks.</p>
</section>
<section id="references">
<h2><a class="toc-backref" href="#id18" role="doc-backlink">References</a><a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id4" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id2">2</a>,<a role="doc-backlink" href="#id3">3</a>)</span>
<p>Guetschel, P., Moreau, T., and Tangermann, M. (2024)
“S-JEPA: towards seamless cross-dataset transfer
through dynamic spatial attention”.  <a class="reference external" href="https://arxiv.org/abs/2403.11772">https://arxiv.org/abs/2403.11772</a></p>
</aside>
</aside>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 11.723 seconds)</p>
<p><strong>Estimated memory usage:</strong>  868 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-advanced-training-plot-finetune-foundation-model-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/0ada35f18bb95235ba2842270483081f/plot_finetune_foundation_model.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_finetune_foundation_model.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a32a306db00e9cee755a6d170274505e/plot_finetune_foundation_model.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_finetune_foundation_model.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a17859efbd73c4ab12ff3a773716e0a1/plot_finetune_foundation_model.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">plot_finetune_foundation_model.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


  
</div>

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="plot_data_augmentation_search.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Searching the best data augmentation on BCIC IV 2a Dataset</p>
      </div>
    </a>
    <a class="right-next"
       href="plot_moabb_benchmark.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Cross-session motor imagery with deep learning EEGNet v4 model</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-and-preparing-the-data">Loading and preparing the data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-a-dataset">Loading a dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-dataset-parameters">Define Dataset parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#create-windows-from-events">Create Windows from Events</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-a-pre-trained-foundation-model">Loading a pre-trained foundation model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#download-and-load-pre-trained-weights">Download and Load Pre-trained Weights</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instantiate-the-foundation-model">Instantiate the Foundation Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-pre-trained-weights-into-the-model">Load the Pre-trained Weights into the Model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-the-model">Fine-tuning the Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#freezing-pre-trained-layers">Freezing Pre-trained Layers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-procedure">Fine-tuning Procedure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#all-in-one-implementation">All-in-one Implementation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion-and-next-steps">Conclusion and Next Steps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

    <script src="https://braindecode.org/versionwarning.js"></script>
    
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item"><p class="text-center text-muted small">&copy; Copyright 2018–2025, Braindecode Developers.</p></div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>