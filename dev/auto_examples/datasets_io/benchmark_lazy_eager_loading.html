
<!DOCTYPE html>


<html lang="en" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Benchmarking eager and lazy loading &#8212; Braindecode 0.7 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css?v=09706775" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script src="../../_static/documentation_options.js?v=df5ae754"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=36754332"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-7Q43R82K6D"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-7Q43R82K6D');
            </script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-7Q43R82K6D');
            </script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'auto_examples/datasets_io/benchmark_lazy_eager_loading';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://braindecode.org/stable/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.7';
        </script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Benchmarking preprocessing with parallelization and serialization" href="plot_benchmark_preprocessing.html" />
    <link rel="prev" title="Loading and organizing data" href="index.html" />
    <link rel="canonical" href="braindecode.org/index.html" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
    
    
    
    <img src="../../_static/braindecode_symbol.png" class="logo__image only-light" alt="Braindecode Logo"/>
    <script>document.write(`<img src="../../_static/braindecode_symbol.png" class="logo__image only-dark" alt="Braindecode Logo"/>`);</script>
  
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../install/install.html">
                        Install
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cite.html">
                        Cite
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        Tutorial and Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../help.html">
                        Get help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../whats_new.html">
                        What’s new
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown">
      0.7  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../install/install.html">
                        Install
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cite.html">
                        Cite
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        Tutorial and Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../help.html">
                        Get help
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../whats_new.html">
                        What’s new
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item">
<script>
document.write(`
  <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-bs-toggle="dropdown">
      0.7  <!-- this text may get changed later by javascript -->
      <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
  </div>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Loading and organizing data</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Benchmarking eager and lazy loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_benchmark_preprocessing.html">Benchmarking preprocessing with parallelization and serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_custom_dataset_example.html">Custom Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_load_save_datasets.html">Load and save dataset example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_mne_dataset_example.html">MNE Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_moabb_dataset_example.html">MOABB Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_split_dataset.html">Split Dataset Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_tuh_discrete_multitarget.html">Multiple discrete targets with the TUH EEG Corpus</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../model_building/index.html">Basic model building and training</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_bcic_iv_2a_moabb_cropped.html">Cropped Decoding on BCIC IV 2a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_bcic_iv_2a_moabb_trial.html">Basic Brain Decoding on EEG Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_how_train_test_and_tune.html">How to train, test and tune your model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_hyperparameter_tuning_with_scikit-learn.html">Hyperparameter tuning with scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../model_building/plot_regression.html">Regression example on fake data</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../advanced_training/index.html">Advanced neural network training strategies</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced_training/plot_data_augmentation.html">Data Augmentation on BCIC IV 2a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced_training/plot_data_augmentation_search.html">Searching the best data augmentation on BCIC IV 2a Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced_training/plot_relative_positioning.html">Self-supervised learning on EEG with relative positioning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../applied_examples/index.html">Applied examples on real-world datasets</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_bcic_iv_4_ecog_cropped.html">Fingers flexion cropped decoding on BCIC IV 4 ECoG Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_bcic_iv_4_ecog_trial.html">Fingers flexion decoding on BCIC IV 4 ECoG Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_sleep_staging_chambon2018.html">Sleep staging on the Sleep Physionet dataset using Chambon2018 network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_sleep_staging_eldele2021.html">Sleep staging on the Sleep Physionet dataset using Eldele2021</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_sleep_staging_usleep.html">Sleep staging on the Sleep Physionet dataset using U-Sleep network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../applied_examples/plot_tuh_eeg_corpus.html">Process a big data EEG resource (TUH EEG Corpus)</a></li>
</ul>
</li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Examples</a></li>
    
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Loading and organizing data</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Benchmarking eager and lazy loading</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
<div>
  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-datasets-io-benchmark-lazy-eager-loading-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="benchmarking-eager-and-lazy-loading">
<span id="sphx-glr-auto-examples-datasets-io-benchmark-lazy-eager-loading-py"></span><h1>Benchmarking eager and lazy loading<a class="headerlink" href="#benchmarking-eager-and-lazy-loading" title="Link to this heading">#</a></h1>
<p>In this example, we compare the execution time and memory requirements of 1)
eager loading, i.e., preloading the entire data into memory and 2) lazy loading,
i.e., only loading examples from disk when they are required. We also include
some other experiment parameters in the comparison for the sake of completeness
(e.g., <cite>num_workers</cite>, <cite>cuda</cite>, <cite>batch_size</cite>, etc.).</p>
<p>While eager loading might be required for some preprocessing steps that require
continuous data (e.g., temporal filtering, resampling), it also allows
fast access to the data during training. However, this might come at the expense
of large memory usage, and can ultimately become impossible if the dataset does
not fit into memory (e.g., the TUH EEG dataset’s &gt;1,5 TB of recordings will
not fit in the memory of most machines).</p>
<p>Lazy loading avoids this potential memory issue by loading examples from disk
when they are required. This means large datasets can be used for training,
however this introduces some file-reading overhead every time an example must
be extracted. Some preprocessing steps that require continuous data also have to
be implemented differently to accomodate the nature of windowed data. Overall
though, we can reduce the impact of lazy loading by using the <cite>num_workers</cite>
parameter of pytorch’s <cite>Dataloader</cite> class, which dispatches the data loading to
multiple processes.</p>
<p>To enable lazy loading in braindecode, data files must be saved in an
MNE-compatible format (e.g., ‘fif’, ‘edf’, etc.), and the <cite>Dataset</cite> object must
have been instantiated with parameter <cite>preload=False</cite>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Authors: Hubert Banville &lt;hubert.jbanville@gmail.com&gt;</span>
<span class="c1">#</span>
<span class="c1"># License: BSD (3-clause)</span>

<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/itertools.html#itertools.product" title="itertools.product" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">product</span></a>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DataLoader</span></a>

<span class="kn">import</span> <span class="nn">mne</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">braindecode.datasets</span> <span class="kn">import</span> <a href="../../generated/braindecode.datasets.TUHAbnormal.html#braindecode.datasets.TUHAbnormal" title="braindecode.datasets.TUHAbnormal" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TUHAbnormal</span></a>
<span class="kn">from</span> <span class="nn">braindecode.preprocessing</span> <span class="kn">import</span> <a href="../../generated/braindecode.preprocessing.create_fixed_length_windows.html#braindecode.preprocessing.create_fixed_length_windows" title="braindecode.preprocessing.create_fixed_length_windows" class="sphx-glr-backref-module-braindecode-preprocessing sphx-glr-backref-type-py-function"><span class="n">create_fixed_length_windows</span></a>
<span class="kn">from</span> <span class="nn">braindecode.models</span> <span class="kn">import</span> <a href="../../generated/braindecode.models.ShallowFBCSPNet.html#braindecode.models.ShallowFBCSPNet" title="braindecode.models.ShallowFBCSPNet" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ShallowFBCSPNet</span></a><span class="p">,</span> <a href="../../generated/braindecode.models.Deep4Net.html#braindecode.models.Deep4Net" title="braindecode.models.Deep4Net" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Deep4Net</span></a>


<a href="https://mne.tools/stable/generated/mne.set_log_level.html#mne.set_log_level" title="mne.set_log_level" class="sphx-glr-backref-module-mne sphx-glr-backref-type-py-function"><span class="n">mne</span><span class="o">.</span><span class="n">set_log_level</span></a><span class="p">(</span><span class="s1">&#39;WARNING&#39;</span><span class="p">)</span>  <span class="c1"># avoid messages everytime a window is extracted</span>
</pre></div>
</div>
<p>We start by setting two pytorch internal parameters that can affect the
comparison:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">..</span> <span class="n">GENERATED</span> <span class="n">FROM</span> <span class="n">PYTHON</span> <span class="n">SOURCE</span> <span class="n">LINES</span> <span class="mi">57</span><span class="o">-</span><span class="mi">62</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_JOBS</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Enables automatic algorithm optimizations</span>
<a href="https://pytorch.org/docs/stable/generated/torch.set_num_threads.html#torch.set_num_threads" title="torch.set_num_threads" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span></a><span class="p">(</span><span class="n">N_JOBS</span><span class="p">)</span>  <span class="c1"># Sets the available number of threads</span>
</pre></div>
</div>
<p>Next, we define a few functions to automate the benchmarking.
For the purpose of this example, we load some recordings from the TUH Abnormal
corpus, extract sliding windows, and bundle them in a braindecode Dataset.
We then train a neural network for a few epochs.</p>
<p>Each one of these steps will be timed, so we can report the total time taken
to prepare the data and train the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_example_data</span><span class="p">(</span><span class="n">preload</span><span class="p">,</span> <span class="n">window_len_s</span><span class="p">,</span> <span class="n">n_recordings</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create windowed dataset from subjects of the TUH Abnormal dataset.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    preload: bool</span>
<span class="sd">        If True, use eager loading, otherwise use lazy loading.</span>
<span class="sd">    window_len_s: int</span>
<span class="sd">        Window length in seconds.</span>
<span class="sd">    n_recordings: list of int</span>
<span class="sd">        Number of recordings to load.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    windows_ds: BaseConcatDataset</span>
<span class="sd">        Windowed data.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        The recordings from the TUH Abnormal corpus do not all share the same</span>
<span class="sd">        sampling rate. The following assumes that the files have already been</span>
<span class="sd">        resampled to a common sampling rate.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">recording_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_recordings</span><span class="p">))</span>

    <span class="n">ds</span> <span class="o">=</span> <a href="../../generated/braindecode.datasets.TUHAbnormal.html#braindecode.datasets.TUHAbnormal" title="braindecode.datasets.TUHAbnormal" class="sphx-glr-backref-module-braindecode-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">TUHAbnormal</span></a><span class="p">(</span>
        <span class="n">TUH_PATH</span><span class="p">,</span> <span class="n">recording_ids</span><span class="o">=</span><span class="n">recording_ids</span><span class="p">,</span>
        <span class="n">target_name</span><span class="o">=</span><span class="s1">&#39;pathological&#39;</span><span class="p">,</span>
        <span class="n">preload</span><span class="o">=</span><span class="n">preload</span><span class="p">)</span>

    <span class="n">fs</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;sfreq&#39;</span><span class="p">]</span>
    <span class="n">window_len_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fs</span> <span class="o">*</span> <span class="n">window_len_s</span><span class="p">)</span>
    <span class="n">window_stride_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fs</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span>
    <span class="c1"># window_stride_samples = int(fs * window_len_s)</span>
    <span class="n">windows_ds</span> <span class="o">=</span> <a href="../../generated/braindecode.preprocessing.create_fixed_length_windows.html#braindecode.preprocessing.create_fixed_length_windows" title="braindecode.preprocessing.create_fixed_length_windows" class="sphx-glr-backref-module-braindecode-preprocessing sphx-glr-backref-type-py-function"><span class="n">create_fixed_length_windows</span></a><span class="p">(</span>
        <span class="n">ds</span><span class="p">,</span> <span class="n">start_offset_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stop_offset_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">window_size_samples</span><span class="o">=</span><span class="n">window_len_samples</span><span class="p">,</span>
        <span class="n">window_stride_samples</span><span class="o">=</span><span class="n">window_stride_samples</span><span class="p">,</span> <span class="n">drop_last_window</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">preload</span><span class="o">=</span><span class="n">preload</span><span class="p">,</span> <span class="n">drop_bad_windows</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Drop bad epochs</span>
    <span class="c1"># XXX: This could be parallelized.</span>
    <span class="c1"># XXX: Also, this could be implemented in the Dataset object itself.</span>
    <span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">windows_ds</span><span class="o">.</span><span class="n">datasets</span><span class="p">:</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">drop_bad</span><span class="p">()</span>
        <span class="k">assert</span> <span class="n">ds</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">preload</span> <span class="o">==</span> <span class="n">preload</span>

    <span class="k">return</span> <span class="n">windows_ds</span>


<span class="k">def</span> <span class="nf">create_example_model</span><span class="p">(</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">window_len_samples</span><span class="p">,</span>
                         <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;shallow&#39;</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create model, loss and optimizer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_channels : int</span>
<span class="sd">        Number of channels in the input</span>
<span class="sd">    n_times : int</span>
<span class="sd">        Window length in the input</span>
<span class="sd">    n_classes : int</span>
<span class="sd">        Number of classes in the output</span>
<span class="sd">    kind : str</span>
<span class="sd">        &#39;shallow&#39; or &#39;deep&#39;</span>
<span class="sd">    cuda : bool</span>
<span class="sd">        If True, move the model to a CUDA device.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    model : torch.nn.Module</span>
<span class="sd">        Model to train.</span>
<span class="sd">    loss :</span>
<span class="sd">        Loss function</span>
<span class="sd">    optimizer :</span>
<span class="sd">        Optimizer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;shallow&#39;</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <a href="../../generated/braindecode.models.ShallowFBCSPNet.html#braindecode.models.ShallowFBCSPNet" title="braindecode.models.ShallowFBCSPNet" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ShallowFBCSPNet</span></a><span class="p">(</span>
            <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">input_window_samples</span><span class="o">=</span><span class="n">window_len_samples</span><span class="p">,</span>
            <span class="n">n_filters_time</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">filter_time_length</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">n_filters_spat</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
            <span class="n">pool_time_length</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">pool_time_stride</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">final_conv_length</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
            <span class="n">split_first_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_norm_alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;deep&#39;</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <a href="../../generated/braindecode.models.Deep4Net.html#braindecode.models.Deep4Net" title="braindecode.models.Deep4Net" class="sphx-glr-backref-module-braindecode-models sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">Deep4Net</span></a><span class="p">(</span>
            <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">input_window_samples</span><span class="o">=</span><span class="n">window_len_samples</span><span class="p">,</span>
            <span class="n">final_conv_length</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">n_filters_time</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">n_filters_spat</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
            <span class="n">filter_time_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">pool_time_length</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pool_time_stride</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">n_filters_2</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">filter_length_2</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_filters_3</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">filter_length_3</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_filters_4</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">filter_length_4</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">first_pool_mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">later_pool_mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">double_time_convs</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">split_first_layer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">batch_norm_alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">stride_before_pool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="n">optimizer</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="n">loss</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss" title="torch.nn.NLLLoss" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span></a><span class="p">()</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span>


<span class="k">def</span> <span class="nf">run_training</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run training loop.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : torch.nn.Module</span>
<span class="sd">        Model to train.</span>
<span class="sd">    dataloader : torch.utils.data.Dataloader</span>
<span class="sd">        Data loader which will serve examples to the model during training.</span>
<span class="sd">    loss :</span>
<span class="sd">        Loss function.</span>
<span class="sd">    optimizer :</span>
<span class="sd">        Optimizer.</span>
<span class="sd">    n_epochs : int</span>
<span class="sd">        Number of epochs to train the model for.</span>
<span class="sd">    cuda : bool</span>
<span class="sd">        If True, move X and y to CUDA device.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    model : torch.nn.Module</span>
<span class="sd">        Trained model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
        <span class="n">loss_vals</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

            <span class="n">loss_val</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">loss_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_val</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

            <span class="n">loss_val</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1"> - mean training loss: </span><span class="si">{</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.mean.html#numpy.mean" title="numpy.mean" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">mean</span></a><span class="p">(</span><span class="n">loss_vals</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>
</pre></div>
</div>
<p>Next, we define the different hyperparameters that we want to compare:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">PRELOAD</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>  <span class="c1"># True -&gt; eager loading; False -&gt; lazy loading</span>
<span class="n">N_RECORDINGS</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">]</span>  <span class="c1"># Number of recordings to load from the TUH Abnormal corpus</span>
<span class="n">WINDOW_LEN_S</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>  <span class="c1"># Window length, in seconds</span>
<span class="n">N_EPOCHS</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># Number of epochs to train the model for</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">]</span>  <span class="c1"># Training minibatch size</span>
<span class="n">MODEL</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;shallow&#39;</span><span class="p">,</span> <span class="s1">&#39;deep&#39;</span><span class="p">]</span>

<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># number of processes used by pytorch&#39;s Dataloader</span>
<span class="n">PIN_MEMORY</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>  <span class="c1"># whether to use pinned memory</span>
<span class="n">CUDA</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span> <span class="k">if</span> <a href="https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>  <span class="c1"># whether to use a CUDA device</span>

<span class="n">N_REPETITIONS</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Number of times to repeat the experiment (to get better time estimates)</span>
</pre></div>
</div>
<p>The following path needs to be changed to your local folder containing the
TUH Abnormal corpus:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TUH_PATH</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;/storage/store/data/tuh_eeg/www.isip.piconepress.com/projects/&#39;</span>
            <span class="s1">&#39;tuh_eeg/downloads/tuh_eeg_abnormal/v2.0.0/edf/&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>We can finally cycle through all the different combinations of the parameters
we set above to evaluate their execution time:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">all_results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">preload</span><span class="p">,</span> <span class="n">n_recordings</span><span class="p">,</span> <span class="n">win_len_s</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">model_kind</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/itertools.html#itertools.product" title="itertools.product" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">product</span></a><span class="p">(</span>
            <span class="nb">range</span><span class="p">(</span><span class="n">N_REPETITIONS</span><span class="p">),</span> <span class="n">PRELOAD</span><span class="p">,</span> <span class="n">N_RECORDINGS</span><span class="p">,</span> <span class="n">WINDOW_LEN_S</span><span class="p">,</span> <span class="n">N_EPOCHS</span><span class="p">,</span>
            <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">MODEL</span><span class="p">,</span> <span class="n">NUM_WORKERS</span><span class="p">,</span> <span class="n">PIN_MEMORY</span><span class="p">,</span> <span class="n">CUDA</span><span class="p">):</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;repetition&#39;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
        <span class="s1">&#39;preload&#39;</span><span class="p">:</span> <span class="n">preload</span><span class="p">,</span>
        <span class="s1">&#39;n_recordings&#39;</span><span class="p">:</span> <span class="n">n_recordings</span><span class="p">,</span>
        <span class="s1">&#39;win_len_s&#39;</span><span class="p">:</span> <span class="n">win_len_s</span><span class="p">,</span>
        <span class="s1">&#39;n_epochs&#39;</span><span class="p">:</span> <span class="n">n_epochs</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
        <span class="s1">&#39;model_kind&#39;</span><span class="p">:</span> <span class="n">model_kind</span><span class="p">,</span>
        <span class="s1">&#39;num_workers&#39;</span><span class="p">:</span> <span class="n">num_workers</span><span class="p">,</span>
        <span class="s1">&#39;pin_memory&#39;</span><span class="p">:</span> <span class="n">pin_memory</span><span class="p">,</span>
        <span class="s1">&#39;cuda&#39;</span><span class="p">:</span> <span class="n">cuda</span>
    <span class="p">}</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Repetition </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">N_REPETITIONS</span><span class="si">}</span><span class="s1">:</span><span class="se">\n</span><span class="si">{</span><span class="n">results</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># Load the dataset</span>
    <span class="n">data_loading_start</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">load_example_data</span><span class="p">(</span><span class="n">preload</span><span class="p">,</span> <span class="n">win_len_s</span><span class="p">,</span> <span class="n">n_recordings</span><span class="o">=</span><span class="n">n_recordings</span><span class="p">)</span>
    <span class="n">data_loading_end</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>

    <span class="c1"># Create the data loader</span>
    <span class="n">training_setup_start</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="n">dataloader</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">DataLoader</span></a><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">worker_init_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="c1"># Instantiate model and optimizer</span>
    <span class="n">n_channels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">ch_names</span><span class="p">)</span>
    <span class="n">n_times</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">times</span><span class="p">)</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">create_example_model</span><span class="p">(</span>
        <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">n_times</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="n">model_kind</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="n">cuda</span><span class="p">)</span>
    <span class="n">training_setup_end</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>

    <span class="c1"># Start training loop</span>
    <span class="n">model_training_start</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="n">trained_model</span> <span class="o">=</span> <span class="n">run_training</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="n">cuda</span><span class="p">)</span>
    <span class="n">model_training_end</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>

    <span class="k">del</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">trained_model</span>

    <span class="c1"># Record timing results</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;data_preparation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_loading_end</span> <span class="o">-</span> <span class="n">data_loading_start</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;training_setup&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">training_setup_end</span> <span class="o">-</span> <span class="n">training_setup_start</span>
    <span class="n">results</span><span class="p">[</span><span class="s1">&#39;model_training&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_training_end</span> <span class="o">-</span> <span class="n">model_training_start</span>
    <span class="n">all_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
<p>The results are formatted into a pandas DataFrame and saved locally as a CSV
file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">all_results</span><span class="p">)</span>
<span class="n">fname</span> <span class="o">=</span> <span class="s1">&#39;lazy_vs_eager_loading_results.csv&#39;</span>
<span class="n">results_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Results saved under </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>We can finally summarize this information into the following plot:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">catplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">results_df</span><span class="p">,</span> <span class="n">row</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;model_kind&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;model_training&#39;</span><span class="p">,</span>
    <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;num_workers&#39;</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s1">&#39;preload&#39;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;strip&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The results of this comparison will change depending on the hyperparameters
that were set above, and on the actual hardware that is being used.</p>
</div>
<p>Generally speaking, we expect lazy loading to be slower than eager loading
during model training, but to potentially be pretty competitive if multiple
workers were enabled (i.e.., <cite>num_workers &gt; 0</cite>). Training on a CUDA device
should also yield substantial speedups.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 0.000 seconds)</p>
<p><strong>Estimated memory usage:</strong>  0 MB</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-datasets-io-benchmark-lazy-eager-loading-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/bee463a2563e9377210dd6396f8af549/benchmark_lazy_eager_loading.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">benchmark_lazy_eager_loading.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/0f2bf063e08b7d05b80e0004fcbbb6f9/benchmark_lazy_eager_loading.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">benchmark_lazy_eager_loading.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>


  
</div>

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Loading and organizing data</p>
      </div>
    </a>
    <a class="right-next"
       href="plot_benchmark_preprocessing.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Benchmarking preprocessing with parallelization and serialization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

    <script src="https://braindecode.org/versionwarning.js"></script>
    
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item"><p class="text-center text-muted small">&copy; Copyright 2018–2023, Braindecode Developers.</p></div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>