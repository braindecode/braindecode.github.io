
<!DOCTYPE html>


<html lang="en" data-content_root="../" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Models Categorization &#8212; Braindecode 1.3.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css?v=f3e3feaa" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=96647119"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-7Q43R82K6D"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-7Q43R82K6D');
            </script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'models/models_categorization';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://braindecode.org/stable/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.3';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="canonical" href="https://braindecode.org/models/models_categorization.html" />
    <link rel="icon" href="../_static/braindecode_symbol.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Convolution-layer models" href="categorization/convolution.html" />
    <link rel="prev" title="The brain decode problem" href="models.html" />
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NWDKLVNR');</script>
  <!-- End Google Tag Manager -->

  <link rel="canonical" href="braindecode.org/index.html" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.3" />

  <!-- Google Analytics (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-CHY0V439ZQ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-CHY0V439ZQ');
  </script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>
<aside class="bd-header-announcement" aria-label="Announcement">
  <div class="bd-header-announcement__content"><strong>Using Braindecode in academic work?</strong> <a class='braindecode-announcement-cta' href='cite.html'>Cite Braindecode</a> <span class='braindecode-announcement-secondary'>DOI: <a href='https://doi.org/10.5281/zenodo.16279624'>10.5281/zenodo.16279624</a></span></div>
</aside>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
    
    <img src="../_static/braindecode_long.svg" class="logo__image only-light" alt="Braindecode Logo"/>
    <img src="../_static/braindecode_long.svg" class="logo__image only-dark pst-js-only" alt="Braindecode Logo"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install/install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="models.html">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../cite.html">
    Cite
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Tutorial and Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../help.html">
    Get help
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    What's new
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install/install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="models.html">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../cite.html">
    Cite
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Tutorial and Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../help.html">
    Get help
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    What's new
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Models Categorization</a></li>

<li class="toctree-l1"><a class="reference internal" href="models_table.html">Models Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="models_visualization.html">Visualization</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="models.html" class="nav-link">The brain decode problem</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Models Categorization</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NWDKLVNR"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div>
  
  <section id="models-categorization">
<h1>Models Categorization<a class="headerlink" href="#models-categorization" title="Link to this heading">#</a></h1>
<p>Given the brain-decoding framework from the previous page, we define our neural networks,
denoted <span class="math notranslate nohighlight">\(f\)</span>, as a composition of sequential transformations:</p>
<div class="math notranslate nohighlight">
\[f_{\mathrm{method}}
\;=\;
f_{\mathrm{convolution}} \circ f_{\ell} \circ \cdots  \circ f_{\mathrm{linear}}\,\]</div>
<p>where each <span class="math notranslate nohighlight">\(f_\ell\)</span> is a specific <span class="math notranslate nohighlight">\(\ell\)</span> layer in the neural network,
focusing mostly of time in learning the mapping <span class="math notranslate nohighlight">\(f_{\mathrm{method}} : \mathcal{X} \to \mathcal{Y}\)</span> on the
training data, with parameters <span class="math notranslate nohighlight">\(\theta \in \Theta\)</span>.
How these <em>core</em> <span class="math notranslate nohighlight">\(\ell\)</span> sequence transformations are structured and combined defines the overall focus and strength of the models.</p>
<p>Here, we categorize the main families of brain decoding models based on their core components and design philosophies.
The categories are not mutually exclusive, but an indication of what governs that neural network model; many models blend elements from multiple families to leverage their combined strengths.
Beginning directly, the categories are nine: <span class="sd-sphinx-override sd-badge sd-bg-success sd-bg-text-success">Convolution</span>, <span class="sd-sphinx-override sd-badge sd-bg-secondary sd-bg-text-secondary">Recurrent</span>, <span class="sd-sphinx-override sd-badge sd-bg-info sd-bg-text-info">Attention/Transformer</span>, <span class="sd-sphinx-override sd-badge sd-bg-primary sd-bg-text-primary">Filterbank</span>, <span class="sd-sphinx-override sd-badge sd-bg-warning sd-bg-text-warning">Interpretability</span>, <span class="sd-sphinx-override sd-badge sd-bg-danger sd-bg-text-danger">Foundation Model</span>, <span class="sd-sphinx-override sd-badge sd-bg-light sd-bg-text-light">Graph Neural Network</span>, <span class="sd-sphinx-override sd-badge sd-bg-dark sd-bg-text-dark">Symmetric Positive-Definite</span> and <span class="sd-sphinx-override sd-badge sd-outline-dark sd-text-dark">Channel</span>.</p>
<p>At the moment, not all the categories are implemented, validated, and tested, but there are some that are noteworthy for introducing or popularizing concepts or layer designs that can take decoding further.</p>
<p>The convolutional layer appears as the core primitive across most architectures.
This is because <strong>convolutions are filtering</strong> operations, such as band-pass <a class="reference external" href="https://mne.tools/stable/auto_tutorials/preprocessing/25_background_filtering.html">filters</a>, useful and needed to extract local features from brain signals.
More details about each categories can be found in the respective sections below.</p>
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-1 sd-row-cols-xs-1 sd-row-cols-sm-2 sd-row-cols-md-3 sd-row-cols-lg-3 sd-g-3 sd-g-xs-3 sd-g-sm-3 sd-g-md-3 sd-g-lg-3 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<i class="fas fa-braille"></i> Convolution Layers</div>
<p class="sd-card-text"><span class="sd-sphinx-override sd-badge sd-bg-success sd-bg-text-success">Convolution</span></p>
<figure class="align-center">
<img alt="Diagram of a convolutional layer" class="no-scaled-link" src="../_images/convolution.png" style="width: 90%;" />
</figure>
<p class="sd-card-text">Applies temporal and/or spatial convolutions to extract local features from brain signals.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<i class="fas fa-repeat"></i> Recurrent Layers</div>
<p class="sd-card-text"><span class="sd-sphinx-override sd-badge sd-bg-secondary sd-bg-text-secondary">Recurrent</span></p>
<figure class="align-center">
<img alt="Diagram of recurrent/TCN models" class="no-scaled-link" src="../_images/rnn.png" style="width: 90%;" />
</figure>
<p class="sd-card-text">Models temporal dependencies via recurrent units or TCNs with dilations.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<i class="fas fa-magnifying-glass-chart"></i> Attention/Transformer</div>
<p class="sd-card-text"><span class="sd-sphinx-override sd-badge sd-bg-info sd-bg-text-info">Attention/Transformer</span></p>
<figure class="align-center">
<img alt="Diagram of attention modules" class="no-scaled-link" src="../_images/attention.png" style="width: 90%;" />
</figure>
<p class="sd-card-text">Uses attention mechanisms for feature focusing. Can be trained effectively without self-supervised pre-training.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<i class="fas fa-layer-group"></i> Filterbank Models</div>
<p class="sd-card-text"><span class="sd-sphinx-override sd-badge sd-bg-primary sd-bg-text-primary">Filterbank</span></p>
<figure class="align-center">
<img alt="Diagram of filterbank models" class="no-scaled-link" src="../_images/filterbank.png" style="width: 90%;" />
</figure>
<p class="sd-card-text">Decomposes signals into multiple bands (learned or fixed) to capture frequency-specific information.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<i class="fas fa-eye"></i> Interpretability-by-Design</div>
<p class="sd-card-text"><span class="sd-sphinx-override sd-badge sd-bg-warning sd-bg-text-warning">Interpretability</span></p>
<figure class="align-center">
<img alt="Diagram of interpretable architectures" class="no-scaled-link" src="../_images/interpre.png" style="width: 90%;" />
</figure>
<p class="sd-card-text">Architectures with inherently interpretable layers allow direct neuroscientific validation of learned features.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<i class="fas fa-circle-nodes"></i> Symmetric Positive-Definite</div>
<p class="sd-card-text"><span class="sd-sphinx-override sd-badge sd-bg-dark sd-bg-text-dark">SPD</span> <span class="sd-sphinx-override sd-badge sd-outline-danger sd-text-danger">To be released soon!</span></p>
<figure class="unavailable align-center">
<img alt="Diagram of SPD learning" class="no-scaled-link" src="../_images/spd.png" style="width: 90%;" />
</figure>
<p class="sd-card-text">Learns on covariance/connectivity as SPD matrices using BiMap/ReEig/LogEig layers.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<i class="fas fa-lightbulb"></i> Foundation Models</div>
<p class="sd-card-text"><span class="sd-sphinx-override sd-badge sd-bg-danger sd-bg-text-danger">Foundation Model</span></p>
<figure class="align-center">
<img alt="Diagram of transformer models" class="no-scaled-link" src="../_images/lbm.png" style="width: 90%;" />
</figure>
<p class="sd-card-text">Large-scale foundation model layers require self-supervised pre-training to work effectively.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<i class="fas fa-share-nodes"></i> Graph Neural Network</div>
<p class="sd-card-text"><span class="sd-sphinx-override sd-badge sd-bg-light sd-bg-text-light">Graph Neural Network</span></p>
<figure class="unavailable align-center">
<img alt="Diagram of GNN models" class="no-scaled-link" src="../_images/gnn.png" style="width: 90%;" />
</figure>
<p class="sd-card-text">Treats channels/regions as nodes with learned/static edges to model connectivity.</p>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<i class="fas fa-clone"></i> Channel-Domain</div>
<p class="sd-card-text"><span class="sd-sphinx-override sd-badge sd-outline-dark sd-text-dark">Channel</span></p>
<figure class="align-center">
<img alt="Diagram of channel-domain methods" class="no-scaled-link" src="../_images/channel.png" style="width: 90%;" />
</figure>
<p class="sd-card-text">Usage montage information with spatial filtering / channel / hemisphere / brain region selection strategies.</p>
</div>
</div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Across most architectures, the earliest stages are convolutional (<span class="sd-sphinx-override sd-badge sd-bg-success sd-bg-text-success">Convolution</span>), reflecting the brain time series’s noisy, locally structured nature.
These layers apply temporal and/or spatial convolutions—often depthwise-separable as in EEGNet, per-channel or across channel groups to extract robust local features.
<a class="reference internal" href="../generated/braindecode.models.EEGNet.html#braindecode.models.EEGNet" title="braindecode.models.EEGNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">EEGNet</span></code></a>, <a class="reference internal" href="../generated/braindecode.models.ShallowFBCSPNet.html#braindecode.models.ShallowFBCSPNet" title="braindecode.models.ShallowFBCSPNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShallowFBCSPNet</span></code></a>, <a class="reference internal" href="../generated/braindecode.models.EEGNeX.html#braindecode.models.EEGNeX" title="braindecode.models.EEGNeX"><code class="xref py py-class docutils literal notranslate"><span class="pre">EEGNeX</span></code></a>, and <a class="reference internal" href="../generated/braindecode.models.EEGInceptionERP.html#braindecode.models.EEGInceptionERP" title="braindecode.models.EEGInceptionERP"><code class="xref py py-class docutils literal notranslate"><span class="pre">EEGInceptionERP</span></code></a></p></li>
<li><p>In the <strong>recurrent</strong> family (<span class="sd-sphinx-override sd-badge sd-bg-secondary sd-bg-text-secondary">Recurrent</span>), many modern EEG models actually rely on <em>temporal convolutional networks</em> (TCNs) with dilations to grow the receptive field, rather than explicit recurrence (<span id="id1"><a class="reference internal" href="models.html#id20" title="Shaojie Bai, J Zico Kolter, and Vladlen Koltun. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271, 2018.">11</a></span>), <a class="reference internal" href="../generated/braindecode.models.BDTCN.html#braindecode.models.BDTCN" title="braindecode.models.BDTCN"><code class="xref py py-class docutils literal notranslate"><span class="pre">BDTCN</span></code></a>,</p></li>
<li><p>In contrast, several methods employ <strong>attention/transformer</strong> modules (<span class="sd-sphinx-override sd-badge sd-bg-info sd-bg-text-info">Attention/Transformer</span>) to capture longer-range dependencies efficiently, e.g., <a class="reference internal" href="../generated/braindecode.models.EEGConformer.html#braindecode.models.EEGConformer" title="braindecode.models.EEGConformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">EEGConformer</span></code></a>, <a class="reference internal" href="../generated/braindecode.models.CTNet.html#braindecode.models.CTNet" title="braindecode.models.CTNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">CTNet</span></code></a>, <a class="reference internal" href="../generated/braindecode.models.ATCNet.html#braindecode.models.ATCNet" title="braindecode.models.ATCNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">ATCNet</span></code></a>, <a class="reference internal" href="../generated/braindecode.models.AttentionBaseNet.html#braindecode.models.AttentionBaseNet" title="braindecode.models.AttentionBaseNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">AttentionBaseNet</span></code></a> (<span id="id2"><a class="reference internal" href="models.html#id17" title="Yonghao Song, Qingqing Zheng, Bingchuan Liu, and Xiaorong Gao. Eeg conformer: convolutional transformer for eeg decoding and visualization. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 31:710–719, 2022.">12</a>, <a class="reference internal" href="models.html#id18" title="Wei Zhao, Xiaolu Jiang, Baocan Zhang, Shixiao Xiao, and Sujun Weng. CTNet: a convolutional transformer network for EEG-based motor imagery classification. Scientific reports, 14(1):20237, 2024.">13</a>, <a class="reference internal" href="models.html#id19" title="Hamdi Altaheri, Ghulam Muhammad, and Mansour Alsulaiman. Physics-informed attention temporal convolutional network for EEG-based motor imagery classification. IEEE transactions on industrial informatics, 19(2):2249–2258, 2022.">14</a></span>).</p></li>
<li><p><strong>Filterbank-style models</strong> (<span class="sd-sphinx-override sd-badge sd-bg-primary sd-bg-text-primary">Filterbank</span>) explicitly decompose signals into multiple bands before (or while) learning, echoing the classic FBCSP pipeline; examples include <a class="reference internal" href="../generated/braindecode.models.FBCNet.html#braindecode.models.FBCNet" title="braindecode.models.FBCNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">FBCNet</span></code></a> and <a class="reference internal" href="../generated/braindecode.models.FBMSNet.html#braindecode.models.FBMSNet" title="braindecode.models.FBMSNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">FBMSNet</span></code></a> (<span id="id3"><a class="reference internal" href="models.html#id27" title="Ravikiran Mane, Effie Chew, Karen Chua, Kai Keng Ang, Neethu Robinson, A Prasad Vinod, Seong-Whan Lee, and Cuntai Guan. Fbcnet: a multi-view convolutional neural network for brain-computer interface. arXiv preprint arXiv:2104.01233, 2021.">15</a>, <a class="reference internal" href="models.html#id28" title="Ke Liu, Mingzhao Yang, Zhuliang Yu, Guoyin Wang, and Wei Wu. Fbmsnet: a filter-bank multi-scale convolutional neural network for eeg-based motor imagery decoding. IEEE Transactions on Biomedical Engineering, 70(2):436–445, 2022.">16</a></span>).</p></li>
<li><p><strong>Interpretability-by-design</strong> (<span class="sd-sphinx-override sd-badge sd-bg-warning sd-bg-text-warning">Interpretability</span>) architectures expose physiologically meaningful primitives (e.g., band-pass/sinc filters, variance or connectivity features), enabling direct neuroscientific inspection; see <a class="reference internal" href="../generated/braindecode.models.SincShallowNet.html#braindecode.models.SincShallowNet" title="braindecode.models.SincShallowNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">SincShallowNet</span></code></a> and <a class="reference internal" href="../generated/braindecode.models.EEGMiner.html#braindecode.models.EEGMiner" title="braindecode.models.EEGMiner"><code class="xref py py-class docutils literal notranslate"><span class="pre">EEGMiner</span></code></a> (<span id="id4"><a class="reference internal" href="models.html#id26" title="Davide Borra, Silvia Fantozzi, and Elisa Magosso. Interpretable and lightweight convolutional neural network for eeg decoding: application to movement execution and imagination. Neural Networks, 129:55–74, 2020.">17</a>, <a class="reference internal" href="models.html#id25" title="Siegfried Ludwig, Stylianos Bakas, Dimitrios A Adamos, Nikolaos Laskaris, Yannis Panagakis, and Stefanos Zafeiriou. Eegminer: discovering interpretable features of brain activity with learnable filters. Journal of Neural Engineering, 21(3):036010, 2024.">18</a></span>).</p></li>
<li><p><strong>SPD / Riemannian</strong> (<span class="sd-sphinx-override sd-badge sd-bg-dark sd-bg-text-dark">SPD</span>) methods operate on covariance (or connectivity) matrices as points on the SPD manifold, combining layers such as BiMap, ReEig, and LogEig; deep SPD networks and Riemannian classifiers motivate this family (<span id="id5"><a class="reference internal" href="models.html#id24" title="Zhiwu Huang and Luc Van Gool. A riemannian network for spd matrix learning. In Proceedings of the AAAI conference on artificial intelligence, volume 31. 2017.">19</a></span>). <em>(Coming soon in a dedicate repository.)</em></p></li>
<li><p><strong>Foundation Model / Transformer</strong> (<span class="sd-sphinx-override sd-badge sd-bg-danger sd-bg-text-danger">Foundation Model</span>) approaches pretrain attention-based encoders on diverse biosignals and fine-tune for EEG tasks; e.g., <a class="reference internal" href="../generated/braindecode.models.BIOT.html#braindecode.models.BIOT" title="braindecode.models.BIOT"><code class="xref py py-class docutils literal notranslate"><span class="pre">BIOT</span></code></a> (<span id="id6"><a class="reference internal" href="models.html#id29" title="Chaoqi Yang, M Westover, and Jimeng Sun. Biot: biosignal transformer for cross-data learning in the wild. Advances in Neural Information Processing Systems, 36:78240–78260, 2023.">20</a></span>), <a class="reference internal" href="../generated/braindecode.models.Labram.html#braindecode.models.Labram" title="braindecode.models.Labram"><code class="xref py py-class docutils literal notranslate"><span class="pre">Labram</span></code></a> (<span id="id7"><a class="reference internal" href="models.html#id6" title="Weibang Jiang, Liming Zhao, and Bao-liang Lu. Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI. In The Twelfth International Conference on Learning Representations. 2024. URL: https://openreview.net/forum?id=QzTpTRVtrP.">21</a></span>). These typically need a heavily self-supervised pre-training before decoding.</p></li>
<li><p><strong>Graph neural networks</strong> (<span class="sd-sphinx-override sd-badge sd-bg-light sd-bg-text-light">Graph Neural Network</span>) treat channels/regions as nodes with learned (static or dynamic) edges to model functional connectivity explicitly; representative EEG-GNN, more common in the epileptic decoding (<span id="id8"><a class="reference internal" href="models.html#id23" title="Dominik Klepl, Min Wu, and Fei He. Graph neural network-based eeg classification: a survey. IEEE Transactions on Neural Systems and Rehabilitation Engineering, 32:493–503, 2024.">22</a></span>).</p></li>
<li><p><strong>Channel-domain robustness</strong> (<span class="sd-sphinx-override sd-badge sd-outline-dark sd-text-dark">Channel</span>) techniques target variability in electrode layouts by learning montage-agnostic or channel-selective layers (e.g., dynamic spatial filtering, differentiable channel re-ordering); these strategies improve cross-setup generalization <a class="reference internal" href="../generated/braindecode.models.SignalJEPA.html#braindecode.models.SignalJEPA" title="braindecode.models.SignalJEPA"><code class="xref py py-class docutils literal notranslate"><span class="pre">SignalJEPA</span></code></a> (<span id="id9"><a class="reference internal" href="models.html#id22" title="P. Guetschel, T. Moreau, and M. Tangermann. S-JEPA: towards seamless cross-dataset transfer through dynamic spatial attention. In Proceedings of the 9th Graz Brain-Computer Interface Conference. 2024. URL: https://doi.org/10.3217/978-3-99161-014-4-003, doi:10.3217/978-3-99161-014-4-003.">23</a>, <a class="reference internal" href="models.html#id21" title="Zhige Chen, Rui Yang, Mengjie Huang, Fumin Li, Guoping Lu, and Zidong Wang. Eegprogress: a fast and lightweight progressive convolution architecture for eeg classification. Computers in Biology and Medicine, 169:107901, 2024.">24</a></span>).</p></li>
</ul>
<p>We are continually expanding this collection and welcome contributions! If you have implemented a
model relevant to EEG, ECoG, or MEG analysis, consider adding it to Braindecode.</p>
</section>
<section id="submit-a-new-model">
<h1>Submit a new model<a class="headerlink" href="#submit-a-new-model" title="Link to this heading">#</a></h1>
<p>Want to contribute a new model to Braindecode? Great! You can propose a new model by opening an
<a class="reference external" href="https://github.com/braindecode/braindecode/issues/">issue</a> (please include a link to the relevant publication or description) or,
even better, directly submit your implementation via a <a class="reference external" href="https://github.com/braindecode/braindecode/pulls/">pull request</a>.
We appreciate your contributions to expanding the library!</p>
<p><span class="sd-d-grid"><a class="sd-sphinx-override sd-btn sd-text-wrap sd-btn-primary reference internal" href="models_table.html"><span class="doc">Next: Models Table</span></a></span></p>
<div class="toctree-wrapper compound">
</div>
</section>


  
</div>

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="models.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">The brain decode problem</p>
      </div>
    </a>
    <a class="right-next"
       href="categorization/convolution.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"> Convolution-layer models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

    <script src="https://braindecode.org/versionwarning.js"></script>
    
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item"><p class="text-center text-muted small">&copy; Copyright 2018–2025, Braindecode Developers.</p></div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>