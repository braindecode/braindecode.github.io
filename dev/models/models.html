
<!DOCTYPE html>


<html lang="en" data-content_root="../" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>The brain decode problem &#8212; Braindecode 1.3.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css?v=c4836816" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=96647119"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-7Q43R82K6D"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-7Q43R82K6D');
            </script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'models/models';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://braindecode.org/stable/_static/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '1.3';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="canonical" href="https://braindecode.org/models/models.html" />
    <link rel="icon" href="../_static/braindecode_symbol.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Models Categorization" href="models_categorization.html" />
    <link rel="prev" title="Installing from sources" href="../install/install_source.html" />
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NWDKLVNR');</script>
  <!-- End Google Tag Manager -->

  <link rel="canonical" href="braindecode.org/index.html" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="1.3" />

  <!-- Google Analytics (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-CHY0V439ZQ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-CHY0V439ZQ');
  </script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
    
    <img src="../_static/braindecode_long.png" class="logo__image only-light" alt="Braindecode Logo"/>
    <img src="../_static/braindecode_long.png" class="logo__image only-dark pst-js-only" alt="Braindecode Logo"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install/install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../cite.html">
    Cite
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Tutorial and Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../help.html">
    Get help
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../whats_new.html">
    Whatâ€™s new
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../install/install.html">
    Install
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="#">
    Models
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../cite.html">
    Cite
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../auto_examples/index.html">
    Tutorial and Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../api.html">
    API
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../help.html">
    Get help
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../whats_new.html">
    Whatâ€™s new
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item">
<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="models_categorization.html">Models Categorization</a></li>

<li class="toctree-l1"><a class="reference internal" href="models_table.html">Models Summary</a></li>
<li class="toctree-l1"><a class="reference internal" href="models_visualization.html">Visualization</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">The brain decode problem</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NWDKLVNR"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div>
  
  <section id="the-brain-decode-problem">
<span id="models"></span><h1>The brain decode problem<a class="headerlink" href="#the-brain-decode-problem" title="Link to this heading">#</a></h1>
<p>All the models in this library tackle the following problem:
given time-series signals <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{C \times T}\)</span> and labels
<span class="math notranslate nohighlight">\(y \in \mathcal{Y}\)</span>, <a class="reference internal" href="../api.html#module-braindecode" title="braindecode"><code class="xref py py-class docutils literal notranslate"><span class="pre">braindecode</span></code></a> implements neural networks
<span class="math notranslate nohighlight">\(f\)</span> that <strong>decode</strong> brain activity, i.e., it applies a series of transformations
layers (e.g. <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv2d</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Linear</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ELU.html#torch.nn.ELU" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ELU</span></code></a>) to the data
to allow us to filter and extract features that are relevant to what we are modeling, in other words:</p>
<div class="math notranslate nohighlight">
\[f_{\theta} : X \to y,\]</div>
<p>where <span class="math notranslate nohighlight">\(C\)</span> (<code class="docutils literal notranslate"><span class="pre">n_chans</span></code>) is the number of channels/electrodes and <span class="math notranslate nohighlight">\(T\)</span> (<code class="docutils literal notranslate"><span class="pre">n_times</span></code>) is the temporal window
length/epoch size over the interval of interest.</p>
<p>The definition of <span class="math notranslate nohighlight">\(y\)</span> is broad; it may be anchored in a cognitive stimulus (e.g., BCI, ERP, SSVEP, cVEP),
mental state (sleep stage), brain age, visual/audio/text/action inputs, or any target
that can be quantized and modeled as a decoding task, see references <span id="id1"><a class="reference internal" href="#id4" title="Bruno Aristimunha, Alexandre Janoni Bayerlein, M. Jorge Cardoso, Walter Hugo Lopez Pinaya, and Raphael Yokoingawa De Camargo. Sleep-Energy: An Energy Optimization Method to Sleep Stage Scoring. IEEE Access, 11:34595-34602, 2023.">1</a>, <a class="reference internal" href="#id7" title="Bruno Aristimunha, Igor Carrara, Pierre Guetschel, Sara Sedlar, Pedro Rodrigues, Jan Sosulski, Divyesh Narayanan, Erik Bjareholt, Barthelemy Quentin, Robin Tibor Schirrmeister, Emmanuel Kalunga, Ludovic Darmet, Cattan Gregoire, Ali Abdul Hussain, Ramiro Gatti, Vladislav Goncharenko, Jordy Thielen, Thomas Moreau, Yannick Roy, Vinay Jayaram, Alexandre Barachant, and Sylvain Chevallier. Mother of all bci benchmarks v1.0. doi.org/10.5281/zenodo.10034223, 2023. DOI: 10.5281/zenodo.10034223.">2</a>, <a class="reference internal" href="#id5" title="Sylvain Chevallier, Igor Carrara, Bruno Aristimunha, Pierre Guetschel, Sara Sedlar, Bruna Lopes, Sebastien Velut, Salim Khazem, and Thomas Moreau. The largest EEG-based BCI reproducibility study for open science: the MOABB benchmark. arXiv preprint arXiv:2404.15319, 2024.">3</a>, <a class="reference internal" href="#id8" title="Jarod LÃ©vy, Mingfang Zhang, Svetlana Pinet, JÃ©rÃ©my Rapin, Hubert Banville, StÃ©phane d'Ascoli, and Jean-RÃ©mi King. Brain-to-text decoding: a non-invasive approach via typing. arXiv preprint arXiv:2502.17480, 2025.">4</a>, <a class="reference internal" href="#id9" title="Yohann Benchetrit, Hubert Banville, and Jean-Remi King. Brain decoding: toward real-time reconstruction of visual perception. In The Twelfth International Conference on Learning Representations. 2024. URL: https://openreview.net/forum?id=3y1K6buO8c.">5</a>, <a class="reference internal" href="#id11" title="StÃ©phane d'Ascoli, Corentin Bel, JÃ©rÃ©my Rapin, Hubert Banville, Yohann Benchetrit, Christophe Pallier, and Jean-RÃ©mi King. Decoding individual words from non-invasive brain recordings across 723 participants. arXiv preprint arXiv:2412.17829, 2024.">6</a>, <a class="reference internal" href="#id12" title="Denis A Engemann, Apolline Mellot, Richard HÃ¶chenberger, Hubert Banville, David Sabbagh, Lukas Gemein, Tonio Ball, and Alexandre Gramfort. A reusable benchmark of brain-age prediction from m/eeg resting-state signals. Neuroimage, 262:119521, 2022.">7</a>, <a class="reference internal" href="#id13" title="Jonathan Xu, Bruno Aristimunha, Max Emanuel Feucht, Emma Qian, Charles Liu, Tazik Shahjahan, Martyna Spyra, Steven Zifan Zhang, Nicholas Short, Jioh Kim, Paula Perdomo, Ricky Renfeng Mao, Yashvir Sabharwal, Michael Ahedor Moaz Shoura, and Adrian Nestor. Alljoined â€“ a dataset for EEG-to-image decoding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Workshop on Data Curation and Augmentation in Enhancing Medical Imaging Applications, 1â€“9. 2024.">8</a></span>.</p>
<p>We aim to translate recorded brain activity into its originating stimulus, behavior,
or mental state, <span id="id2">King and Dehaene [<a class="reference internal" href="#id14" title="Jean-RÃ©mi King and Stanislas Dehaene. Characterizing the dynamics of mental representations: the temporal generalization method. Trends in cognitive sciences, 18(4):203â€“210, 2014.">2014</a>], King <em>et al.</em> [<a class="reference internal" href="#id15" title="Jean-RÃ©mi King, Laura Gwilliams, Chris Holdgraf, Jona Sassenhagen, Alexandre Barachant, Denis Engemann, Eric Larson, and Alexandre Gramfort. Encoding and Decoding Framework to Uncover the Algorithms of Cognition. In The Cognitive Neurosciences. The MIT Press, 05 2020.">2020</a>]</span>, again, <span class="math notranslate nohighlight">\(f(X) \to y\)</span>.</p>
<p>The neural networks model <span class="math notranslate nohighlight">\(f\)</span> learns a representation that is useful for the encoded stimulus
in the subjectâ€™s brain over time seriesâ€”also known as <em>reverse inference</em>.</p>
<p>In supervised decoding, we usually learn the network parameters <span class="math notranslate nohighlight">\(\theta\)</span> by minimizing
the regularized the average loss over the training set <span class="math notranslate nohighlight">\(\mathcal{D}_{\text{tr}}=\{(x_i,y_i)\}_{i=1}^{N_{\text{tr}}}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\theta^{*}
  &amp;= \arg\min_{\theta}\, \hat{\mathcal{R}}(\theta) \\
  &amp;= \arg\min_{\theta}\, \frac{1}{N_{\text{tr}}}\sum_{i=1}^{N_{\text{tr}}}
     \ell\!\left(f_{\theta}(x_i),\, y_i\right) \;+\; \lambda\,\Omega(\theta)\,,
\end{aligned}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\ell\)</span> is the task loss (e.g., cross-entropy <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code></a>), <span class="math notranslate nohighlight">\(\Omega\)</span> is an optional regularizer, and <span class="math notranslate nohighlight">\(\lambda \ge 0\)</span> its weight (e.g. <code class="docutils literal notranslate"><span class="pre">weight_decay</span></code> parameter in <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="(in PyTorch v2.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Adam</span></code></a> is the example of regularization).</p>
<p>Equivalently, the goal is to minimize the expected risk <span class="math notranslate nohighlight">\(\mathcal{R}(\theta)=\mathbb{E}_{(x,y)\sim P_{\text{tr}}}
[\ell(f_{\theta}(x),y)]\)</span>, for which the empirical average above is a finite-sample
approximation.</p>
<p>With this, in this modelâ€™s sub-pages, we provide:</p>
<blockquote>
<div><ul class="simple">
<li><ol class="arabic simple">
<li><p>Our definition of the brain decoding problem (here);</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p><a class="reference internal" href="models_categorization.html"><span class="doc">The categorization of the neural networks based on what is inside them</span></a>;</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="3">
<li><p><a class="reference internal" href="models_table.html"><span class="doc">A table overview to understand what is inside the models</span></a>;</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="4">
<li><p><a class="reference internal" href="models_visualization.html"><span class="doc">A visualization of the common important information from the models</span></a>.</p></li>
</ol>
</li>
</ul>
</div></blockquote>
<p><span class="sd-d-grid"><a class="sd-sphinx-override sd-btn sd-text-wrap sd-btn-primary reference internal" href="models_categorization.html"><span class="doc">Next: Models categorization â†’</span></a></span></p>
<p class="rubric">References</p>
<div class="docutils container" id="id3">
<div role="list" class="citation-list">
<div class="citation" id="id4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Bruno Aristimunha, AlexandreÂ Janoni Bayerlein, M.Â Jorge Cardoso, Walter HugoÂ Lopez Pinaya, and RaphaelÂ Yokoingawa DeÂ Camargo. Sleep-Energy: An Energy Optimization Method to Sleep Stage Scoring. <em>IEEE Access</em>, 11:34595â€“34602, 2023.</p>
</div>
<div class="citation" id="id7" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">2</a><span class="fn-bracket">]</span></span>
<p>Bruno Aristimunha, Igor Carrara, Pierre Guetschel, Sara Sedlar, Pedro Rodrigues, Jan Sosulski, Divyesh Narayanan, Erik Bjareholt, Barthelemy Quentin, RobinÂ Tibor Schirrmeister, Emmanuel Kalunga, Ludovic Darmet, Cattan Gregoire, Ali AbdulÂ Hussain, Ramiro Gatti, Vladislav Goncharenko, Jordy Thielen, Thomas Moreau, Yannick Roy, Vinay Jayaram, Alexandre Barachant, and Sylvain Chevallier. Mother of all bci benchmarks v1.0. <a class="reference external" href="doi.org/10.5281/zenodo.10034223">doi.org/10.5281/zenodo.10034223</a>, 2023. DOI: 10.5281/zenodo.10034223.</p>
</div>
<div class="citation" id="id5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">3</a><span class="fn-bracket">]</span></span>
<p>Sylvain Chevallier, Igor Carrara, Bruno Aristimunha, Pierre Guetschel, Sara Sedlar, Bruna Lopes, Sebastien Velut, Salim Khazem, and Thomas Moreau. The largest EEG-based BCI reproducibility study for open science: the MOABB benchmark. <em>arXiv preprint arXiv:2404.15319</em>, 2024.</p>
</div>
<div class="citation" id="id8" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">4</a><span class="fn-bracket">]</span></span>
<p>Jarod LÃ©vy, Mingfang Zhang, Svetlana Pinet, JÃ©rÃ©my Rapin, Hubert Banville, StÃ©phane d'Ascoli, and Jean-RÃ©mi King. Brain-to-text decoding: a non-invasive approach via typing. <em>arXiv preprint arXiv:2502.17480</em>, 2025.</p>
</div>
<div class="citation" id="id9" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">5</a><span class="fn-bracket">]</span></span>
<p>Yohann Benchetrit, Hubert Banville, and Jean-Remi King. Brain decoding: toward real-time reconstruction of visual perception. In <em>The Twelfth International Conference on Learning Representations</em>. 2024. URL: <a class="reference external" href="https://openreview.net/forum?id=3y1K6buO8c">https://openreview.net/forum?id=3y1K6buO8c</a>.</p>
</div>
<div class="citation" id="id11" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">6</a><span class="fn-bracket">]</span></span>
<p>StÃ©phane d'Ascoli, Corentin Bel, JÃ©rÃ©my Rapin, Hubert Banville, Yohann Benchetrit, Christophe Pallier, and Jean-RÃ©mi King. Decoding individual words from non-invasive brain recordings across 723 participants. <em>arXiv preprint arXiv:2412.17829</em>, 2024.</p>
</div>
<div class="citation" id="id12" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">7</a><span class="fn-bracket">]</span></span>
<p>DenisÂ A Engemann, Apolline Mellot, Richard HÃ¶chenberger, Hubert Banville, David Sabbagh, Lukas Gemein, Tonio Ball, and Alexandre Gramfort. A reusable benchmark of brain-age prediction from m/eeg resting-state signals. <em>Neuroimage</em>, 262:119521, 2022.</p>
</div>
<div class="citation" id="id13" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">8</a><span class="fn-bracket">]</span></span>
<p>Jonathan Xu, Bruno Aristimunha, MaxÂ Emanuel Feucht, Emma Qian, Charles Liu, Tazik Shahjahan, Martyna Spyra, StevenÂ Zifan Zhang, Nicholas Short, Jioh Kim, Paula Perdomo, RickyÂ Renfeng Mao, Yashvir Sabharwal, Michael AhedorÂ Moaz Shoura, and Adrian Nestor. Alljoined â€“ a dataset for EEG-to-image decoding. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Workshop on Data Curation and Augmentation in Enhancing Medical Imaging Applications</em>, 1â€“9. 2024.</p>
</div>
<div class="citation" id="id14" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">9</a><span class="fn-bracket">]</span></span>
<p>Jean-RÃ©mi King and Stanislas Dehaene. Characterizing the dynamics of mental representations: the temporal generalization method. <em>Trends in cognitive sciences</em>, 18(4):203â€“210, 2014.</p>
</div>
<div class="citation" id="id15" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">10</a><span class="fn-bracket">]</span></span>
<p>Jean-RÃ©mi King, Laura Gwilliams, Chris Holdgraf, Jona Sassenhagen, Alexandre Barachant, Denis Engemann, Eric Larson, and Alexandre Gramfort. Encoding and Decoding Framework to Uncover the Algorithms of Cognition. In <em>The Cognitive Neurosciences</em>. The MIT Press, 05 2020.</p>
</div>
<div class="citation" id="id20" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></span>
<p>Shaojie Bai, JÂ Zico Kolter, and Vladlen Koltun. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. <em>arXiv preprint arXiv:1803.01271</em>, 2018.</p>
</div>
<div class="citation" id="id17" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>12<span class="fn-bracket">]</span></span>
<p>Yonghao Song, Qingqing Zheng, Bingchuan Liu, and Xiaorong Gao. Eeg conformer: convolutional transformer for eeg decoding and visualization. <em>IEEE Transactions on Neural Systems and Rehabilitation Engineering</em>, 31:710â€“719, 2022.</p>
</div>
<div class="citation" id="id18" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>13<span class="fn-bracket">]</span></span>
<p>Wei Zhao, Xiaolu Jiang, Baocan Zhang, Shixiao Xiao, and Sujun Weng. CTNet: a convolutional transformer network for EEG-based motor imagery classification. <em>Scientific reports</em>, 14(1):20237, 2024.</p>
</div>
<div class="citation" id="id19" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>14<span class="fn-bracket">]</span></span>
<p>Hamdi Altaheri, Ghulam Muhammad, and Mansour Alsulaiman. Physics-informed attention temporal convolutional network for EEG-based motor imagery classification. <em>IEEE transactions on industrial informatics</em>, 19(2):2249â€“2258, 2022.</p>
</div>
<div class="citation" id="id27" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>15<span class="fn-bracket">]</span></span>
<p>Ravikiran Mane, Effie Chew, Karen Chua, KaiÂ Keng Ang, Neethu Robinson, AÂ Prasad Vinod, Seong-Whan Lee, and Cuntai Guan. Fbcnet: a multi-view convolutional neural network for brain-computer interface. <em>arXiv preprint arXiv:2104.01233</em>, 2021.</p>
</div>
<div class="citation" id="id28" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>16<span class="fn-bracket">]</span></span>
<p>KeÂ Liu, Mingzhao Yang, Zhuliang Yu, Guoyin Wang, and Wei Wu. Fbmsnet: a filter-bank multi-scale convolutional neural network for eeg-based motor imagery decoding. <em>IEEE Transactions on Biomedical Engineering</em>, 70(2):436â€“445, 2022.</p>
</div>
<div class="citation" id="id26" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>17<span class="fn-bracket">]</span></span>
<p>Davide Borra, Silvia Fantozzi, and Elisa Magosso. Interpretable and lightweight convolutional neural network for eeg decoding: application to movement execution and imagination. <em>Neural Networks</em>, 129:55â€“74, 2020.</p>
</div>
<div class="citation" id="id25" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>18<span class="fn-bracket">]</span></span>
<p>Siegfried Ludwig, Stylianos Bakas, DimitriosÂ A Adamos, Nikolaos Laskaris, Yannis Panagakis, and Stefanos Zafeiriou. Eegminer: discovering interpretable features of brain activity with learnable filters. <em>Journal of Neural Engineering</em>, 21(3):036010, 2024.</p>
</div>
<div class="citation" id="id24" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>19<span class="fn-bracket">]</span></span>
<p>Zhiwu Huang and Luc VanÂ Gool. A riemannian network for spd matrix learning. In <em>Proceedings of the AAAI conference on artificial intelligence</em>, volumeÂ 31. 2017.</p>
</div>
<div class="citation" id="id29" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>20<span class="fn-bracket">]</span></span>
<p>Chaoqi Yang, MÂ Westover, and Jimeng Sun. Biot: biosignal transformer for cross-data learning in the wild. <em>Advances in Neural Information Processing Systems</em>, 36:78240â€“78260, 2023.</p>
</div>
<div class="citation" id="id6" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>21<span class="fn-bracket">]</span></span>
<p>Weibang Jiang, Liming Zhao, and Bao-liang Lu. Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI. In <em>The Twelfth International Conference on Learning Representations</em>. 2024. URL: <a class="reference external" href="https://openreview.net/forum?id=QzTpTRVtrP">https://openreview.net/forum?id=QzTpTRVtrP</a>.</p>
</div>
<div class="citation" id="id23" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>22<span class="fn-bracket">]</span></span>
<p>Dominik Klepl, Min Wu, and Fei He. Graph neural network-based eeg classification: a survey. <em>IEEE Transactions on Neural Systems and Rehabilitation Engineering</em>, 32:493â€“503, 2024.</p>
</div>
<div class="citation" id="id22" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>23<span class="fn-bracket">]</span></span>
<p>P.Â Guetschel, T.Â Moreau, and M.Â Tangermann. S-JEPA: towards seamless cross-dataset transfer through dynamic spatial attention. In <em>Proceedings of the 9th Graz Brain-Computer Interface Conference</em>. 2024. URL: <a class="reference external" href="https://doi.org/10.3217/978-3-99161-014-4-003">https://doi.org/10.3217/978-3-99161-014-4-003</a>, <a class="reference external" href="https://doi.org/10.3217/978-3-99161-014-4-003">doi:10.3217/978-3-99161-014-4-003</a>.</p>
</div>
<div class="citation" id="id21" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>24<span class="fn-bracket">]</span></span>
<p>Zhige Chen, Rui Yang, Mengjie Huang, Fumin Li, Guoping Lu, and Zidong Wang. Eegprogress: a fast and lightweight progressive convolution architecture for eeg classification. <em>Computers in Biology and Medicine</em>, 169:107901, 2024.</p>
</div>
</div>
</div>
<div class="toctree-wrapper compound">
</div>
</section>


  
</div>

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../install/install_source.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Installing from sources</p>
      </div>
    </a>
    <a class="right-next"
       href="models_categorization.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Models Categorization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

    <script src="https://braindecode.org/versionwarning.js"></script>
    
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item"><p class="text-center text-muted small">&copy; Copyright 2018â€“2025, Braindecode Developers.</p></div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>