

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>braindecode.regressor.EEGRegressor &mdash; Braindecode 0.5 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="braindecode.models.ShallowFBCSPNet" href="braindecode.models.ShallowFBCSPNet.html" />
    <link rel="prev" title="braindecode.classifier.EEGClassifier" href="braindecode.classifier.EEGClassifier.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> Braindecode
          

          
          </a>

          
            
            
              <div class="version">
                0.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/plot_bcic_iv_2a_moabb_trial.html"> Basic trialwise decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/plot_bcic_iv_2a_moabb_cropped.html"> More data-efficient &quot;cropped decoding&quot;</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/plot_mne_dataset_example.html"> Your own datasets through MNE</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/plot_custom_dataset_example.html"> Your own datasets through Numpy</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Braindecode examples</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../api.html#classifier">Classifier</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../api.html#regressor">Regressor</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">braindecode.regressor.EEGRegressor</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#models">Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#datasets">Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#data-utils">Data Utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#utils">Utils</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Braindecode</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../api.html">API Reference</a> &raquo;</li>
        
      <li>braindecode.regressor.EEGRegressor</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/generated/braindecode.regressor.EEGRegressor.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="braindecode-regressor-eegregressor">
<h1>braindecode.regressor.EEGRegressor<a class="headerlink" href="#braindecode-regressor-eegregressor" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="braindecode.regressor.EEGRegressor">
<em class="property">class </em><code class="sig-prename descclassname">braindecode.regressor.</code><code class="sig-name descname">EEGRegressor</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="n">cropped</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">callbacks</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">iterator_train__shuffle</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>Regressor that calls loss function directly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>module: torch module (class or instance)</strong></dt><dd><p>A PyTorch <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>. In general, the
uninstantiated class should be passed, although instantiated
modules will also work.</p>
</dd>
<dt><strong>criterion: torch criterion (class, default=torch.nn.MSELoss)</strong></dt><dd><p>Mean squared error loss.</p>
</dd>
<dt><strong>optimizer: torch optim (class, default=torch.optim.SGD)</strong></dt><dd><p>The uninitialized optimizer (update rule) used to optimize the
module</p>
</dd>
<dt><strong>lr: float (default=0.01)</strong></dt><dd><p>Learning rate passed to the optimizer. You may use <code class="docutils literal notranslate"><span class="pre">lr</span></code> instead
of using <code class="docutils literal notranslate"><span class="pre">optimizer__lr</span></code>, which would result in the same outcome.</p>
</dd>
<dt><strong>max_epochs: int (default=10)</strong></dt><dd><p>The number of epochs to train for each <code class="docutils literal notranslate"><span class="pre">fit</span></code> call. Note that you
may keyboard-interrupt training at any time.</p>
</dd>
<dt><strong>batch_size: int (default=128)</strong></dt><dd><p>Mini-batch size. Use this instead of setting
<code class="docutils literal notranslate"><span class="pre">iterator_train__batch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">iterator_test__batch_size</span></code>,
which would result in the same outcome. If <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is -1,
a single batch with all the data will be used during training
and validation.</p>
</dd>
<dt><strong>iterator_train: torch DataLoader</strong></dt><dd><p>The default PyTorch <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> used for
training data.</p>
</dd>
<dt><strong>iterator_valid: torch DataLoader</strong></dt><dd><p>The default PyTorch <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> used for
validation and test data, i.e. during inference.</p>
</dd>
<dt><strong>dataset: torch Dataset (default=skorch.dataset.Dataset)</strong></dt><dd><p>The dataset is necessary for the incoming data to work with
pytorch’s <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>. It has to implement the <code class="docutils literal notranslate"><span class="pre">__len__</span></code> and
<code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> methods. The provided dataset should be capable of
dealing with a lot of data types out of the box, so only change
this if your data is not supported. You should generally pass the
uninitialized <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class and define additional arguments to
X and y by prefixing them with <code class="docutils literal notranslate"><span class="pre">dataset__</span></code>. It is also possible
to pass an initialzed <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>, in which case no additional
arguments may be passed.</p>
</dd>
<dt><strong>train_split: None or callable (default=skorch.dataset.CVSplit(5))</strong></dt><dd><p>If None, there is no train/validation split. Else, train_split
should be a function or callable that is called with X and y
data and should return the tuple <code class="docutils literal notranslate"><span class="pre">dataset_train,</span> <span class="pre">dataset_valid</span></code>.
The validation data may be None.</p>
</dd>
<dt><strong>warm_start: bool (default=False)</strong></dt><dd><p>Whether each fit call should lead to a re-initialization of the
module (cold start) or whether the module should be trained
further (warm start).</p>
</dd>
<dt><strong>verbose: int (default=1)</strong></dt><dd><p>Control the verbosity level.</p>
</dd>
<dt><strong>device: str, torch.device (default=’cpu’)</strong></dt><dd><p>The compute device to be used. If set to ‘cuda’, data in torch
tensors will be pushed to cuda tensors before being sent to the
module. If set to None, then all compute devices will be left
unmodified.</p>
</dd>
<dt><strong>cropped: bool (default=False)</strong></dt><dd><p>Defines whether torch model passed to this class is cropped or not.
Currently used for callbacks definition.</p>
</dd>
<dt><strong>callbacks: None or list of strings or list of Callback instances (default=None)</strong></dt><dd><p>More callbacks, in addition to those returned by
<code class="docutils literal notranslate"><span class="pre">get_default_callbacks</span></code>. Each callback should inherit from
<code class="xref py py-class docutils literal notranslate"><span class="pre">skorch.callbacks.Callback</span></code>. If not <code class="docutils literal notranslate"><span class="pre">None</span></code>, callbacks can be a
list of strings specifying <cite>sklearn</cite> scoring functions (for scoring
functions names see: <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter">https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter</a>)
or a list of callbacks where the callback names are inferred from the
class name. Name conflicts are resolved by appending a count suffix
starting with 1, e.g. <code class="docutils literal notranslate"><span class="pre">EpochScoring_1</span></code>. Alternatively,
a tuple <code class="docutils literal notranslate"><span class="pre">(name,</span> <span class="pre">callback)</span></code> can be passed, where <code class="docutils literal notranslate"><span class="pre">name</span></code>
should be unique. Callbacks may or may not be instantiated.
The callback name can be used to set parameters on specific
callbacks (e.g., for the callback with name <code class="docutils literal notranslate"><span class="pre">'print_log'</span></code>, use
<code class="docutils literal notranslate"><span class="pre">net.set_params(callbacks__print_log__keys_ignored=['epoch',</span>
<span class="pre">'train_loss'])</span></code>).</p>
</dd>
<dt><strong>iterator_train__shuffle: bool (default=True)</strong></dt><dd><p>Defines whether train dataset will be shuffled. As skorch does not
shuffle the train dataset by default this one overwrites this option.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Attributes</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>prefixes_: list of str</strong></dt><dd><p>Contains the prefixes to special parameters. E.g., since there
is the <code class="docutils literal notranslate"><span class="pre">'module'</span></code> prefix, it is possible to set parameters like
so: <code class="docutils literal notranslate"><span class="pre">NeuralNet(...,</span> <span class="pre">optimizer__momentum=0.95)</span></code>.</p>
</dd>
<dt><strong>cuda_dependent_attributes_: list of str</strong></dt><dd><p>Contains a list of all attribute prefixes whose values depend on a
CUDA device. If a <code class="docutils literal notranslate"><span class="pre">NeuralNet</span></code> trained with a CUDA-enabled device
is unpickled on a machine without CUDA or with CUDA disabled, the
listed attributes are mapped to CPU.  Expand this list if you
want to add other cuda-dependent attributes.</p>
</dd>
<dt><strong>initialized_: bool</strong></dt><dd><p>Whether the <code class="xref py py-class docutils literal notranslate"><span class="pre">NeuralNet</span></code> was initialized.</p>
</dd>
<dt><strong>module_: torch module (instance)</strong></dt><dd><p>The instantiated module.</p>
</dd>
<dt><strong>criterion_: torch criterion (instance)</strong></dt><dd><p>The instantiated criterion.</p>
</dd>
<dt><strong>callbacks_: list of tuples</strong></dt><dd><p>The complete (i.e. default and other), initialized callbacks, in
a tuple with unique names.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">check_data</span></code>(X, y)</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.check_is_fitted" title="braindecode.regressor.EEGRegressor.check_is_fitted"><code class="xref py py-obj docutils literal notranslate"><span class="pre">check_is_fitted</span></code></a>([attributes])</p></td>
<td><p>Checks whether the net is initialized</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.evaluation_step" title="braindecode.regressor.EEGRegressor.evaluation_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluation_step</span></code></a>(Xi[, training])</p></td>
<td><p>Perform a forward step to produce the output used for prediction and scoring.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.fit" title="braindecode.regressor.EEGRegressor.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X, y, **fit_params)</p></td>
<td><p>See <code class="docutils literal notranslate"><span class="pre">NeuralNet.fit</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.fit_loop" title="braindecode.regressor.EEGRegressor.fit_loop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_loop</span></code></a>(X[, y, epochs])</p></td>
<td><p>The proper fit loop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.forward" title="braindecode.regressor.EEGRegressor.forward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward</span></code></a>(X[, training, device])</p></td>
<td><p>Gather and concatenate the output from forward call with input data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.forward_iter" title="braindecode.regressor.EEGRegressor.forward_iter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">forward_iter</span></code></a>(X[, training, device])</p></td>
<td><p>Yield outputs of module forward calls on each batch of data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.get_dataset" title="braindecode.regressor.EEGRegressor.get_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_dataset</span></code></a>(X[, y])</p></td>
<td><p>Get a dataset that contains the input data and is passed to the iterator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.get_iterator" title="braindecode.regressor.EEGRegressor.get_iterator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_iterator</span></code></a>(dataset[, training, drop_index])</p></td>
<td><p>Get an iterator that allows to loop over the batches of the given data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.get_loss" title="braindecode.regressor.EEGRegressor.get_loss"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_loss</span></code></a>(y_pred, y_true, *args, **kwargs)</p></td>
<td><p>Return the loss for this batch by calling NeuralNet get_loss. Parameters ———- y_pred : torch tensor   Predicted target values y_true : torch tensor   True target values. X : input data, compatible with skorch.dataset.Dataset   By default, you should be able to pass:     * numpy arrays     * torch tensors     * pandas DataFrame or Series     * scipy sparse CSR matrices     * a dictionary of the former three     * a list/tuple of the former three     * a Dataset   If this doesn’t work with your data, you have to pass a   <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data. training : bool (default=False)   Whether train mode should be used or not.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.get_split_datasets" title="braindecode.regressor.EEGRegressor.get_split_datasets"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_split_datasets</span></code></a>(X[, y])</p></td>
<td><p>Get internal train and validation datasets.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.get_train_step_accumulator" title="braindecode.regressor.EEGRegressor.get_train_step_accumulator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_train_step_accumulator</span></code></a>()</p></td>
<td><p>Return the train step accumulator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.infer" title="braindecode.regressor.EEGRegressor.infer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer</span></code></a>(x, **fit_params)</p></td>
<td><p>Perform a single inference step on a batch of data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.initialize" title="braindecode.regressor.EEGRegressor.initialize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize</span></code></a>()</p></td>
<td><p>Initializes all components of the <code class="xref py py-class docutils literal notranslate"><span class="pre">NeuralNet</span></code> and returns self.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.initialize_callbacks" title="braindecode.regressor.EEGRegressor.initialize_callbacks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize_callbacks</span></code></a>()</p></td>
<td><p>Initializes all callbacks and save the result in the <code class="docutils literal notranslate"><span class="pre">callbacks_</span></code> attribute.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.initialize_criterion" title="braindecode.regressor.EEGRegressor.initialize_criterion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize_criterion</span></code></a>()</p></td>
<td><p>Initializes the criterion.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.initialize_history" title="braindecode.regressor.EEGRegressor.initialize_history"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize_history</span></code></a>()</p></td>
<td><p>Initializes the history.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.initialize_module" title="braindecode.regressor.EEGRegressor.initialize_module"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize_module</span></code></a>()</p></td>
<td><p>Initializes the module.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.initialize_optimizer" title="braindecode.regressor.EEGRegressor.initialize_optimizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initialize_optimizer</span></code></a>([triggered_directly])</p></td>
<td><p>Initialize the model optimizer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.load_params" title="braindecode.regressor.EEGRegressor.load_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_params</span></code></a>([f_params, f_optimizer, …])</p></td>
<td><p>Loads the the module’s parameters, history, and optimizer, not the whole object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.notify" title="braindecode.regressor.EEGRegressor.notify"><code class="xref py py-obj docutils literal notranslate"><span class="pre">notify</span></code></a>(method_name, **cb_kwargs)</p></td>
<td><p>Call the callback method specified in <code class="docutils literal notranslate"><span class="pre">method_name</span></code> with parameters specified in <code class="docutils literal notranslate"><span class="pre">cb_kwargs</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_batch_begin</span></code>(net[, Xi, yi, training])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_epoch_begin</span></code>(net[, dataset_train, …])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_epoch_end</span></code>(net[, dataset_train, dataset_valid])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_begin</span></code>(net[, X, y])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">on_train_end</span></code>(net[, X, y])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.partial_fit" title="braindecode.regressor.EEGRegressor.partial_fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">partial_fit</span></code></a>(X[, y, classes])</p></td>
<td><p>Fit the module.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.predict" title="braindecode.regressor.EEGRegressor.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(X)</p></td>
<td><p>Where applicable, return class labels for samples in X.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.predict_proba" title="braindecode.regressor.EEGRegressor.predict_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_proba</span></code></a>(X)</p></td>
<td><p>Return the output of the module’s forward method as a numpy array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.run_single_epoch" title="braindecode.regressor.EEGRegressor.run_single_epoch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">run_single_epoch</span></code></a>(dataset, training, prefix, …)</p></td>
<td><p>Compute a single epoch of train or validation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.save_params" title="braindecode.regressor.EEGRegressor.save_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_params</span></code></a>([f_params, f_optimizer, f_history])</p></td>
<td><p>Saves the module’s parameters, history, and optimizer, not the whole object.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.score" title="braindecode.regressor.EEGRegressor.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(X, y[, sample_weight])</p></td>
<td><p>Return the coefficient of determination R^2 of the prediction.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.set_params" title="braindecode.regressor.EEGRegressor.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**kwargs)</p></td>
<td><p>Set the parameters of this class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.train_step" title="braindecode.regressor.EEGRegressor.train_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_step</span></code></a>(Xi, yi, **fit_params)</p></td>
<td><p>Prepares a loss function callable and pass it to the optimizer, hence performing one optimization step.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.train_step_single" title="braindecode.regressor.EEGRegressor.train_step_single"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_step_single</span></code></a>(Xi, yi, **fit_params)</p></td>
<td><p>Compute y_pred, loss value, and update net’s gradients.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#braindecode.regressor.EEGRegressor.validation_step" title="braindecode.regressor.EEGRegressor.validation_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">validation_step</span></code></a>(Xi, yi, **fit_params)</p></td>
<td><p>Perform a forward step using batched data and return the resulting loss.</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 78%" />
<col style="width: 22%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>get_default_callbacks</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_params</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>initialize_virtual_params</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>on_batch_end</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>on_grad_computed</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>predict_with_window_inds_and_ys</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.check_is_fitted">
<code class="sig-name descname">check_is_fitted</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">attributes</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.check_is_fitted" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether the net is initialized</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>attributes</strong><span class="classifier">iterable of str or None (default=None)</span></dt><dd><p>All the attributes that are strictly required of a fitted
net. By default, this is the <cite>module_</cite> attribute.</p>
</dd>
<dt><strong>Other arguments as in</strong></dt><dd></dd>
<dt><strong>``sklearn.utils.validation.check_is_fitted``.</strong></dt><dd></dd>
</dl>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><dl class="simple">
<dt>skorch.exceptions.NotInitializedError</dt><dd><p>When the given attributes are not present.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.evaluation_step">
<code class="sig-name descname">evaluation_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xi</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.evaluation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform a forward step to produce the output used for
prediction and scoring.</p>
<p>Therefore the module is set to evaluation mode by default
beforehand which can be overridden to re-enable features
like dropout by setting <code class="docutils literal notranslate"><span class="pre">training=True</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>See <code class="docutils literal notranslate"><span class="pre">NeuralNet.fit</span></code>.</p>
<p>In contrast to <code class="docutils literal notranslate"><span class="pre">NeuralNet.fit</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code> is non-optional to
avoid mistakenly forgetting about <code class="docutils literal notranslate"><span class="pre">y</span></code>. However, <code class="docutils literal notranslate"><span class="pre">y</span></code> can be
set to <code class="docutils literal notranslate"><span class="pre">None</span></code> in case it is derived dynamically from
<code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.fit_loop">
<code class="sig-name descname">fit_loop</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">epochs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.fit_loop" title="Permalink to this definition">¶</a></dt>
<dd><p>The proper fit loop.</p>
<p>Contains the logic of what actually happens during the fit
loop.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">input data, compatible with skorch.dataset.Dataset</span></dt><dd><p>By default, you should be able to pass:</p>
<blockquote>
<div><ul class="simple">
<li><p>numpy arrays</p></li>
<li><p>torch tensors</p></li>
<li><p>pandas DataFrame or Series</p></li>
<li><p>scipy sparse CSR matrices</p></li>
<li><p>a dictionary of the former three</p></li>
<li><p>a list/tuple of the former three</p></li>
<li><p>a Dataset</p></li>
</ul>
</div></blockquote>
<p>If this doesn’t work with your data, you have to pass a
<code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data.</p>
</dd>
<dt><strong>y</strong><span class="classifier">target data, compatible with skorch.dataset.Dataset</span></dt><dd><p>The same data types as for <code class="docutils literal notranslate"><span class="pre">X</span></code> are supported. If your X is
a Dataset that contains the target, <code class="docutils literal notranslate"><span class="pre">y</span></code> may be set to
None.</p>
</dd>
<dt><strong>epochs</strong><span class="classifier">int or None (default=None)</span></dt><dd><p>If int, train for this number of epochs; if None, use
<code class="docutils literal notranslate"><span class="pre">self.max_epochs</span></code>.</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional parameters passed to the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of
the module and to the <code class="docutils literal notranslate"><span class="pre">self.train_split</span></code> call.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">device</span><span class="o">=</span><span class="default_value">'cpu'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Gather and concatenate the output from forward call with
input data.</p>
<p>The outputs from <code class="docutils literal notranslate"><span class="pre">self.module_.forward</span></code> are gathered on the
compute device specified by <code class="docutils literal notranslate"><span class="pre">device</span></code> and then concatenated
using PyTorch <code class="xref py py-func docutils literal notranslate"><span class="pre">cat()</span></code>. If multiple outputs are
returned by <code class="docutils literal notranslate"><span class="pre">self.module_.forward</span></code>, each one of them must be
able to be concatenated this way.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">input data, compatible with skorch.dataset.Dataset</span></dt><dd><p>By default, you should be able to pass:</p>
<blockquote>
<div><ul class="simple">
<li><p>numpy arrays</p></li>
<li><p>torch tensors</p></li>
<li><p>pandas DataFrame or Series</p></li>
<li><p>scipy sparse CSR matrices</p></li>
<li><p>a dictionary of the former three</p></li>
<li><p>a list/tuple of the former three</p></li>
<li><p>a Dataset</p></li>
</ul>
</div></blockquote>
<p>If this doesn’t work with your data, you have to pass a
<code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data.</p>
</dd>
<dt><strong>training</strong><span class="classifier">bool (default=False)</span></dt><dd><p>Whether to set the module to train mode or not.</p>
</dd>
<dt><strong>device</strong><span class="classifier">string (default=’cpu’)</span></dt><dd><p>The device to store each inference result on.
This defaults to CPU memory since there is genereally
more memory available there. For performance reasons
this might be changed to a specific CUDA device,
e.g. ‘cuda:0’.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y_infer</strong><span class="classifier">torch tensor</span></dt><dd><p>The result from the forward step.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.forward_iter">
<code class="sig-name descname">forward_iter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">device</span><span class="o">=</span><span class="default_value">'cpu'</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.forward_iter" title="Permalink to this definition">¶</a></dt>
<dd><p>Yield outputs of module forward calls on each batch of data.
The storage device of the yielded tensors is determined
by the <code class="docutils literal notranslate"><span class="pre">device</span></code> parameter.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">input data, compatible with skorch.dataset.Dataset</span></dt><dd><p>By default, you should be able to pass:</p>
<blockquote>
<div><ul class="simple">
<li><p>numpy arrays</p></li>
<li><p>torch tensors</p></li>
<li><p>pandas DataFrame or Series</p></li>
<li><p>scipy sparse CSR matrices</p></li>
<li><p>a dictionary of the former three</p></li>
<li><p>a list/tuple of the former three</p></li>
<li><p>a Dataset</p></li>
</ul>
</div></blockquote>
<p>If this doesn’t work with your data, you have to pass a
<code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data.</p>
</dd>
<dt><strong>training</strong><span class="classifier">bool (default=False)</span></dt><dd><p>Whether to set the module to train mode or not.</p>
</dd>
<dt><strong>device</strong><span class="classifier">string (default=’cpu’)</span></dt><dd><p>The device to store each inference result on.
This defaults to CPU memory since there is genereally
more memory available there. For performance reasons
this might be changed to a specific CUDA device,
e.g. ‘cuda:0’.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>yp</strong><span class="classifier">torch tensor</span></dt><dd><p>Result from a forward call on an individual batch.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.get_dataset">
<code class="sig-name descname">get_dataset</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.get_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a dataset that contains the input data and is passed to
the iterator.</p>
<p>Override this if you want to initialize your dataset
differently.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">input data, compatible with skorch.dataset.Dataset</span></dt><dd><p>By default, you should be able to pass:</p>
<blockquote>
<div><ul class="simple">
<li><p>numpy arrays</p></li>
<li><p>torch tensors</p></li>
<li><p>pandas DataFrame or Series</p></li>
<li><p>scipy sparse CSR matrices</p></li>
<li><p>a dictionary of the former three</p></li>
<li><p>a list/tuple of the former three</p></li>
<li><p>a Dataset</p></li>
</ul>
</div></blockquote>
<p>If this doesn’t work with your data, you have to pass a
<code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data.</p>
</dd>
<dt><strong>y</strong><span class="classifier">target data, compatible with skorch.dataset.Dataset</span></dt><dd><p>The same data types as for <code class="docutils literal notranslate"><span class="pre">X</span></code> are supported. If your X is
a Dataset that contains the target, <code class="docutils literal notranslate"><span class="pre">y</span></code> may be set to
None.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>dataset</dt><dd><p>The initialized dataset.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.get_iterator">
<code class="sig-name descname">get_iterator</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">training</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">drop_index</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.get_iterator" title="Permalink to this definition">¶</a></dt>
<dd><p>Get an iterator that allows to loop over the batches of the
given data.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">self.iterator_train__batch_size</span></code> and/or
<code class="docutils literal notranslate"><span class="pre">self.iterator_test__batch_size</span></code> are not set, use
<code class="docutils literal notranslate"><span class="pre">self.batch_size</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>dataset</strong><span class="classifier">torch Dataset (default=skorch.dataset.Dataset)</span></dt><dd><p>Usually, <code class="docutils literal notranslate"><span class="pre">self.dataset</span></code>, initialized with the corresponding
data, is passed to <code class="docutils literal notranslate"><span class="pre">get_iterator</span></code>.</p>
</dd>
<dt><strong>training</strong><span class="classifier">bool (default=False)</span></dt><dd><p>Whether to use <code class="docutils literal notranslate"><span class="pre">iterator_train</span></code> or <code class="docutils literal notranslate"><span class="pre">iterator_test</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>iterator</dt><dd><p>An instantiated iterator that allows to loop over the
mini-batches.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.get_loss">
<code class="sig-name descname">get_loss</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">y_pred</span></em>, <em class="sig-param"><span class="n">y_true</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.get_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the loss for this batch by calling NeuralNet get_loss.
Parameters
———-
y_pred : torch tensor</p>
<blockquote>
<div><p>Predicted target values</p>
</div></blockquote>
<dl>
<dt>y_true<span class="classifier">torch tensor</span></dt><dd><p>True target values.</p>
</dd>
<dt>X<span class="classifier">input data, compatible with skorch.dataset.Dataset</span></dt><dd><dl class="simple">
<dt>By default, you should be able to pass:</dt><dd><ul class="simple">
<li><p>numpy arrays</p></li>
<li><p>torch tensors</p></li>
<li><p>pandas DataFrame or Series</p></li>
<li><p>scipy sparse CSR matrices</p></li>
<li><p>a dictionary of the former three</p></li>
<li><p>a list/tuple of the former three</p></li>
<li><p>a Dataset</p></li>
</ul>
</dd>
</dl>
<p>If this doesn’t work with your data, you have to pass a
<code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data.</p>
</dd>
<dt>training<span class="classifier">bool (default=False)</span></dt><dd><p>Whether train mode should be used or not.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.get_split_datasets">
<code class="sig-name descname">get_split_datasets</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.get_split_datasets" title="Permalink to this definition">¶</a></dt>
<dd><p>Get internal train and validation datasets.</p>
<p>The validation dataset can be None if <code class="docutils literal notranslate"><span class="pre">self.train_split</span></code> is
set to None; then internal validation will be skipped.</p>
<p>Override this if you want to change how the net splits
incoming data into train and validation part.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">input data, compatible with skorch.dataset.Dataset</span></dt><dd><p>By default, you should be able to pass:</p>
<blockquote>
<div><ul class="simple">
<li><p>numpy arrays</p></li>
<li><p>torch tensors</p></li>
<li><p>pandas DataFrame or Series</p></li>
<li><p>scipy sparse CSR matrices</p></li>
<li><p>a dictionary of the former three</p></li>
<li><p>a list/tuple of the former three</p></li>
<li><p>a Dataset</p></li>
</ul>
</div></blockquote>
<p>If this doesn’t work with your data, you have to pass a
<code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data.</p>
</dd>
<dt><strong>y</strong><span class="classifier">target data, compatible with skorch.dataset.Dataset</span></dt><dd><p>The same data types as for <code class="docutils literal notranslate"><span class="pre">X</span></code> are supported. If your X is
a Dataset that contains the target, <code class="docutils literal notranslate"><span class="pre">y</span></code> may be set to
None.</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional parameters passed to the <code class="docutils literal notranslate"><span class="pre">self.train_split</span></code>
call.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>dataset_train</dt><dd><p>The initialized training dataset.</p>
</dd>
<dt>dataset_valid</dt><dd><p>The initialized validation dataset or None</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.get_train_step_accumulator">
<code class="sig-name descname">get_train_step_accumulator</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.get_train_step_accumulator" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the train step accumulator.</p>
<p>By default, the accumulator stores and retrieves the first
value from the optimizer call. Most optimizers make only one
call, so first value is at the same time the only value.</p>
<p>In case of some optimizers, e.g. LBFGS,
<code class="docutils literal notranslate"><span class="pre">train_step_calc_gradient</span></code> is called multiple times, as the
loss function is evaluated multiple times per optimizer
call. If you don’t want to return the first value in that
case, override this method to return your custom accumulator.</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.infer">
<code class="sig-name descname">infer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.infer" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform a single inference step on a batch of data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">input data</span></dt><dd><p>A batch of the input data.</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional parameters passed to the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of
the module and to the <code class="docutils literal notranslate"><span class="pre">self.train_split</span></code> call.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.initialize">
<code class="sig-name descname">initialize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes all components of the <code class="xref py py-class docutils literal notranslate"><span class="pre">NeuralNet</span></code> and
returns self.</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.initialize_callbacks">
<code class="sig-name descname">initialize_callbacks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.initialize_callbacks" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes all callbacks and save the result in the
<code class="docutils literal notranslate"><span class="pre">callbacks_</span></code> attribute.</p>
<p>Both <code class="docutils literal notranslate"><span class="pre">default_callbacks</span></code> and <code class="docutils literal notranslate"><span class="pre">callbacks</span></code> are used (in that
order). Callbacks may either be initialized or not, and if
they don’t have a name, the name is inferred from the class
name. The <code class="docutils literal notranslate"><span class="pre">initialize</span></code> method is called on all callbacks.</p>
<p>The final result will be a list of tuples, where each tuple
consists of a name and an initialized callback. If names are
not unique, a ValueError is raised.</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.initialize_criterion">
<code class="sig-name descname">initialize_criterion</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.initialize_criterion" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes the criterion.</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.initialize_history">
<code class="sig-name descname">initialize_history</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.initialize_history" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes the history.</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.initialize_module">
<code class="sig-name descname">initialize_module</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.initialize_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes the module.</p>
<p>Note that if the module has learned parameters, those will be
reset.</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.initialize_optimizer">
<code class="sig-name descname">initialize_optimizer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">triggered_directly</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.initialize_optimizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize the model optimizer. If <code class="docutils literal notranslate"><span class="pre">self.optimizer__lr</span></code>
is not set, use <code class="docutils literal notranslate"><span class="pre">self.lr</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>triggered_directly</strong><span class="classifier">bool (default=True)</span></dt><dd><p>Only relevant when optimizer is re-initialized.
Initialization of the optimizer can be triggered directly
(e.g. when lr was changed) or indirectly (e.g. when the
module was re-initialized). If and only if the former
happens, the user should receive a message informing them
about the parameters that caused the re-initialization.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.load_params">
<code class="sig-name descname">load_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">f_params</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">f_optimizer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">f_history</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">checkpoint</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.load_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads the the module’s parameters, history, and optimizer,
not the whole object.</p>
<p>To save and load the whole object, use pickle.</p>
<p><code class="docutils literal notranslate"><span class="pre">f_params</span></code> and <code class="docutils literal notranslate"><span class="pre">f_optimizer</span></code> uses PyTorchs’
<code class="xref py py-func docutils literal notranslate"><span class="pre">save()</span></code>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>f_params</strong><span class="classifier">file-like object, str, None (default=None)</span></dt><dd><p>Path of module parameters. Pass <code class="docutils literal notranslate"><span class="pre">None</span></code> to not load.</p>
</dd>
<dt><strong>f_optimizer</strong><span class="classifier">file-like object, str, None (default=None)</span></dt><dd><p>Path of optimizer. Pass <code class="docutils literal notranslate"><span class="pre">None</span></code> to not load.</p>
</dd>
<dt><strong>f_history</strong><span class="classifier">file-like object, str, None (default=None)</span></dt><dd><p>Path to history. Pass <code class="docutils literal notranslate"><span class="pre">None</span></code> to not load.</p>
</dd>
<dt><strong>checkpoint</strong><span class="classifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">Checkpoint</span></code>, None (default=None)</span></dt><dd><p>Checkpoint to load params from. If a checkpoint and a <code class="docutils literal notranslate"><span class="pre">f_*</span></code>
path is passed in, the <code class="docutils literal notranslate"><span class="pre">f_*</span></code> will be loaded. Pass
<code class="docutils literal notranslate"><span class="pre">None</span></code> to not load.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">before</span> <span class="o">=</span> <span class="n">NeuralNetClassifier</span><span class="p">(</span><span class="n">mymodule</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">before</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">f_params</span><span class="o">=</span><span class="s1">&#39;model.pkl&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">f_optimizer</span><span class="o">=</span><span class="s1">&#39;optimizer.pkl&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">f_history</span><span class="o">=</span><span class="s1">&#39;history.json&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">after</span> <span class="o">=</span> <span class="n">NeuralNetClassifier</span><span class="p">(</span><span class="n">mymodule</span><span class="p">)</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">after</span><span class="o">.</span><span class="n">load_params</span><span class="p">(</span><span class="n">f_params</span><span class="o">=</span><span class="s1">&#39;model.pkl&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="n">f_optimizer</span><span class="o">=</span><span class="s1">&#39;optimizer.pkl&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="n">f_history</span><span class="o">=</span><span class="s1">&#39;history.json&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.notify">
<code class="sig-name descname">notify</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">method_name</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">cb_kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.notify" title="Permalink to this definition">¶</a></dt>
<dd><p>Call the callback method specified in <code class="docutils literal notranslate"><span class="pre">method_name</span></code> with
parameters specified in <code class="docutils literal notranslate"><span class="pre">cb_kwargs</span></code>.</p>
<p>Method names can be one of:
* on_train_begin
* on_train_end
* on_epoch_begin
* on_epoch_end
* on_batch_begin
* on_batch_end</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.partial_fit">
<code class="sig-name descname">partial_fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">classes</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the module.</p>
<p>If the module is initialized, it is not re-initialized, which
means that this method should be used if you want to continue
training a model (warm start).</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">input data, compatible with skorch.dataset.Dataset</span></dt><dd><p>By default, you should be able to pass:</p>
<blockquote>
<div><ul class="simple">
<li><p>numpy arrays</p></li>
<li><p>torch tensors</p></li>
<li><p>pandas DataFrame or Series</p></li>
<li><p>scipy sparse CSR matrices</p></li>
<li><p>a dictionary of the former three</p></li>
<li><p>a list/tuple of the former three</p></li>
<li><p>a Dataset</p></li>
</ul>
</div></blockquote>
<p>If this doesn’t work with your data, you have to pass a
<code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data.</p>
</dd>
<dt><strong>y</strong><span class="classifier">target data, compatible with skorch.dataset.Dataset</span></dt><dd><p>The same data types as for <code class="docutils literal notranslate"><span class="pre">X</span></code> are supported. If your X is
a Dataset that contains the target, <code class="docutils literal notranslate"><span class="pre">y</span></code> may be set to
None.</p>
</dd>
<dt><strong>classes</strong><span class="classifier">array, sahpe (n_classes,)</span></dt><dd><p>Solely for sklearn compatibility, currently unused.</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional parameters passed to the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of
the module and to the <code class="docutils literal notranslate"><span class="pre">self.train_split</span></code> call.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Where applicable, return class labels for samples in X.</p>
<p>If the module’s forward method returns multiple outputs as a
tuple, it is assumed that the first output contains the
relevant information and the other values are ignored. If all
values are relevant, consider using
<code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> instead.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">input data, compatible with skorch.dataset.Dataset</span></dt><dd><p>By default, you should be able to pass:</p>
<blockquote>
<div><ul class="simple">
<li><p>numpy arrays</p></li>
<li><p>torch tensors</p></li>
<li><p>pandas DataFrame or Series</p></li>
<li><p>scipy sparse CSR matrices</p></li>
<li><p>a dictionary of the former three</p></li>
<li><p>a list/tuple of the former three</p></li>
<li><p>a Dataset</p></li>
</ul>
</div></blockquote>
<p>If this doesn’t work with your data, you have to pass a
<code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y_pred</strong><span class="classifier">numpy ndarray</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.predict_proba">
<code class="sig-name descname">predict_proba</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the output of the module’s forward method as a numpy
array.</p>
<p>If the module’s forward method returns multiple outputs as a
tuple, it is assumed that the first output contains the
relevant information and the other values are ignored. If all
values are relevant, consider using
<code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code> instead.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">input data, compatible with skorch.dataset.Dataset</span></dt><dd><p>By default, you should be able to pass:</p>
<blockquote>
<div><ul class="simple">
<li><p>numpy arrays</p></li>
<li><p>torch tensors</p></li>
<li><p>pandas DataFrame or Series</p></li>
<li><p>scipy sparse CSR matrices</p></li>
<li><p>a dictionary of the former three</p></li>
<li><p>a list/tuple of the former three</p></li>
<li><p>a Dataset</p></li>
</ul>
</div></blockquote>
<p>If this doesn’t work with your data, you have to pass a
<code class="docutils literal notranslate"><span class="pre">Dataset</span></code> that can deal with the data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y_proba</strong><span class="classifier">numpy ndarray</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.run_single_epoch">
<code class="sig-name descname">run_single_epoch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dataset</span></em>, <em class="sig-param"><span class="n">training</span></em>, <em class="sig-param"><span class="n">prefix</span></em>, <em class="sig-param"><span class="n">step_fn</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.run_single_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute a single epoch of train or validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>dataset</strong><span class="classifier">torch Dataset</span></dt><dd><p>The initialized dataset to loop over.</p>
</dd>
<dt><strong>training</strong><span class="classifier">bool</span></dt><dd><p>Whether to set the module to train mode or not.</p>
</dd>
<dt><strong>prefix</strong><span class="classifier">str</span></dt><dd><p>Prefix to use when saving to the history.</p>
</dd>
<dt><strong>step_fn</strong><span class="classifier">callable</span></dt><dd><p>Function to call for each batch.</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional parameters passed to the <code class="docutils literal notranslate"><span class="pre">step_fn</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.save_params">
<code class="sig-name descname">save_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">f_params</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">f_optimizer</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">f_history</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.save_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the module’s parameters, history, and optimizer,
not the whole object.</p>
<p>To save the whole object, use pickle. This is necessary when
you need additional learned attributes on the net, e.g. the
<code class="docutils literal notranslate"><span class="pre">classes_</span></code> attribute on
<code class="xref py py-class docutils literal notranslate"><span class="pre">skorch.classifier.NeuralNetClassifier</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">f_params</span></code> and <code class="docutils literal notranslate"><span class="pre">f_optimizer</span></code> uses PyTorchs’
<code class="xref py py-func docutils literal notranslate"><span class="pre">save()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>f_params</strong><span class="classifier">file-like object, str, None (default=None)</span></dt><dd><p>Path of module parameters. Pass <code class="docutils literal notranslate"><span class="pre">None</span></code> to not save</p>
</dd>
<dt><strong>f_optimizer</strong><span class="classifier">file-like object, str, None (default=None)</span></dt><dd><p>Path of optimizer. Pass <code class="docutils literal notranslate"><span class="pre">None</span></code> to not save</p>
</dd>
<dt><strong>f_history</strong><span class="classifier">file-like object, str, None (default=None)</span></dt><dd><p>Path to history. Pass <code class="docutils literal notranslate"><span class="pre">None</span></code> to not save</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">before</span> <span class="o">=</span> <span class="n">NeuralNetClassifier</span><span class="p">(</span><span class="n">mymodule</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">before</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">f_params</span><span class="o">=</span><span class="s1">&#39;model.pkl&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">f_optimizer</span><span class="o">=</span><span class="s1">&#39;optimizer.pkl&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                   <span class="n">f_history</span><span class="o">=</span><span class="s1">&#39;history.json&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">after</span> <span class="o">=</span> <span class="n">NeuralNetClassifier</span><span class="p">(</span><span class="n">mymodule</span><span class="p">)</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">after</span><span class="o">.</span><span class="n">load_params</span><span class="p">(</span><span class="n">f_params</span><span class="o">=</span><span class="s1">&#39;model.pkl&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="n">f_optimizer</span><span class="o">=</span><span class="s1">&#39;optimizer.pkl&#39;</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="n">f_history</span><span class="o">=</span><span class="s1">&#39;history.json&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span></em>, <em class="sig-param"><span class="n">sample_weight</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the residual
sum of squares ((y_true - y_pred) ** 2).sum() and v is the total
sum of squares ((y_true - y_true.mean()) ** 2).sum().
The best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like of shape (n_samples, n_features)</span></dt><dd><p>Test samples. For some estimators this may be a
precomputed kernel matrix or a list of generic objects instead,
shape = (n_samples, n_samples_fitted),
where n_samples_fitted is the number of
samples used in the fitting for the estimator.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs)</span></dt><dd><p>True values for X.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Sample weights.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p>R^2 of self.predict(X) wrt. y.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The R2 score used when calling <code class="docutils literal notranslate"><span class="pre">score</span></code> on a regressor uses
<code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> from version 0.23 to keep consistent
with default value of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="(in scikit-learn v0.23)"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score()</span></code></a>.
This influences the <code class="docutils literal notranslate"><span class="pre">score</span></code> method of all the multioutput
regressors (except for
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="(in scikit-learn v0.23)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.set_params">
<code class="sig-name descname">set_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this class.</p>
<p>Valid parameter keys can be listed with <code class="docutils literal notranslate"><span class="pre">get_params()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt>self</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.train_step">
<code class="sig-name descname">train_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xi</span></em>, <em class="sig-param"><span class="n">yi</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.train_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Prepares a loss function callable and pass it to the optimizer,
hence performing one optimization step.</p>
<p>Loss function callable as required by some optimizers (and accepted by
all of them):
<a class="reference external" href="https://pytorch.org/docs/master/optim.html#optimizer-step-closure">https://pytorch.org/docs/master/optim.html#optimizer-step-closure</a></p>
<p>The module is set to be in train mode (e.g. dropout is
applied).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>Xi</strong><span class="classifier">input data</span></dt><dd><p>A batch of the input data.</p>
</dd>
<dt><strong>yi</strong><span class="classifier">target data</span></dt><dd><p>A batch of the target data.</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional parameters passed to the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of
the module and to the train_split call.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.train_step_single">
<code class="sig-name descname">train_step_single</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xi</span></em>, <em class="sig-param"><span class="n">yi</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.train_step_single" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute y_pred, loss value, and update net’s gradients.</p>
<p>The module is set to be in train mode (e.g. dropout is
applied).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>Xi</strong><span class="classifier">input data</span></dt><dd><p>A batch of the input data.</p>
</dd>
<dt><strong>yi</strong><span class="classifier">target data</span></dt><dd><p>A batch of the target data.</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional parameters passed to the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of
the module and to the <code class="docutils literal notranslate"><span class="pre">self.train_split</span></code> call.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="braindecode.regressor.EEGRegressor.validation_step">
<code class="sig-name descname">validation_step</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Xi</span></em>, <em class="sig-param"><span class="n">yi</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">fit_params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#braindecode.regressor.EEGRegressor.validation_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform a forward step using batched data and return the
resulting loss.</p>
<p>The module is set to be in evaluation mode (e.g. dropout is
not applied).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>Xi</strong><span class="classifier">input data</span></dt><dd><p>A batch of the input data.</p>
</dd>
<dt><strong>yi</strong><span class="classifier">target data</span></dt><dd><p>A batch of the target data.</p>
</dd>
<dt><strong>**fit_params</strong><span class="classifier">dict</span></dt><dd><p>Additional parameters passed to the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of
the module and to the <code class="docutils literal notranslate"><span class="pre">self.train_split</span></code> call.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div style='clear:both'></div></div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="braindecode.models.ShallowFBCSPNet.html" class="btn btn-neutral float-right" title="braindecode.models.ShallowFBCSPNet" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="braindecode.classifier.EEGClassifier.html" class="btn btn-neutral float-left" title="braindecode.classifier.EEGClassifier" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2018-2020, Braindecode developers

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>