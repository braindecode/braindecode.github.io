{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTrialwise Decoding on BCIC IV 2a Dataset.\n=============================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Maciej Sliwowski <maciek.sliwowski@gmail.com>\n#          Robin Tibor Schirrmeister <robintibor@gmail.com>\n#          Lukas Gemein <l.gemein@gmail.com>\n#          Hubert Banville <hubert.jbanville@gmail.com>\n#\n# License: BSD-3\nfrom collections import OrderedDict\nfrom functools import partial\n\nimport numpy as np\nimport torch\nimport mne\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nfrom skorch.callbacks import LRScheduler\nmne.set_log_level('ERROR')\n\nfrom braindecode import EEGClassifier\nfrom braindecode.datautil import create_windows_from_events\nfrom braindecode.datasets import MOABBDataset\nfrom braindecode.models import Deep4Net\nfrom braindecode.models import ShallowFBCSPNet\nfrom braindecode.util import set_random_seeds\nfrom braindecode.datautil.signalproc import exponential_running_standardize\nfrom braindecode.datautil.transforms import transform_concat_ds\n\nsubject_id = 3  # 1-9\nmodel_name = \"shallow\"  # 'shallow' or 'deep'\nlow_cut_hz = 4.  # 0 or 4\nn_epochs = 5\nseed = 20200220\n\nhigh_cut_hz = 38.\ntrial_start_offset_seconds = -0.5\ninput_time_length = 1125\nbatch_size = 64\nfactor_new = 1e-3\ninit_block_size = 1000\ncuda = torch.cuda.is_available()\ndevice = 'cuda' if cuda else 'cpu'\nif cuda:\n    torch.backends.cudnn.benchmark = True\n\nn_classes = 4\nn_chans = 22\n\nset_random_seeds(seed=seed, cuda=cuda)\n\nif model_name == \"shallow\":\n    model = ShallowFBCSPNet(\n        n_chans,\n        n_classes,\n        input_time_length=input_time_length,\n        final_conv_length='auto',\n    )\n    lr = 0.0625 * 0.01\n    weight_decay = 0\n\nelif model_name == \"deep\":\n    model = Deep4Net(\n        n_chans,\n        n_classes,\n        input_time_length=input_time_length,\n        final_conv_length='auto',\n    )\n    lr = 1 * 0.01\n    weight_decay = 0.5 * 0.001\n\nif cuda:\n    model.cuda()\n\ndataset = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids=[subject_id])\n\nstandardize_func = partial(\n    exponential_running_standardize, factor_new=factor_new,\n    init_block_size=init_block_size)\nraw_transform_dict = OrderedDict([\n    (\"pick_types\", dict(eeg=True, meg=False, stim=False)),\n    ('apply_function', dict(fun=lambda x: x * 1e6, channel_wise=False)),\n    ('filter', dict(l_freq=low_cut_hz, h_freq=high_cut_hz)),\n    ('apply_function', dict(fun=standardize_func, channel_wise=False))\n])\ntransform_concat_ds(dataset, raw_transform_dict)\n\nsfreqs = [ds.raw.info['sfreq'] for ds in dataset.datasets]\nassert len(np.unique(sfreqs)) == 1\ntrial_start_offset_samples = int(trial_start_offset_seconds * sfreqs[0])\n\nwindows_dataset = create_windows_from_events(\n    dataset,\n    trial_start_offset_samples=trial_start_offset_samples,\n    trial_stop_offset_samples=0,\n    supercrop_size_samples=input_time_length,\n    supercrop_stride_samples=input_time_length,\n    drop_samples=False,\n    preload=True,\n)\n\n\nclass TrainTestBCICIV2aSplit(object):\n    def __call__(self, dataset, y, **kwargs):\n        splitted = dataset.split('session')\n        return splitted['session_T'], splitted['session_E']\n\n\nclf = EEGClassifier(\n    model,\n    cropped=False,\n    criterion=torch.nn.NLLLoss,\n    optimizer=torch.optim.AdamW,\n    train_split=TrainTestBCICIV2aSplit(),\n    optimizer__lr=lr,\n    optimizer__weight_decay=weight_decay,\n    iterator_train__shuffle=True,\n    batch_size=batch_size,\n    callbacks=[\n        \"accuracy\",\n        # seems n_epochs -1 leads to desired behavior of lr=0 after end of training?\n        (\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n    ],\n    device=device,\n)\n\nclf.fit(windows_dataset, y=None, epochs=n_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ignore_keys = [\n        'batches', 'train_batch_count', 'valid_batch_count',\n        'train_loss_best',\n        'valid_loss_best', 'train_accuracy_best',\n        'valid_accuracy_best', 'dur']\nresults = [dict([(key, val) for key, val in hist_dict.items() if\n                key not in ignore_keys])\n           for hist_dict in clf.history]\n\ndf = pd.DataFrame(results).set_index('epoch')\n# get percent of misclass for better visual comparison to loss\ndf = df.assign(train_misclass=100 - 100 * df.train_accuracy,\n         valid_misclass=100 - 100 * df.valid_accuracy)\n\nplt.style.use('seaborn')\nfig, ax1 = plt.subplots(figsize=(8,3))\n\ndf.loc[:,['train_loss', 'valid_loss']].plot(\n    ax=ax1, style=['-',':'], marker='o',\n    color='tab:blue', legend=False, fontsize=14)\n\nax1.tick_params(axis='y', labelcolor='tab:blue', labelsize=14)\nax1.set_ylabel(\"Loss\", color='tab:blue', fontsize=14)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\ndf.loc[:,['train_misclass', 'valid_misclass']].plot(\n    ax=ax2, style=['-',':'], marker='o',\n    color='tab:red', legend=False)\nax2.tick_params(axis='y', labelcolor='tab:red', labelsize=14)\nax2.set_ylabel(\"Misclassification Rate [%]\", color='tab:red', fontsize=14)\nax2.set_ylim(ax2.get_ylim()[0],85) # make some room for legend\nax1.set_xlabel(\"Epoch\", fontsize=14)\n\n# where some data has already been plotted to ax\nhandles = []\nhandles.append(Line2D([0], [0], color='black', linewidth=1, linestyle='-', label='Train'))\nhandles.append(Line2D([0], [0], color='black', linewidth=1, linestyle=':', label='Valid'))\nplt.legend(handles,[h.get_label() for h in handles], fontsize=14,)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}