{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSimple Moabb Dataset Example\n=========================\n\nShowcasing how to fetch and crop a moabb dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Lukas Gemein <l.gemein@gmail.com>\n#\n# License: BSD (3-clause)\n\nfrom braindecode.datasets import MOABBDataset\n\n# create a dataset based on BCIC IV 2a fetched with moabb\nds = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids=[4],\n                  trial_start_offset_samples=0, trial_stop_offset_samples=1000,\n                  supercrop_size_samples=1000, supercrop_stride_samples=1000)\n\n# we can iterate through ds which yields an example x, target y,\n# and info as i_supercrop_in_trial, i_start_in_trial, and i_stop_in_trial\n# which is required for combining supercrop predictions in the scorer\nfor x, y, info in ds:\n    print(x.shape, y, info)\n    break\n\n# each base_ds in ds has its own info DataFrame\nprint(ds.datasets[-1].info)\n# ds has a concattenation of all DataFrames of its datasets\nprint(ds.info)\n\n# we can easily split ds based on a criterium in the info DataFrame\nsubsets = ds.split(\"session\")\nprint(subsets)\n\n# again we can iterate through the subsets as through the ds\nfor x, y, info in subsets[\"session_E\"]:\n    print(x.shape, y, info)\n    break\n\n# create a dataset based on TUH Abnormal EEG Corpus (v2.0.0)\n# for this dataset, no events exist but a label (pathological / non-pathological\n# is valid for the entire recording\n# ds = TUHAbnormal(path=\"/path/to/the/directory/\",\n#                  subject_ids=[0, 1], trial_start_offset_samples=0,\n#                  trial_stop_offset_samples=1000, supercrop_size_samples=1000,\n#                  supercrop_stride_samples=1000, mapping={False: 0, True: 1})\n\n# as before, we can iterate through the dataset, getting the same kind of info\n# for x, y, info in ds:\n#     print(x.get_data().shape, y, info)\n#     break\n\n# we can change the target for this dataset to 'age'\n# ds = TUHAbnormal(path=\"/path/to/the/directory/\",\n#                  subject_ids=[0, 1], trial_start_offset_samples=0,\n#                  trial_stop_offset_samples=1000, supercrop_size_samples=1000,\n#                  supercrop_stride_samples=1000, target=\"age\",\n#                  mapping={False: 0, True: 1})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}