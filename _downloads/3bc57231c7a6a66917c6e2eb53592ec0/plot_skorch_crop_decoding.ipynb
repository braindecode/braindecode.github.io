{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSkorch Crop Decoding\n=========================\n\nExample using Skorch for crop decoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Lukas Gemein\n#          Robin Tibor Schirrmeister\n#          Alexandre Gramfort\n#          Maciej Sliwowski\n#\n# License: BSD-3\n\nimport numpy as np\n\nimport mne\nfrom mne.io import concatenate_raws\n\nimport torch\nfrom torch import optim\nfrom torch.utils.data import Dataset\n\nfrom skorch.net import NeuralNet\nfrom skorch.callbacks.scoring import EpochScoring\n\nfrom braindecode.models import ShallowFBCSPNet\nfrom braindecode.util import set_random_seeds\nfrom braindecode.datautil import CropsDataLoader\nfrom braindecode.models.util import to_dense_prediction_model\nfrom braindecode.experiments.scoring import CroppedTrialEpochScoring\n\nsubject_id = 22  # carefully cherry-picked to give nice results on such limited data :)\nevent_codes = [5, 6, 9, 10, 13, 14]  # codes for executed and imagined hands/feet\n\n# This will download the files if you don't have them yet,\n# and then return the paths to the files.\nphysionet_paths = mne.datasets.eegbci.load_data(\n    subject_id, event_codes, update_path=False)\n\n# Load each of the files\nraws = [\n    mne.io.read_raw_edf(\n        path, preload=True, stim_channel=\"auto\", verbose=\"WARNING\"\n    )\n    for path in physionet_paths\n]\n\n# Concatenate them\nraw = concatenate_raws(raws)\ndel raws\n\n# Find the events in this dataset\nevents, _ = mne.events_from_annotations(raw)\n\n# Use only EEG channels\npicks = mne.pick_types(raw.info, meg=False, eeg=True, exclude=\"bads\")\n\n# Extract trials, only using EEG channels\nepochs = mne.Epochs(\n    raw,\n    events,\n    event_id=dict(hands_or_left=2, feet_or_right=3),\n    tmin=1,\n    tmax=4.1,\n    proj=False,\n    picks=picks,\n    baseline=None,\n    preload=True,\n)\n\nX = (epochs.get_data() * 1e6).astype(np.float32)\ny = (epochs.events[:, 2] - 2).astype(np.int64)  # 2,3 -> 0,1\ndel epochs\n\n# Set if you want to use GPU\n# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\ncuda = False\nset_random_seeds(seed=20170629, cuda=cuda)\nn_classes = 2\nin_chans = X.shape[1]\n\n\nclass EEGDataSet(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        if self.X.ndim == 3:\n            self.X = self.X[:, :, :, None]\n        self.y = y\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        i_trial, start, stop = idx\n        return self.X[i_trial, :, start:stop], self.y[i_trial]\n\n\ntrain_set = EEGDataSet(X[:70], y[:70])\ntest_set = EEGDataSet(X[70:], y=y[70:])\n\n\nclass TrainTestSplit(object):\n    def __init__(self, train_size):\n        assert isinstance(train_size, (int, float))\n        self.train_size = train_size\n\n    def __call__(self, dataset, y, **kwargs):\n        # can we directly use this https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n        # or stick to same API\n        if isinstance(self.train_size, int):\n            n_train_samples = self.train_size\n        else:\n            n_train_samples = int(self.train_size * len(dataset))\n\n        X, y = dataset.X, dataset.y\n        return (\n            EEGDataSet(X[:n_train_samples], y[:n_train_samples]),\n            EEGDataSet(X[n_train_samples:], y[n_train_samples:]),\n        )\n\n\nset_random_seeds(20200114, True)\n\n# final_conv_length = auto ensures we only get a single output in the time dimension\nmodel = ShallowFBCSPNet(\n    in_chans=in_chans,\n    n_classes=n_classes,\n    input_time_length=train_set.X.shape[2],\n    final_conv_length=\"auto\",\n).create_network()\nto_dense_prediction_model(model)\nif cuda:\n    model.cuda()\n\ninput_time_length = X.shape[2]\n\n# Perform forward pass to determine how many outputs per input\nwith torch.no_grad():\n    dummy_input = torch.tensor(X[:1, :, :input_time_length, None], device=\"cpu\")\n    n_preds_per_input = model(dummy_input).shape[2]\n\n\nclass CroppedNLLLoss:\n    \"\"\"Compute NLL Loss after averaging predictions across time.\n    Assumes predictions are in shape:\n    n_batch size x n_classes x n_predictions (in time)\"\"\"\n\n    def __call__(self, preds, targets):\n        return torch.nn.functional.nll_loss(torch.mean(preds, dim=2), targets)\n\n\ncropped_cb_train = CroppedTrialEpochScoring(\n    \"accuracy\",\n    on_train=True,\n    name=\"train_trial_accuracy\",\n    lower_is_better=False,\n)\n\ncropped_cb_valid = CroppedTrialEpochScoring(\n    \"accuracy\",\n    on_train=False,\n    name=\"valid_trial_accuracy\",\n    lower_is_better=False,\n)\n\nclf = NeuralNet(\n    model,\n    criterion=CroppedNLLLoss,\n    optimizer=optim.AdamW,\n    train_split=TrainTestSplit(train_size=40),\n    optimizer__lr=0.0625 * 0.01,\n    optimizer__weight_decay=0,\n    batch_size=64,\n    iterator_train=CropsDataLoader,\n    iterator_valid=CropsDataLoader,\n    iterator_train__input_time_length=input_time_length,\n    iterator_train__n_preds_per_input=n_preds_per_input,\n    iterator_valid__input_time_length=input_time_length,\n    iterator_valid__n_preds_per_input=n_preds_per_input,\n    callbacks=[\n        (\"train_trial_accuracy\", cropped_cb_train),\n        (\"valid_trial_accuracy\", cropped_cb_valid),\n    ],\n)\n\nclf.fit(train_set, y=None, epochs=4)\nclf.predict(test_set)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}