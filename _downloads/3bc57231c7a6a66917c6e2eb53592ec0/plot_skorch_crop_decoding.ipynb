{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSkorch Crop Decoding\n=========================\n\nExample using Skorch for crop decoding on a simpler dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Lukas Gemein\n#          Robin Tibor Schirrmeister\n#          Alexandre Gramfort\n#          Maciej Sliwowski\n#\n# License: BSD-3\n\nimport mne\nimport numpy as np\nfrom mne.io import concatenate_raws\nfrom torch import optim\n\nfrom braindecode.classifier import EEGClassifier\nfrom braindecode.datasets.croppedxy import CroppedXyDataset\nfrom braindecode.datautil.splitters import TrainTestSplit\nfrom braindecode.losses import CroppedNLLLoss\nfrom braindecode.models import ShallowFBCSPNet\nfrom braindecode.models.util import to_dense_prediction_model, get_output_shape\nfrom braindecode.scoring import CroppedTrialEpochScoring\nfrom braindecode.util import set_random_seeds\n\nsubject_id = (\n    22  # carefully cherry-picked to give nice results on such limited data :)\n)\nevent_codes = [\n    5,\n    6,\n    9,\n    10,\n    13,\n    14,\n]  # codes for executed and imagined hands/feet\n\n# This will download the files if you don't have them yet,\n# and then return the paths to the files.\nphysionet_paths = mne.datasets.eegbci.load_data(\n    subject_id, event_codes, update_path=False\n)\n\n# Load each of the files\nraws = [\n    mne.io.read_raw_edf(\n        path, preload=True, stim_channel=\"auto\", verbose=\"WARNING\"\n    )\n    for path in physionet_paths\n]\n\n# Concatenate them\nraw = concatenate_raws(raws)\ndel raws\n\n# Find the events in this dataset\nevents, _ = mne.events_from_annotations(raw)\n\n# Use only EEG channels\npicks = mne.pick_types(raw.info, meg=False, eeg=True, exclude=\"bads\")\n\n# Extract trials, only using EEG channels\nepochs = mne.Epochs(\n    raw,\n    events,\n    event_id=dict(hands_or_left=2, feet_or_right=3),\n    tmin=1,\n    tmax=4.1,\n    proj=False,\n    picks=picks,\n    baseline=None,\n    preload=True,\n)\n\nX = (epochs.get_data() * 1e6).astype(np.float32)\ny = (epochs.events[:, 2] - 2).astype(np.int64)  # 2,3 -> 0,1\ndel epochs\n\n# Set if you want to use GPU\n# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\ncuda = False\nset_random_seeds(seed=20170629, cuda=cuda)\nn_classes = 2\nin_chans = X.shape[1]\n\n\nset_random_seeds(20200114, cuda=False)\n\n# final_conv_length = auto ensures we only get a single output in the time dimension\nmodel = ShallowFBCSPNet(\n    in_chans=in_chans,\n    n_classes=n_classes,\n    input_time_length=X.shape[2],\n    final_conv_length=\"auto\",\n)\nto_dense_prediction_model(model)\nif cuda:\n    model.cuda()\n\ninput_time_length = X.shape[2]\n\n# Perform forward pass to determine how many outputs per input\nn_preds_per_input = get_output_shape(model, in_chans, input_time_length)[2]\n\n\ntrain_set = CroppedXyDataset(X[:70], y[:70],\n                             input_time_length=input_time_length,\n                             n_preds_per_input=n_preds_per_input)\ntest_set = CroppedXyDataset(X[70:], y=y[70:],\n                            input_time_length=input_time_length,\n                            n_preds_per_input=n_preds_per_input)\n\nclf = EEGClassifier(\n    model,\n    cropped=True,\n    criterion=CroppedNLLLoss,\n    optimizer=optim.AdamW,\n    train_split=TrainTestSplit(\n        train_size=40,\n        input_time_length=input_time_length,\n        n_preds_per_input=n_preds_per_input,),\n    optimizer__lr=0.0625 * 0.01,\n    optimizer__weight_decay=0,\n    batch_size=64,\n    callbacks=['accuracy'],\n)\n\nclf.fit(train_set, y=None, epochs=4)\nclf.predict(test_set)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}