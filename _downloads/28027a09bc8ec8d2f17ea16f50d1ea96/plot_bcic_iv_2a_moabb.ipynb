{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCropped Decoding on BCIC IV 2a Competition Set with skorch and moabb.\n=====================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Maciej Sliwowski <maciek.sliwowski@gmail.com>\n#          Robin Tibor Schirrmeister <robintibor@gmail.com>\n#          Lukas Gemein <l.gemein@gmail.com>\n#          Hubert Banville <hubert.jbanville@gmail.com>\n#\n# License: BSD-3\nfrom collections import OrderedDict\nfrom functools import partial\n\nimport numpy as np\nimport torch\nimport mne\n\nfrom braindecode.models.util import to_dense_prediction_model, get_output_shape\n\nmne.set_log_level('ERROR')\n\nfrom braindecode.datautil.windowers import create_windows_from_events\nfrom braindecode.classifier import EEGClassifier\nfrom braindecode.datasets import MOABBDataset\nfrom braindecode.losses import CroppedNLLLoss\nfrom braindecode.models.deep4 import Deep4Net\nfrom braindecode.models.shallow_fbcsp import ShallowFBCSPNet\nfrom braindecode.scoring import CroppedTrialEpochScoring\nfrom braindecode.util import set_random_seeds\nfrom braindecode.datautil.signalproc import exponential_running_standardize\nfrom braindecode.datautil.transforms import transform_concat_ds\n\nmodel_name = \"shallow\"  # 'shallow' or 'deep'\ncuda = torch.cuda.is_available()\ndevice = 'cuda' if cuda else 'cpu'\n\nset_random_seeds(seed=20190706, cuda=cuda)\n\nsubject_id = 1  # 1-9\nn_classes = 4\n\nlow_cut_hz = 4.  # 0 or 4\nhigh_cut_hz = 38.\nmodel = \"shallow\"  # 'shallow' or 'deep'\ntrial_start_offset_seconds = -0.5\ninput_time_length = 1000\nmax_epochs = 5\nmax_increase_epochs = 80\nbatch_size = 32\nfactor_new = 1e-3\ninit_block_size = 1000\n\nn_chans = 22\n\nif model_name == \"shallow\":\n    model = ShallowFBCSPNet(\n        n_chans,\n        n_classes,\n        input_time_length=input_time_length,\n        final_conv_length=30,\n    )\nelif model_name == \"deep\":\n    model = Deep4Net(\n        n_chans,\n        n_classes,\n        input_time_length=input_time_length,\n        final_conv_length=2,\n    )\n\nif cuda:\n    model.cuda()\n\nto_dense_prediction_model(model)\n\nn_preds_per_input = get_output_shape(model, n_chans, input_time_length)[2]\n\ndataset = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids=[subject_id])\n\nstandardize_func = partial(\n    exponential_running_standardize, factor_new=factor_new,\n    init_block_size=init_block_size)\nraw_transform_dict = OrderedDict([\n    (\"pick_types\", dict(eeg=True, meg=False, stim=False)),\n    ('apply_function', dict(fun=lambda x: x*1e6, channel_wise=False)),\n    ('filter', dict(l_freq=low_cut_hz, h_freq=high_cut_hz)),\n    ('apply_function', dict(fun=standardize_func, channel_wise=False))\n])\ntransform_concat_ds(dataset, raw_transform_dict)\n\nsfreqs = [ds.raw.info['sfreq'] for ds in dataset.datasets]\nassert len(np.unique(sfreqs)) == 1\ntrial_start_offset_samples = int(trial_start_offset_seconds * sfreqs[0])\n\nwindows_dataset = create_windows_from_events(\n    dataset,\n    trial_start_offset_samples=trial_start_offset_samples,\n    trial_stop_offset_samples=0,\n    supercrop_size_samples=input_time_length,\n    supercrop_stride_samples=n_preds_per_input,\n    drop_samples=False\n)\n\n\nclass TrainTestBCICIV2aSplit(object):\n    def __call__(self, dataset, y, **kwargs):\n        splitted = dataset.split('session')\n        return splitted['session_T'], splitted['session_E']\n\n\n# MaxNormDefaultConstraint and early stopping should be added to repeat\n# previous braindecode\nclf = EEGClassifier(\n    model,\n    cropped=True,\n    criterion=CroppedNLLLoss,\n    optimizer=torch.optim.AdamW,\n    train_split=TrainTestBCICIV2aSplit(),\n    optimizer__lr=0.0625 * 0.01,\n    optimizer__weight_decay=0,\n    batch_size=batch_size,\n    callbacks=['accuracy', 'f1_macro'],\n    device=device,\n)\n\nclf.fit(windows_dataset, y=None, epochs=2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}